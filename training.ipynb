{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bffa0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "from math import sin, asin, cos, radians, fabs, sqrt\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bc292b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROOT = '/home/rick/PythonWorkplace/CIGIT2021'\n",
    "ROOT = 'E:\\CIGIT2021'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c04b47e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name1 = 'dn2up.csv'\n",
    "data_name2 = 'up2dn.csv'\n",
    "label_name1 = 'dn2up_stop&signal.csv'\n",
    "label_name2 = 'up2dn_stop&signal.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35906545",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path1 = os.path.join(ROOT, data_name1)    # dn2up\n",
    "data_path2 = os.path.join(ROOT, data_name2)    # up2dn\n",
    "label_path1 = os.path.join(ROOT, label_name1)  # dn2up\n",
    "label_path2 = os.path.join(ROOT, label_name2)  # up2dn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b10ec7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dn2up_data = np.loadtxt(data_path1,delimiter=',',dtype='float64')\n",
    "dn2up_data = dn2up_data[:,:-10]\n",
    "\n",
    "up2dn_data = np.loadtxt(data_path2,delimiter=',',dtype='float64')\n",
    "up2dn_data = up2dn_data[:,:-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "870e474a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dn2up_label = np.loadtxt(label_path1,delimiter=',',dtype='int')\n",
    "dn2up_label_binary = np.zeros((0,2),dtype='int')\n",
    "for i in dn2up_label:\n",
    "    if i[1] == 1:\n",
    "        dn2up_label_binary = np.vstack((dn2up_label_binary,i))\n",
    "        \n",
    "dn2up_label_binary = dn2up_label_binary.T\n",
    "dn2up_label = dn2up_label.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e7dfe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "up2dn_label = np.loadtxt(label_path2,delimiter=',',dtype='int')\n",
    "up2dn_label_binary = np.zeros((0,2),dtype='int')\n",
    "for i in up2dn_label:\n",
    "    if i[1] == 1:\n",
    "        up2dn_label_binary = np.vstack((up2dn_label_binary,i))\n",
    "        \n",
    "up2dn_label_binary = up2dn_label_binary.T\n",
    "up2dn_label = up2dn_label.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22934412",
   "metadata": {},
   "outputs": [],
   "source": [
    "up2dn_label = up2dn_label[:,:-1]\n",
    "up2dn_label_binary = up2dn_label_binary[:,:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabdc82c",
   "metadata": {},
   "source": [
    "# Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8827c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c019da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentile(x, percent):\n",
    "    out = np.zeros(len(x[0]))\n",
    "    count = 0\n",
    "    y = x.T\n",
    "    p = percent / 100\n",
    "    for row in y:\n",
    "        tmp = np.sort(row)\n",
    "        location = int(len(row) * p)\n",
    "        speed = tmp[location - 1]\n",
    "        out[count] = speed\n",
    "        count += 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1618daff",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_dn2up = np.mean(dn2up_data,0)\n",
    "f1_up2dn = np.mean(up2dn_data,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f346efd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f2_dn2up = np.std(dn2up_data,0)\n",
    "f2_up2dn = np.std(up2dn_data,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a7a826e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f3_dn2up = np.abs(stats.skew(dn2up_data,0))\n",
    "f3_up2dn = np.abs(stats.skew(up2dn_data,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64d83419",
   "metadata": {},
   "outputs": [],
   "source": [
    "f4_dn2up = np.abs(stats.kurtosis(dn2up_data,0))\n",
    "f4_up2dn = np.abs(stats.kurtosis(up2dn_data,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0b1af5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f5_dn2up = (f3_dn2up ** 2 + 1) / f4_dn2up\n",
    "f5_up2dn = (f3_up2dn ** 2 + 1) / f4_up2dn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "638992a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f6_dn2up = np.median(dn2up_data,0)\n",
    "f6_up2dn = np.median(up2dn_data,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0682696f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f7_dn2up = percentile(dn2up_data,15)\n",
    "f7_up2dn = percentile(up2dn_data,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e68d4965",
   "metadata": {},
   "outputs": [],
   "source": [
    "f8_dn2up = percentile(dn2up_data,85)\n",
    "f8_up2dn = percentile(up2dn_data,85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "867dc672",
   "metadata": {},
   "outputs": [],
   "source": [
    "f9_dn2up = f8_dn2up - f7_dn2up\n",
    "f9_up2dn = f8_up2dn - f7_up2dn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1dd1c3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f10_dn2up = np.max(dn2up_data,0)\n",
    "f10_up2dn = np.max(up2dn_data,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1546db26",
   "metadata": {},
   "outputs": [],
   "source": [
    "f11_dn2up = np.min(dn2up_data,0)\n",
    "f11_up2dn = np.min(up2dn_data,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33751e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dn2up_data_feature = np.zeros((0,1890))\n",
    "up2dn_data_feature = np.zeros((0,1890))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10162db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,11):\n",
    "    tmp_name_dn2up = 'f%d_dn2up' %i\n",
    "    tmp_name_up2dn = 'f%d_up2dn' %i\n",
    "    \n",
    "    dn2up_data_feature = np.vstack((dn2up_data_feature, globals()[tmp_name_dn2up]))\n",
    "    up2dn_data_feature = np.vstack((up2dn_data_feature, globals()[tmp_name_up2dn]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f074fae",
   "metadata": {},
   "source": [
    "# Framing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57a09d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "dn2up_data_fram = np.zeros((0,len(dn2up_data),10))\n",
    "up2dn_data_fram = np.zeros((0,len(up2dn_data),10))\n",
    "dn2up_data_fram_feature = np.zeros((0,len(dn2up_data_feature),10))\n",
    "up2dn_data_fram_feature = np.zeros((0,len(up2dn_data_feature),10))\n",
    "\n",
    "dn2up_label_fram = np.zeros(0)\n",
    "up2dn_label_fram = np.zeros(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "527d1584",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_index_dn2up = []\n",
    "overlap_index_up2dn = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d1a52b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(int(len(dn2up_data[0])/10)):    # /100m\n",
    "    tmp = np.linspace(i*100,(i+1)*100-10,10,dtype=int)\n",
    "    count = 0\n",
    "    for j in tmp:\n",
    "        \n",
    "        if j in dn2up_label_binary:     # dn2up_label\n",
    "            count += 1\n",
    "            overlap = 5\n",
    "            overlap_index_dn2up.append([i,overlap])\n",
    "            for y in range((int(j/10)-7),(int(j/10)-7+overlap)):   # number of overlapping：5\n",
    "                tmp_data1 = dn2up_data[:,y:y+10].reshape(1,len(dn2up_data),10)\n",
    "                tmp_data2 = dn2up_data_feature[:,y:y+10].reshape(1,len(dn2up_data_feature),10)\n",
    "                dn2up_data_fram = np.vstack((dn2up_data_fram,tmp_data1))\n",
    "                dn2up_data_fram_feature = np.vstack((dn2up_data_fram_feature,tmp_data2))\n",
    "\n",
    "                loc = np.argwhere(dn2up_label[0]==j)\n",
    "                dn2up_label_fram = np.hstack((dn2up_label_fram,dn2up_label[1][loc[0][0]]))\n",
    "\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    if count == 0:\n",
    "        tmp_data1 = dn2up_data[:,i*10:i*10+10].reshape(1,len(dn2up_data),10)\n",
    "        tmp_data2 = dn2up_data_feature[:,i*10:i*10+10].reshape(1,len(dn2up_data_feature),10)\n",
    "        dn2up_data_fram = np.vstack((dn2up_data_fram,tmp_data1))\n",
    "        dn2up_data_fram_feature = np.vstack((dn2up_data_fram_feature,tmp_data2))\n",
    "        \n",
    "        dn2up_label_fram = np.hstack((dn2up_label_fram,0))\n",
    "    else:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "318b9d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "dn2up_data_fram_feature = dn2up_data_fram_feature.reshape((len(dn2up_data_fram_feature),-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7190def1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(int(len(up2dn_data[0])/10)):    # /100m\n",
    "    tmp = np.linspace(i*100,(i+1)*100-10,10,dtype=int)\n",
    "    count = 0\n",
    "    for j in tmp:\n",
    "        \n",
    "        if j in up2dn_label_binary:\n",
    "            count += 1\n",
    "            overlap = 5\n",
    "            overlap_index_up2dn.append([i,overlap])\n",
    "            for y in range((int(j/10)-7),(int(j/10)-7+overlap)):   # number of overlapping：5\n",
    "                tmp_data1 = up2dn_data[:,y:y+10].reshape(1,len(up2dn_data),10)\n",
    "                tmp_data2 = up2dn_data_feature[:,y:y+10].reshape(1,len(up2dn_data_feature),10)\n",
    "                up2dn_data_fram = np.vstack((up2dn_data_fram,tmp_data1))\n",
    "                up2dn_data_fram_feature = np.vstack((up2dn_data_fram_feature,tmp_data2))\n",
    "\n",
    "                loc = np.argwhere(up2dn_label[0]==j)\n",
    "                up2dn_label_fram = np.hstack((up2dn_label_fram,up2dn_label[1][loc[0][0]]))\n",
    "\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    if count == 0:\n",
    "        tmp_data1 = up2dn_data[:,i*10:i*10+10].reshape(1,len(up2dn_data),10)\n",
    "        tmp_data2 = up2dn_data_feature[:,i*10:i*10+10].reshape(1,len(up2dn_data_feature),10)\n",
    "        up2dn_data_fram = np.vstack((up2dn_data_fram,tmp_data1))\n",
    "        up2dn_data_fram_feature = np.vstack((up2dn_data_fram_feature,tmp_data2))\n",
    "        \n",
    "        up2dn_label_fram = np.hstack((up2dn_label_fram,0))\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80fb80b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "up2dn_data_fram_feature = up2dn_data_fram_feature.reshape((len(up2dn_data_fram_feature),-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7882ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fram_feature = np.vstack((dn2up_data_fram_feature,up2dn_data_fram_feature))\n",
    "label_fram_feature = np.hstack((dn2up_label_fram,up2dn_label_fram))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad07cac",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95cf2d1",
   "metadata": {},
   "source": [
    "# k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7f9f6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model, neighbors, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a26ab056",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_knn_dn2up = np.zeros(0)\n",
    "f1_knn_up2dn = np.zeros(0)\n",
    "f1_knn_all = np.zeros(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "34e3181c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c48dcf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_knn_all_cv = np.zeros((0,fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3afd5398",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    k_neighbors = (i+1)*2\n",
    "    knn = neighbors.KNeighborsClassifier(n_neighbors=k_neighbors,algorithm=\"brute\")\n",
    "    tmp_f1_dn2up = np.zeros(0)\n",
    "    tmp_f1_up2dn = np.zeros(0)\n",
    "    tmp_f1_all = np.zeros(0)\n",
    "    for j in range(fold):   # cross validation\n",
    "        length_dn2up = int(len(dn2up_data_fram_feature) / fold)\n",
    "        length_up2dn = int(len(up2dn_data_fram_feature) / fold)\n",
    "        length_all = int(len(data_fram_feature) / fold)\n",
    "        \n",
    "        train_data_dn2up = np.vstack((dn2up_data_fram_feature[:j*length_dn2up],dn2up_data_fram_feature[(j+1)*length_dn2up:]))\n",
    "        train_data_up2dn = np.vstack((up2dn_data_fram_feature[:j*length_up2dn],up2dn_data_fram_feature[(j+1)*length_up2dn:]))\n",
    "        train_data_all = np.vstack((data_fram_feature[:j*length_all],data_fram_feature[(j+1)*length_all:]))\n",
    "\n",
    "        test_data_dn2up = dn2up_data_fram_feature[j*length_dn2up:(j+1)*length_dn2up]\n",
    "        test_data_up2dn = up2dn_data_fram_feature[j*length_up2dn:(j+1)*length_up2dn]\n",
    "        test_data_all = data_fram_feature[j*length_all:(j+1)*length_all]\n",
    "        \n",
    "        train_label_dn2up = np.hstack((dn2up_label_fram[:j*length_dn2up],dn2up_label_fram[(j+1)*length_dn2up:]))\n",
    "        test_label_dn2up = dn2up_label_fram[j*length_dn2up:(j+1)*length_dn2up]\n",
    "        \n",
    "        train_label_up2dn = np.hstack((up2dn_label_fram[:j*length_up2dn],up2dn_label_fram[(j+1)*length_up2dn:]))\n",
    "        test_label_up2dn = up2dn_label_fram[j*length_up2dn:(j+1)*length_up2dn]\n",
    "        \n",
    "        train_label_all = np.hstack((label_fram_feature[:j*length_all],label_fram_feature[(j+1)*length_all:]))\n",
    "        test_label_all = label_fram_feature[j*length_all:(j+1)*length_all]\n",
    "        \n",
    "        knn.fit(train_data_dn2up,train_label_dn2up) \n",
    "        knn_pred_dn2up = knn.predict(test_data_dn2up)        \n",
    "        f1score_dn2up = metrics.f1_score(knn_pred_dn2up,test_label_dn2up)\n",
    "        tmp_f1_dn2up = np.hstack((tmp_f1_dn2up,f1score_dn2up))\n",
    "        \n",
    "        knn.fit(train_data_up2dn,train_label_up2dn) \n",
    "        knn_pred_up2dn = knn.predict(test_data_up2dn)        \n",
    "        f1score_up2dn = metrics.f1_score(knn_pred_up2dn,test_label_up2dn)\n",
    "        tmp_f1_up2dn = np.hstack((tmp_f1_up2dn,f1score_up2dn))\n",
    "        \n",
    "        knn.fit(train_data_all,train_label_all) \n",
    "        knn_pred_all = knn.predict(test_data_all)        \n",
    "        f1score_all = metrics.f1_score(knn_pred_all,test_label_all)\n",
    "        tmp_f1_all = np.hstack((tmp_f1_all,f1score_all))\n",
    "        \n",
    "    f1_m_dn2up = np.max(tmp_f1_dn2up)\n",
    "    f1_m_up2dn = np.max(tmp_f1_up2dn)\n",
    "    f1_m_all = np.max(tmp_f1_all)\n",
    "    f1_knn_all_cv = np.vstack((f1_knn_all_cv,tmp_f1_all))\n",
    "    \n",
    "    f1_knn_dn2up = np.hstack((f1_knn_dn2up,f1_m_dn2up))\n",
    "    f1_knn_up2dn = np.hstack((f1_knn_up2dn,f1_m_up2dn))\n",
    "    f1_knn_all = np.hstack((f1_knn_all,f1_m_all))\n",
    "    \n",
    "f1_max_dn2up_knn = np.max(f1_knn_dn2up)\n",
    "f1_max_up2dn_knn = np.max(f1_knn_up2dn)\n",
    "f1_max_all_knn = np.max(f1_knn_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "97b2ef0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "index1 = np.where(f1_knn_all == f1_max_all_knn)[0][0]\n",
    "index2 = np.where(f1_knn_all_cv[index1] == f1_max_all_knn)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7e5a9e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify the highest f1\n",
    "result_knn_data_train = np.vstack((data_fram_feature[:index2*length_all],data_fram_feature[(index2+1)*length_all:]))\n",
    "result_knn_data_test = data_fram_feature[index2*length_all:(index2+1)*length_all]\n",
    "result_knn_label_train = np.hstack((label_fram_feature[:index2*length_all],label_fram_feature[(index2+1)*length_all:]))\n",
    "result_knn_label_test = label_fram_feature[index2*length_all:(index2+1)*length_all]\n",
    "\n",
    "result_k_neighbors = (index1+1)*2\n",
    "result_knn = neighbors.KNeighborsClassifier(n_neighbors=result_k_neighbors,algorithm=\"brute\")\n",
    "\n",
    "result_knn.fit(result_knn_data_train,result_knn_label_train) \n",
    "result_knn_pred = result_knn.predict(result_knn_data_test)\n",
    "f1_verify_knn = metrics.f1_score(result_knn_pred,result_knn_label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5342b661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max f1 score for all: 0.7567567567567567 \n",
      "max f1 score for up2dn: 0.8648648648648648 \n",
      "max f1 score for dn2up: 0.8035714285714286\n"
     ]
    }
   ],
   "source": [
    "print('max f1 score for all:',f1_max_all_knn,'\\n' 'max f1 score for up2dn:',f1_max_up2dn_knn,'\\n' 'max f1 score for dn2up:',f1_max_dn2up_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c339c4",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "96e827d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "362a3607",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_svm_dn2up = np.zeros(0)\n",
    "f1_svm_up2dn = np.zeros(0)\n",
    "f1_svm_all = np.zeros(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aed02f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_svm_all_cv = np.zeros((0,fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0c9c525d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(-4,10):\n",
    "    c = pow(2,i)\n",
    "    g = 1\n",
    "    SVM = svm.SVC(C=c,kernel='rbf',gamma=g)\n",
    "    tmp_f1_dn2up = np.zeros(0)\n",
    "    tmp_f1_up2dn = np.zeros(0)\n",
    "    tmp_f1_all = np.zeros(0)\n",
    "    for j in range(fold):   # cross validation\n",
    "        length_dn2up = int(len(dn2up_data_fram_feature) / fold)\n",
    "        length_up2dn = int(len(up2dn_data_fram_feature) / fold)\n",
    "        length_all = int(len(data_fram_feature) / fold)\n",
    "        \n",
    "        train_data_dn2up = np.vstack((dn2up_data_fram_feature[:j*length_dn2up],dn2up_data_fram_feature[(j+1)*length_dn2up:]))\n",
    "        train_data_up2dn = np.vstack((up2dn_data_fram_feature[:j*length_up2dn],up2dn_data_fram_feature[(j+1)*length_up2dn:]))\n",
    "        train_data_all = np.vstack((data_fram_feature[:j*length_all],data_fram_feature[(j+1)*length_all:]))\n",
    "\n",
    "        test_data_dn2up = dn2up_data_fram_feature[j*length_dn2up:(j+1)*length_dn2up]\n",
    "        test_data_up2dn = up2dn_data_fram_feature[j*length_up2dn:(j+1)*length_up2dn]\n",
    "        test_data_all = data_fram_feature[j*length_all:(j+1)*length_all]\n",
    "        \n",
    "        train_label_dn2up = np.hstack((dn2up_label_fram[:j*length_dn2up],dn2up_label_fram[(j+1)*length_dn2up:]))\n",
    "        test_label_dn2up = dn2up_label_fram[j*length_dn2up:(j+1)*length_dn2up]\n",
    "        \n",
    "        train_label_up2dn = np.hstack((up2dn_label_fram[:j*length_up2dn],up2dn_label_fram[(j+1)*length_up2dn:]))\n",
    "        test_label_up2dn = up2dn_label_fram[j*length_up2dn:(j+1)*length_up2dn]\n",
    "        \n",
    "        train_label_all = np.hstack((label_fram_feature[:j*length_all],label_fram_feature[(j+1)*length_all:]))\n",
    "        test_label_all = label_fram_feature[j*length_all:(j+1)*length_all]\n",
    "        \n",
    "        SVM.fit(train_data_dn2up,train_label_dn2up) \n",
    "        svm_pred_dn2up = SVM.predict(test_data_dn2up)        \n",
    "        f1score_dn2up = metrics.f1_score(svm_pred_dn2up,test_label_dn2up)\n",
    "        tmp_f1_dn2up = np.hstack((tmp_f1_dn2up,f1score_dn2up))\n",
    "        \n",
    "        SVM.fit(train_data_up2dn,train_label_up2dn) \n",
    "        svm_pred_up2dn = SVM.predict(test_data_up2dn)        \n",
    "        f1score_up2dn = metrics.f1_score(svm_pred_up2dn,test_label_up2dn)\n",
    "        tmp_f1_up2dn = np.hstack((tmp_f1_up2dn,f1score_up2dn))\n",
    "        \n",
    "        SVM.fit(train_data_all,train_label_all) \n",
    "        svm_pred_all = SVM.predict(test_data_all)        \n",
    "        f1score_all = metrics.f1_score(svm_pred_all,test_label_all)\n",
    "        tmp_f1_all = np.hstack((tmp_f1_all,f1score_all))\n",
    "        \n",
    "    f1_m_dn2up = np.max(tmp_f1_dn2up)\n",
    "    f1_m_up2dn = np.max(tmp_f1_up2dn)\n",
    "    f1_m_all = np.max(tmp_f1_all)\n",
    "    f1_svm_all_cv = np.vstack((f1_svm_all_cv,tmp_f1_all))\n",
    "    \n",
    "    f1_svm_dn2up = np.hstack((f1_svm_dn2up,f1_m_dn2up))\n",
    "    f1_svm_up2dn = np.hstack((f1_svm_up2dn,f1_m_up2dn))\n",
    "    f1_svm_all = np.hstack((f1_svm_all,f1_m_all))\n",
    "    \n",
    "f1_max_dn2up_svm = np.max(f1_svm_dn2up)\n",
    "f1_max_up2dn_svm = np.max(f1_svm_up2dn)\n",
    "f1_max_all_svm = np.max(f1_svm_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d2abbab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "index3 = np.where(f1_svm_all == f1_max_all_svm)[0][0]\n",
    "index4 = np.where(f1_svm_all_cv[index3] == f1_max_all_svm)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f9ef3510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify the highest f1\n",
    "result_svm_data_train = np.vstack((data_fram_feature[:index4*length_all],data_fram_feature[(index4+1)*length_all:]))\n",
    "result_svm_data_test = data_fram_feature[index4*length_all:(index4+1)*length_all]\n",
    "result_svm_label_train = np.hstack((label_fram_feature[:index4*length_all],label_fram_feature[(index4+1)*length_all:]))\n",
    "result_svm_label_test = label_fram_feature[index4*length_all:(index4+1)*length_all]\n",
    "\n",
    "c = pow(2, int(index3-4))\n",
    "result_svm = svm.SVC(C=c,kernel='rbf',gamma=g)\n",
    "\n",
    "result_svm.fit(result_svm_data_train,result_svm_label_train) \n",
    "result_svm_pred = result_svm.predict(result_svm_data_test)\n",
    "f1_verify_svm = metrics.f1_score(result_svm_pred,result_svm_label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2c82e8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max f1 score for all: 0.7086614173228347 \n",
      "max f1 score for up2dn: 0.7669172932330827 \n",
      "max f1 score for dn2up: 0.7575757575757575\n"
     ]
    }
   ],
   "source": [
    "print('max f1 score for all:',f1_max_all_svm,'\\n' 'max f1 score for up2dn:',f1_max_up2dn_svm,'\\n' 'max f1 score for dn2up:',f1_max_dn2up_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6cabcf",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "db10c07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "228ae939",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_rf_dn2up = np.zeros(0)\n",
    "f1_rf_up2dn = np.zeros(0)\n",
    "f1_rf_all = np.zeros(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3f915d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_rf_all_cv = np.zeros((0,fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c173a6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    n = (i+1)*10\n",
    "    RF = RandomForestClassifier(n_estimators=n, criterion='entropy')\n",
    "    tmp_f1_dn2up = np.zeros(0)\n",
    "    tmp_f1_up2dn = np.zeros(0)\n",
    "    tmp_f1_all = np.zeros(0)\n",
    "    for j in range(fold):   # cross validation\n",
    "        length_dn2up = int(len(dn2up_data_fram_feature) / fold)\n",
    "        length_up2dn = int(len(up2dn_data_fram_feature) / fold)\n",
    "        length_all = int(len(data_fram_feature) / fold)\n",
    "        \n",
    "        train_data_dn2up = np.vstack((dn2up_data_fram_feature[:j*length_dn2up],dn2up_data_fram_feature[(j+1)*length_dn2up:]))\n",
    "        train_data_up2dn = np.vstack((up2dn_data_fram_feature[:j*length_up2dn],up2dn_data_fram_feature[(j+1)*length_up2dn:]))\n",
    "        train_data_all = np.vstack((data_fram_feature[:j*length_all],data_fram_feature[(j+1)*length_all:]))\n",
    "\n",
    "        test_data_dn2up = dn2up_data_fram_feature[j*length_dn2up:(j+1)*length_dn2up]\n",
    "        test_data_up2dn = up2dn_data_fram_feature[j*length_up2dn:(j+1)*length_up2dn]\n",
    "        test_data_all = data_fram_feature[j*length_all:(j+1)*length_all]\n",
    "        \n",
    "        train_label_dn2up = np.hstack((dn2up_label_fram[:j*length_dn2up],dn2up_label_fram[(j+1)*length_dn2up:]))\n",
    "        test_label_dn2up = dn2up_label_fram[j*length_dn2up:(j+1)*length_dn2up]\n",
    "        \n",
    "        train_label_up2dn = np.hstack((up2dn_label_fram[:j*length_up2dn],up2dn_label_fram[(j+1)*length_up2dn:]))\n",
    "        test_label_up2dn = up2dn_label_fram[j*length_up2dn:(j+1)*length_up2dn]\n",
    "        \n",
    "        train_label_all = np.hstack((label_fram_feature[:j*length_all],label_fram_feature[(j+1)*length_all:]))\n",
    "        test_label_all = label_fram_feature[j*length_all:(j+1)*length_all]\n",
    "        \n",
    "        RF.fit(train_data_dn2up,train_label_dn2up) \n",
    "        rf_pred_dn2up = RF.predict(test_data_dn2up)        \n",
    "        f1score_dn2up = metrics.f1_score(rf_pred_dn2up,test_label_dn2up)\n",
    "        tmp_f1_dn2up = np.hstack((tmp_f1_dn2up,f1score_dn2up))\n",
    "        \n",
    "        RF.fit(train_data_up2dn,train_label_up2dn) \n",
    "        rf_pred_up2dn = RF.predict(test_data_up2dn)        \n",
    "        f1score_up2dn = metrics.f1_score(rf_pred_up2dn,test_label_up2dn)\n",
    "        tmp_f1_up2dn = np.hstack((tmp_f1_up2dn,f1score_up2dn))\n",
    "        \n",
    "        RF.fit(train_data_all,train_label_all) \n",
    "        rf_pred_all = RF.predict(test_data_all)        \n",
    "        f1score_all = metrics.f1_score(rf_pred_all,test_label_all)\n",
    "        tmp_f1_all = np.hstack((tmp_f1_all,f1score_all))\n",
    "        \n",
    "    f1_m_dn2up = np.max(tmp_f1_dn2up)\n",
    "    f1_m_up2dn = np.max(tmp_f1_up2dn)\n",
    "    f1_m_all = np.max(tmp_f1_all)\n",
    "    f1_rf_all_cv = np.vstack((f1_rf_all_cv,tmp_f1_all))\n",
    "    \n",
    "    f1_rf_dn2up = np.hstack((f1_rf_dn2up,f1_m_dn2up))\n",
    "    f1_rf_up2dn = np.hstack((f1_rf_up2dn,f1_m_up2dn))\n",
    "    f1_rf_all = np.hstack((f1_rf_all,f1_m_all))\n",
    "    \n",
    "f1_max_dn2up_rf = np.max(f1_rf_dn2up)\n",
    "f1_max_up2dn_rf = np.max(f1_rf_up2dn)\n",
    "f1_max_all_rf = np.max(f1_rf_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "06d4d04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max f1 score for all: 0.654320987654321 \n",
      "max f1 score for up2dn: 0.6153846153846154 \n",
      "max f1 score for dn2up: 0.7532467532467533\n"
     ]
    }
   ],
   "source": [
    "print('max f1 score for all:',f1_max_all_rf,'\\n' 'max f1 score for up2dn:',f1_max_up2dn_rf,'\\n' 'max f1 score for dn2up:',f1_max_dn2up_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6373296",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50a83ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from visdom import Visdom\n",
    "import Ipynb_importer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae9ae16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from fc.ipynb\n"
     ]
    }
   ],
   "source": [
    "from fc import FullConnect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8be799f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsz = 32\n",
    "device = torch.device('cuda')\n",
    "model = FullConnect()\n",
    "criteon = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "13e0d7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Accuracy'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viz = Visdom()\n",
    "viz.line([0.], [0.], win='Training_Loss', opts=dict(title='Training loss'))\n",
    "viz.line([0.], [0.], win='Training_Accuracy', opts=dict(title='Training accuracy'))\n",
    "viz.line([0.], [0.], win='Testing_Loss', opts=dict(title='Testing loss'))\n",
    "viz.line([0.], [0.], win='Accuracy', opts=dict(title='Accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "653c5f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_fram_feature\n",
    "label = label_fram_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d82f38a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机打乱\n",
    "np.random.seed(10)\n",
    "np.random.shuffle(data)\n",
    "np.random.shuffle(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0bfd1ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.from_numpy(data[int(len(data)/3):])\n",
    "train_data = train_data.type(torch.FloatTensor)\n",
    "\n",
    "test_data = torch.from_numpy(data[:int(len(data)/3)])\n",
    "test_data = test_data.type(torch.FloatTensor)\n",
    "\n",
    "train_label = torch.from_numpy(label[int(len(data)/3):])\n",
    "train_label = torch.as_tensor(train_label, dtype=torch.long)\n",
    "\n",
    "test_label = torch.from_numpy(label[:int(len(data)/3)])\n",
    "test_label = torch.as_tensor(test_label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9e1db481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: 0.3861740827560425\n",
      "epoch: 0 loss: 0.324104368686676\n",
      "epoch: 0 loss: 0.31272953748703003\n",
      "epoch: 0 loss: 0.40726104378700256\n",
      "epoch: 0 loss: 0.35409513115882874\n",
      "epoch: 0 loss: 0.44465216994285583\n",
      "epoch: 0 loss: 0.3778573274612427\n",
      "epoch: 0 loss: 0.2814750075340271\n",
      "epoch: 0 loss: 0.4937072992324829\n",
      "epoch: 0 loss: 0.35421937704086304\n",
      "epoch: 0 loss: 0.25649887323379517\n",
      "epoch: 0 loss: 0.35524553060531616\n",
      "epoch: 0 loss: 0.3686962127685547\n",
      "epoch: 0 acc: 0.5520833333333334\n",
      "epoch: 1 loss: 0.4094166159629822\n",
      "epoch: 1 loss: 0.30124980211257935\n",
      "epoch: 1 loss: 0.29859083890914917\n",
      "epoch: 1 loss: 0.43501898646354675\n",
      "epoch: 1 loss: 0.33196181058883667\n",
      "epoch: 1 loss: 0.4559423625469208\n",
      "epoch: 1 loss: 0.340625137090683\n",
      "epoch: 1 loss: 0.24398775398731232\n",
      "epoch: 1 loss: 0.5003544092178345\n",
      "epoch: 1 loss: 0.34835654497146606\n",
      "epoch: 1 loss: 0.27132871747016907\n",
      "epoch: 1 loss: 0.3194340765476227\n",
      "epoch: 1 loss: 0.3573673665523529\n",
      "epoch: 1 acc: 0.5520833333333334\n",
      "epoch: 2 loss: 0.377846896648407\n",
      "epoch: 2 loss: 0.3049628734588623\n",
      "epoch: 2 loss: 0.2982068657875061\n",
      "epoch: 2 loss: 0.4369494318962097\n",
      "epoch: 2 loss: 0.3369867205619812\n",
      "epoch: 2 loss: 0.42752805352211\n",
      "epoch: 2 loss: 0.3378241956233978\n",
      "epoch: 2 loss: 0.2284432053565979\n",
      "epoch: 2 loss: 0.49527090787887573\n",
      "epoch: 2 loss: 0.3709270656108856\n",
      "epoch: 2 loss: 0.24278002977371216\n",
      "epoch: 2 loss: 0.32050102949142456\n",
      "epoch: 2 loss: 0.31779465079307556\n",
      "epoch: 2 acc: 0.546875\n",
      "epoch: 3 loss: 0.37516987323760986\n",
      "epoch: 3 loss: 0.2984045743942261\n",
      "epoch: 3 loss: 0.2928089201450348\n",
      "epoch: 3 loss: 0.3733583986759186\n",
      "epoch: 3 loss: 0.33961349725723267\n",
      "epoch: 3 loss: 0.4617210030555725\n",
      "epoch: 3 loss: 0.3569298982620239\n",
      "epoch: 3 loss: 0.2309427261352539\n",
      "epoch: 3 loss: 0.49058303236961365\n",
      "epoch: 3 loss: 0.36800485849380493\n",
      "epoch: 3 loss: 0.23978032171726227\n",
      "epoch: 3 loss: 0.3392973840236664\n",
      "epoch: 3 loss: 0.33076274394989014\n",
      "epoch: 3 acc: 0.546875\n",
      "epoch: 4 loss: 0.43692299723625183\n",
      "epoch: 4 loss: 0.30923211574554443\n",
      "epoch: 4 loss: 0.3034383952617645\n",
      "epoch: 4 loss: 0.40363359451293945\n",
      "epoch: 4 loss: 0.3376176357269287\n",
      "epoch: 4 loss: 0.4871932566165924\n",
      "epoch: 4 loss: 0.4052105247974396\n",
      "epoch: 4 loss: 0.26821786165237427\n",
      "epoch: 4 loss: 0.552261471748352\n",
      "epoch: 4 loss: 0.35979682207107544\n",
      "epoch: 4 loss: 0.26959317922592163\n",
      "epoch: 4 loss: 0.3327370584011078\n",
      "epoch: 4 loss: 0.375657320022583\n",
      "epoch: 4 acc: 0.578125\n",
      "epoch: 5 loss: 0.46710774302482605\n",
      "epoch: 5 loss: 0.3031679093837738\n",
      "epoch: 5 loss: 0.3274884819984436\n",
      "epoch: 5 loss: 0.42299026250839233\n",
      "epoch: 5 loss: 0.34597423672676086\n",
      "epoch: 5 loss: 0.5155781507492065\n",
      "epoch: 5 loss: 0.3085290491580963\n",
      "epoch: 5 loss: 0.22158312797546387\n",
      "epoch: 5 loss: 0.5020684599876404\n",
      "epoch: 5 loss: 0.3801944851875305\n",
      "epoch: 5 loss: 0.26912710070610046\n",
      "epoch: 5 loss: 0.3365497887134552\n",
      "epoch: 5 loss: 0.33833348751068115\n",
      "epoch: 5 acc: 0.53125\n",
      "epoch: 6 loss: 0.40439164638519287\n",
      "epoch: 6 loss: 0.33567923307418823\n",
      "epoch: 6 loss: 0.2984042465686798\n",
      "epoch: 6 loss: 0.36656200885772705\n",
      "epoch: 6 loss: 0.32977020740509033\n",
      "epoch: 6 loss: 0.47303807735443115\n",
      "epoch: 6 loss: 0.4375491738319397\n",
      "epoch: 6 loss: 0.2566649615764618\n",
      "epoch: 6 loss: 0.4712621569633484\n",
      "epoch: 6 loss: 0.3607513904571533\n",
      "epoch: 6 loss: 0.238132506608963\n",
      "epoch: 6 loss: 0.3370407223701477\n",
      "epoch: 6 loss: 0.33698275685310364\n",
      "epoch: 6 acc: 0.546875\n",
      "epoch: 7 loss: 0.4350549578666687\n",
      "epoch: 7 loss: 0.312364786863327\n",
      "epoch: 7 loss: 0.3105640113353729\n",
      "epoch: 7 loss: 0.3915480077266693\n",
      "epoch: 7 loss: 0.35328206419944763\n",
      "epoch: 7 loss: 0.48565420508384705\n",
      "epoch: 7 loss: 0.39598599076271057\n",
      "epoch: 7 loss: 0.2588083744049072\n",
      "epoch: 7 loss: 0.48973244428634644\n",
      "epoch: 7 loss: 0.3729326128959656\n",
      "epoch: 7 loss: 0.22777003049850464\n",
      "epoch: 7 loss: 0.3622274696826935\n",
      "epoch: 7 loss: 0.36883866786956787\n",
      "epoch: 7 acc: 0.5572916666666666\n",
      "epoch: 8 loss: 0.46197885274887085\n",
      "epoch: 8 loss: 0.3102618157863617\n",
      "epoch: 8 loss: 0.31297317147254944\n",
      "epoch: 8 loss: 0.38895660638809204\n",
      "epoch: 8 loss: 0.345441073179245\n",
      "epoch: 8 loss: 0.48156261444091797\n",
      "epoch: 8 loss: 0.3714562952518463\n",
      "epoch: 8 loss: 0.25725945830345154\n",
      "epoch: 8 loss: 0.4938800036907196\n",
      "epoch: 8 loss: 0.35064300894737244\n",
      "epoch: 8 loss: 0.2497379183769226\n",
      "epoch: 8 loss: 0.33175647258758545\n",
      "epoch: 8 loss: 0.3520843982696533\n",
      "epoch: 8 acc: 0.546875\n",
      "epoch: 9 loss: 0.4346562623977661\n",
      "epoch: 9 loss: 0.30499109625816345\n",
      "epoch: 9 loss: 0.2959352135658264\n",
      "epoch: 9 loss: 0.4066460132598877\n",
      "epoch: 9 loss: 0.3308960497379303\n",
      "epoch: 9 loss: 0.46320950984954834\n",
      "epoch: 9 loss: 0.36700382828712463\n",
      "epoch: 9 loss: 0.25466305017471313\n",
      "epoch: 9 loss: 0.4903302788734436\n",
      "epoch: 9 loss: 0.3527212142944336\n",
      "epoch: 9 loss: 0.2552855610847473\n",
      "epoch: 9 loss: 0.3275196850299835\n",
      "epoch: 9 loss: 0.36056312918663025\n",
      "epoch: 9 acc: 0.5208333333333334\n",
      "epoch: 10 loss: 0.43465590476989746\n",
      "epoch: 10 loss: 0.3216041326522827\n",
      "epoch: 10 loss: 0.3011113405227661\n",
      "epoch: 10 loss: 0.3804781436920166\n",
      "epoch: 10 loss: 0.33556389808654785\n",
      "epoch: 10 loss: 0.48712292313575745\n",
      "epoch: 10 loss: 0.4164554178714752\n",
      "epoch: 10 loss: 0.26134130358695984\n",
      "epoch: 10 loss: 0.47870710492134094\n",
      "epoch: 10 loss: 0.38951554894447327\n",
      "epoch: 10 loss: 0.2638881206512451\n",
      "epoch: 10 loss: 0.37463003396987915\n",
      "epoch: 10 loss: 0.32773804664611816\n",
      "epoch: 10 acc: 0.5416666666666666\n",
      "epoch: 11 loss: 0.40917736291885376\n",
      "epoch: 11 loss: 0.3229497969150543\n",
      "epoch: 11 loss: 0.30662086606025696\n",
      "epoch: 11 loss: 0.3797895312309265\n",
      "epoch: 11 loss: 0.3487285375595093\n",
      "epoch: 11 loss: 0.48300936818122864\n",
      "epoch: 11 loss: 0.3912116587162018\n",
      "epoch: 11 loss: 0.23198240995407104\n",
      "epoch: 11 loss: 0.4779227375984192\n",
      "epoch: 11 loss: 0.3905388116836548\n",
      "epoch: 11 loss: 0.24013325572013855\n",
      "epoch: 11 loss: 0.374234139919281\n",
      "epoch: 11 loss: 0.3377792537212372\n",
      "epoch: 11 acc: 0.5572916666666666\n",
      "epoch: 12 loss: 0.4161624014377594\n",
      "epoch: 12 loss: 0.3269534707069397\n",
      "epoch: 12 loss: 0.3111800253391266\n",
      "epoch: 12 loss: 0.39564090967178345\n",
      "epoch: 12 loss: 0.35525500774383545\n",
      "epoch: 12 loss: 0.4521387815475464\n",
      "epoch: 12 loss: 0.43974971771240234\n",
      "epoch: 12 loss: 0.2894481122493744\n",
      "epoch: 12 loss: 0.4931357800960541\n",
      "epoch: 12 loss: 0.3497024178504944\n",
      "epoch: 12 loss: 0.24680829048156738\n",
      "epoch: 12 loss: 0.34042972326278687\n",
      "epoch: 12 loss: 0.35142821073532104\n",
      "epoch: 12 acc: 0.546875\n",
      "epoch: 13 loss: 0.5090206861495972\n",
      "epoch: 13 loss: 0.3007242679595947\n",
      "epoch: 13 loss: 0.3020620048046112\n",
      "epoch: 13 loss: 0.41411447525024414\n",
      "epoch: 13 loss: 0.33468711376190186\n",
      "epoch: 13 loss: 0.46955904364585876\n",
      "epoch: 13 loss: 0.41740065813064575\n",
      "epoch: 13 loss: 0.30379512906074524\n",
      "epoch: 13 loss: 0.5175395011901855\n",
      "epoch: 13 loss: 0.334808349609375\n",
      "epoch: 13 loss: 0.26797905564308167\n",
      "epoch: 13 loss: 0.33095186948776245\n",
      "epoch: 13 loss: 0.3577721118927002\n",
      "epoch: 13 acc: 0.5416666666666666\n",
      "epoch: 14 loss: 0.5483213067054749\n",
      "epoch: 14 loss: 0.30745840072631836\n",
      "epoch: 14 loss: 0.34173619747161865\n",
      "epoch: 14 loss: 0.41435617208480835\n",
      "epoch: 14 loss: 0.3545644283294678\n",
      "epoch: 14 loss: 0.5235698223114014\n",
      "epoch: 14 loss: 0.43289506435394287\n",
      "epoch: 14 loss: 0.2697426676750183\n",
      "epoch: 14 loss: 0.5006065964698792\n",
      "epoch: 14 loss: 0.3335762917995453\n",
      "epoch: 14 loss: 0.2828664481639862\n",
      "epoch: 14 loss: 0.3257397413253784\n",
      "epoch: 14 loss: 0.37305229902267456\n",
      "epoch: 14 acc: 0.5520833333333334\n",
      "epoch: 15 loss: 0.48621630668640137\n",
      "epoch: 15 loss: 0.3427933156490326\n",
      "epoch: 15 loss: 0.32726162672042847\n",
      "epoch: 15 loss: 0.37482789158821106\n",
      "epoch: 15 loss: 0.37384548783302307\n",
      "epoch: 15 loss: 0.5341747403144836\n",
      "epoch: 15 loss: 0.4480511248111725\n",
      "epoch: 15 loss: 0.3089276850223541\n",
      "epoch: 15 loss: 0.4633042812347412\n",
      "epoch: 15 loss: 0.354082852602005\n",
      "epoch: 15 loss: 0.2489122897386551\n",
      "epoch: 15 loss: 0.35928744077682495\n",
      "epoch: 15 loss: 0.3734722435474396\n",
      "epoch: 15 acc: 0.5416666666666666\n",
      "epoch: 16 loss: 0.5608760714530945\n",
      "epoch: 16 loss: 0.2952911853790283\n",
      "epoch: 16 loss: 0.3359024226665497\n",
      "epoch: 16 loss: 0.3742508292198181\n",
      "epoch: 16 loss: 0.37280717492103577\n",
      "epoch: 16 loss: 0.5341405272483826\n",
      "epoch: 16 loss: 0.39395764470100403\n",
      "epoch: 16 loss: 0.27393829822540283\n",
      "epoch: 16 loss: 0.5166922211647034\n",
      "epoch: 16 loss: 0.3377305269241333\n",
      "epoch: 16 loss: 0.23412156105041504\n",
      "epoch: 16 loss: 0.3372953236103058\n",
      "epoch: 16 loss: 0.3397267758846283\n",
      "epoch: 16 acc: 0.546875\n",
      "epoch: 17 loss: 0.5791060328483582\n",
      "epoch: 17 loss: 0.3039211928844452\n",
      "epoch: 17 loss: 0.3086162209510803\n",
      "epoch: 17 loss: 0.4106307625770569\n",
      "epoch: 17 loss: 0.341309517621994\n",
      "epoch: 17 loss: 0.4966058135032654\n",
      "epoch: 17 loss: 0.4668661952018738\n",
      "epoch: 17 loss: 0.2528546452522278\n",
      "epoch: 17 loss: 0.5312245488166809\n",
      "epoch: 17 loss: 0.3471415638923645\n",
      "epoch: 17 loss: 0.24705111980438232\n",
      "epoch: 17 loss: 0.3324090838432312\n",
      "epoch: 17 loss: 0.3685797154903412\n",
      "epoch: 17 acc: 0.5416666666666666\n",
      "epoch: 18 loss: 0.5450617074966431\n",
      "epoch: 18 loss: 0.3443972170352936\n",
      "epoch: 18 loss: 0.331858366727829\n",
      "epoch: 18 loss: 0.3759574890136719\n",
      "epoch: 18 loss: 0.35149383544921875\n",
      "epoch: 18 loss: 0.5050539374351501\n",
      "epoch: 18 loss: 0.4022972881793976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 loss: 0.28071513772010803\n",
      "epoch: 18 loss: 0.46539410948753357\n",
      "epoch: 18 loss: 0.3628064692020416\n",
      "epoch: 18 loss: 0.2294388711452484\n",
      "epoch: 18 loss: 0.3308197259902954\n",
      "epoch: 18 loss: 0.3566410541534424\n",
      "epoch: 18 acc: 0.5572916666666666\n",
      "epoch: 19 loss: 0.4729793965816498\n",
      "epoch: 19 loss: 0.29628875851631165\n",
      "epoch: 19 loss: 0.32609784603118896\n",
      "epoch: 19 loss: 0.3559989929199219\n",
      "epoch: 19 loss: 0.33615678548812866\n",
      "epoch: 19 loss: 0.4541664719581604\n",
      "epoch: 19 loss: 0.3858971893787384\n",
      "epoch: 19 loss: 0.2799304127693176\n",
      "epoch: 19 loss: 0.48633530735969543\n",
      "epoch: 19 loss: 0.3638972043991089\n",
      "epoch: 19 loss: 0.24187451601028442\n",
      "epoch: 19 loss: 0.3577767014503479\n",
      "epoch: 19 loss: 0.37023085355758667\n",
      "epoch: 19 acc: 0.5416666666666666\n",
      "epoch: 20 loss: 0.4762517511844635\n",
      "epoch: 20 loss: 0.3104972839355469\n",
      "epoch: 20 loss: 0.32735490798950195\n",
      "epoch: 20 loss: 0.38776859641075134\n",
      "epoch: 20 loss: 0.3334616422653198\n",
      "epoch: 20 loss: 0.4182613790035248\n",
      "epoch: 20 loss: 0.4278113543987274\n",
      "epoch: 20 loss: 0.2781433165073395\n",
      "epoch: 20 loss: 0.5259240865707397\n",
      "epoch: 20 loss: 0.3412970006465912\n",
      "epoch: 20 loss: 0.2355983555316925\n",
      "epoch: 20 loss: 0.32636404037475586\n",
      "epoch: 20 loss: 0.3336501717567444\n",
      "epoch: 20 acc: 0.5729166666666666\n",
      "epoch: 21 loss: 0.4646921753883362\n",
      "epoch: 21 loss: 0.2880772352218628\n",
      "epoch: 21 loss: 0.2961284816265106\n",
      "epoch: 21 loss: 0.37820112705230713\n",
      "epoch: 21 loss: 0.3467330038547516\n",
      "epoch: 21 loss: 0.4800851047039032\n",
      "epoch: 21 loss: 0.35516080260276794\n",
      "epoch: 21 loss: 0.2353663295507431\n",
      "epoch: 21 loss: 0.4730093777179718\n",
      "epoch: 21 loss: 0.362000435590744\n",
      "epoch: 21 loss: 0.2178344428539276\n",
      "epoch: 21 loss: 0.34748196601867676\n",
      "epoch: 21 loss: 0.3265560269355774\n",
      "epoch: 21 acc: 0.5625\n",
      "epoch: 22 loss: 0.4642845690250397\n",
      "epoch: 22 loss: 0.31118786334991455\n",
      "epoch: 22 loss: 0.3378788232803345\n",
      "epoch: 22 loss: 0.3683029115200043\n",
      "epoch: 22 loss: 0.3292659521102905\n",
      "epoch: 22 loss: 0.4586928188800812\n",
      "epoch: 22 loss: 0.427059143781662\n",
      "epoch: 22 loss: 0.2478376179933548\n",
      "epoch: 22 loss: 0.4677262306213379\n",
      "epoch: 22 loss: 0.3474317789077759\n",
      "epoch: 22 loss: 0.23548543453216553\n",
      "epoch: 22 loss: 0.34377533197402954\n",
      "epoch: 22 loss: 0.31291961669921875\n",
      "epoch: 22 acc: 0.5572916666666666\n",
      "epoch: 23 loss: 0.44046923518180847\n",
      "epoch: 23 loss: 0.3048548102378845\n",
      "epoch: 23 loss: 0.31959766149520874\n",
      "epoch: 23 loss: 0.4114373028278351\n",
      "epoch: 23 loss: 0.33972156047821045\n",
      "epoch: 23 loss: 0.4410296082496643\n",
      "epoch: 23 loss: 0.43815016746520996\n",
      "epoch: 23 loss: 0.3014986217021942\n",
      "epoch: 23 loss: 0.5217387080192566\n",
      "epoch: 23 loss: 0.33892133831977844\n",
      "epoch: 23 loss: 0.2069883495569229\n",
      "epoch: 23 loss: 0.31912535429000854\n",
      "epoch: 23 loss: 0.3358096778392792\n",
      "epoch: 23 acc: 0.5416666666666666\n",
      "epoch: 24 loss: 0.5426865816116333\n",
      "epoch: 24 loss: 0.29396870732307434\n",
      "epoch: 24 loss: 0.31350573897361755\n",
      "epoch: 24 loss: 0.3856344223022461\n",
      "epoch: 24 loss: 0.3392093777656555\n",
      "epoch: 24 loss: 0.4679585099220276\n",
      "epoch: 24 loss: 0.36825647950172424\n",
      "epoch: 24 loss: 0.2310861200094223\n",
      "epoch: 24 loss: 0.4846383035182953\n",
      "epoch: 24 loss: 0.346062570810318\n",
      "epoch: 24 loss: 0.23752060532569885\n",
      "epoch: 24 loss: 0.3279736638069153\n",
      "epoch: 24 loss: 0.31451883912086487\n",
      "epoch: 24 acc: 0.5416666666666666\n",
      "epoch: 25 loss: 0.4498603940010071\n",
      "epoch: 25 loss: 0.3116634786128998\n",
      "epoch: 25 loss: 0.32871943712234497\n",
      "epoch: 25 loss: 0.38650384545326233\n",
      "epoch: 25 loss: 0.320066899061203\n",
      "epoch: 25 loss: 0.4221048057079315\n",
      "epoch: 25 loss: 0.4089556038379669\n",
      "epoch: 25 loss: 0.24853424727916718\n",
      "epoch: 25 loss: 0.46485188603401184\n",
      "epoch: 25 loss: 0.3432970643043518\n",
      "epoch: 25 loss: 0.2178974449634552\n",
      "epoch: 25 loss: 0.32778388261795044\n",
      "epoch: 25 loss: 0.3159138858318329\n",
      "epoch: 25 acc: 0.5625\n",
      "epoch: 26 loss: 0.43910303711891174\n",
      "epoch: 26 loss: 0.3007187247276306\n",
      "epoch: 26 loss: 0.31883713603019714\n",
      "epoch: 26 loss: 0.37488988041877747\n",
      "epoch: 26 loss: 0.3343348503112793\n",
      "epoch: 26 loss: 0.4296354651451111\n",
      "epoch: 26 loss: 0.3777404725551605\n",
      "epoch: 26 loss: 0.2652590870857239\n",
      "epoch: 26 loss: 0.48563438653945923\n",
      "epoch: 26 loss: 0.34226539731025696\n",
      "epoch: 26 loss: 0.21647106111049652\n",
      "epoch: 26 loss: 0.32218366861343384\n",
      "epoch: 26 loss: 0.32572439312934875\n",
      "epoch: 26 acc: 0.5625\n",
      "epoch: 27 loss: 0.47323358058929443\n",
      "epoch: 27 loss: 0.29118964076042175\n",
      "epoch: 27 loss: 0.3112322986125946\n",
      "epoch: 27 loss: 0.3666600286960602\n",
      "epoch: 27 loss: 0.32586684823036194\n",
      "epoch: 27 loss: 0.4487951099872589\n",
      "epoch: 27 loss: 0.40434595942497253\n",
      "epoch: 27 loss: 0.2896151542663574\n",
      "epoch: 27 loss: 0.5245579481124878\n",
      "epoch: 27 loss: 0.3377492129802704\n",
      "epoch: 27 loss: 0.22693517804145813\n",
      "epoch: 27 loss: 0.3151918053627014\n",
      "epoch: 27 loss: 0.3190843462944031\n",
      "epoch: 27 acc: 0.5572916666666666\n",
      "epoch: 28 loss: 0.48035410046577454\n",
      "epoch: 28 loss: 0.29006096720695496\n",
      "epoch: 28 loss: 0.30758920311927795\n",
      "epoch: 28 loss: 0.39525118470191956\n",
      "epoch: 28 loss: 0.3520757555961609\n",
      "epoch: 28 loss: 0.4834206998348236\n",
      "epoch: 28 loss: 0.34324607253074646\n",
      "epoch: 28 loss: 0.2274610847234726\n",
      "epoch: 28 loss: 0.4691171646118164\n",
      "epoch: 28 loss: 0.358340859413147\n",
      "epoch: 28 loss: 0.22010599076747894\n",
      "epoch: 28 loss: 0.3440247178077698\n",
      "epoch: 28 loss: 0.31220924854278564\n",
      "epoch: 28 acc: 0.546875\n",
      "epoch: 29 loss: 0.4429350793361664\n",
      "epoch: 29 loss: 0.308582603931427\n",
      "epoch: 29 loss: 0.3285828232765198\n",
      "epoch: 29 loss: 0.37124672532081604\n",
      "epoch: 29 loss: 0.33379435539245605\n",
      "epoch: 29 loss: 0.4211858808994293\n",
      "epoch: 29 loss: 0.3719000816345215\n",
      "epoch: 29 loss: 0.24677254259586334\n",
      "epoch: 29 loss: 0.4714773893356323\n",
      "epoch: 29 loss: 0.3347211480140686\n",
      "epoch: 29 loss: 0.2220943123102188\n",
      "epoch: 29 loss: 0.3145074248313904\n",
      "epoch: 29 loss: 0.30769580602645874\n",
      "epoch: 29 acc: 0.5729166666666666\n",
      "epoch: 30 loss: 0.43817728757858276\n",
      "epoch: 30 loss: 0.28872910141944885\n",
      "epoch: 30 loss: 0.3084900677204132\n",
      "epoch: 30 loss: 0.36455798149108887\n",
      "epoch: 30 loss: 0.33622658252716064\n",
      "epoch: 30 loss: 0.4167230725288391\n",
      "epoch: 30 loss: 0.37063467502593994\n",
      "epoch: 30 loss: 0.24675323069095612\n",
      "epoch: 30 loss: 0.4932653605937958\n",
      "epoch: 30 loss: 0.3347148597240448\n",
      "epoch: 30 loss: 0.21233773231506348\n",
      "epoch: 30 loss: 0.3191019594669342\n",
      "epoch: 30 loss: 0.3134150803089142\n",
      "epoch: 30 acc: 0.5572916666666666\n",
      "epoch: 31 loss: 0.4930298626422882\n",
      "epoch: 31 loss: 0.29630112648010254\n",
      "epoch: 31 loss: 0.3027085065841675\n",
      "epoch: 31 loss: 0.3760778605937958\n",
      "epoch: 31 loss: 0.3305721879005432\n",
      "epoch: 31 loss: 0.4191267788410187\n",
      "epoch: 31 loss: 0.36699986457824707\n",
      "epoch: 31 loss: 0.24091535806655884\n",
      "epoch: 31 loss: 0.48409849405288696\n",
      "epoch: 31 loss: 0.3378814458847046\n",
      "epoch: 31 loss: 0.21836026012897491\n",
      "epoch: 31 loss: 0.3158058822154999\n",
      "epoch: 31 loss: 0.3163548409938812\n",
      "epoch: 31 acc: 0.5416666666666666\n",
      "epoch: 32 loss: 0.45074668526649475\n",
      "epoch: 32 loss: 0.2968014180660248\n",
      "epoch: 32 loss: 0.30230259895324707\n",
      "epoch: 32 loss: 0.36284297704696655\n",
      "epoch: 32 loss: 0.3208642303943634\n",
      "epoch: 32 loss: 0.42349815368652344\n",
      "epoch: 32 loss: 0.3804576098918915\n",
      "epoch: 32 loss: 0.24133215844631195\n",
      "epoch: 32 loss: 0.4657047390937805\n",
      "epoch: 32 loss: 0.3362743854522705\n",
      "epoch: 32 loss: 0.21103942394256592\n",
      "epoch: 32 loss: 0.3166109621524811\n",
      "epoch: 32 loss: 0.3075270652770996\n",
      "epoch: 32 acc: 0.5572916666666666\n",
      "epoch: 33 loss: 0.41756534576416016\n",
      "epoch: 33 loss: 0.29922035336494446\n",
      "epoch: 33 loss: 0.3115461766719818\n",
      "epoch: 33 loss: 0.36456719040870667\n",
      "epoch: 33 loss: 0.3343423008918762\n",
      "epoch: 33 loss: 0.42281100153923035\n",
      "epoch: 33 loss: 0.3489932417869568\n",
      "epoch: 33 loss: 0.2345917522907257\n",
      "epoch: 33 loss: 0.4696328639984131\n",
      "epoch: 33 loss: 0.34330639243125916\n",
      "epoch: 33 loss: 0.21806024014949799\n",
      "epoch: 33 loss: 0.3246513307094574\n",
      "epoch: 33 loss: 0.3110739588737488\n",
      "epoch: 33 acc: 0.5416666666666666\n",
      "epoch: 34 loss: 0.4056563377380371\n",
      "epoch: 34 loss: 0.29289764165878296\n",
      "epoch: 34 loss: 0.30161410570144653\n",
      "epoch: 34 loss: 0.3726797103881836\n",
      "epoch: 34 loss: 0.3214919865131378\n",
      "epoch: 34 loss: 0.3989003598690033\n",
      "epoch: 34 loss: 0.3502170443534851\n",
      "epoch: 34 loss: 0.25051143765449524\n",
      "epoch: 34 loss: 0.4561557173728943\n",
      "epoch: 34 loss: 0.3382219970226288\n",
      "epoch: 34 loss: 0.21305523812770844\n",
      "epoch: 34 loss: 0.31052565574645996\n",
      "epoch: 34 loss: 0.31385868787765503\n",
      "epoch: 34 acc: 0.546875\n",
      "epoch: 35 loss: 0.4057587683200836\n",
      "epoch: 35 loss: 0.2811349630355835\n",
      "epoch: 35 loss: 0.2962571978569031\n",
      "epoch: 35 loss: 0.37284964323043823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 35 loss: 0.3348240554332733\n",
      "epoch: 35 loss: 0.38881900906562805\n",
      "epoch: 35 loss: 0.35052987933158875\n",
      "epoch: 35 loss: 0.2556016743183136\n",
      "epoch: 35 loss: 0.4604160785675049\n",
      "epoch: 35 loss: 0.33103829622268677\n",
      "epoch: 35 loss: 0.20690332353115082\n",
      "epoch: 35 loss: 0.3214397728443146\n",
      "epoch: 35 loss: 0.3081083297729492\n",
      "epoch: 35 acc: 0.546875\n",
      "epoch: 36 loss: 0.4079740047454834\n",
      "epoch: 36 loss: 0.2774033844470978\n",
      "epoch: 36 loss: 0.2920841872692108\n",
      "epoch: 36 loss: 0.37752455472946167\n",
      "epoch: 36 loss: 0.3447597324848175\n",
      "epoch: 36 loss: 0.4061150848865509\n",
      "epoch: 36 loss: 0.32931870222091675\n",
      "epoch: 36 loss: 0.23712459206581116\n",
      "epoch: 36 loss: 0.45887264609336853\n",
      "epoch: 36 loss: 0.3270438015460968\n",
      "epoch: 36 loss: 0.21405398845672607\n",
      "epoch: 36 loss: 0.31291255354881287\n",
      "epoch: 36 loss: 0.30296194553375244\n",
      "epoch: 36 acc: 0.5416666666666666\n",
      "epoch: 37 loss: 0.39949604868888855\n",
      "epoch: 37 loss: 0.28319621086120605\n",
      "epoch: 37 loss: 0.30082839727401733\n",
      "epoch: 37 loss: 0.36711978912353516\n",
      "epoch: 37 loss: 0.3354390859603882\n",
      "epoch: 37 loss: 0.3924333155155182\n",
      "epoch: 37 loss: 0.32896164059638977\n",
      "epoch: 37 loss: 0.23953627049922943\n",
      "epoch: 37 loss: 0.4538813531398773\n",
      "epoch: 37 loss: 0.3311235010623932\n",
      "epoch: 37 loss: 0.21236124634742737\n",
      "epoch: 37 loss: 0.3171512484550476\n",
      "epoch: 37 loss: 0.3046748638153076\n",
      "epoch: 37 acc: 0.546875\n",
      "epoch: 38 loss: 0.3922065496444702\n",
      "epoch: 38 loss: 0.27797746658325195\n",
      "epoch: 38 loss: 0.29619085788726807\n",
      "epoch: 38 loss: 0.37185990810394287\n",
      "epoch: 38 loss: 0.33925768733024597\n",
      "epoch: 38 loss: 0.3895043134689331\n",
      "epoch: 38 loss: 0.3256804943084717\n",
      "epoch: 38 loss: 0.24409987032413483\n",
      "epoch: 38 loss: 0.4528789520263672\n",
      "epoch: 38 loss: 0.3271476924419403\n",
      "epoch: 38 loss: 0.2079358547925949\n",
      "epoch: 38 loss: 0.3107254207134247\n",
      "epoch: 38 loss: 0.3040512800216675\n",
      "epoch: 38 acc: 0.546875\n",
      "epoch: 39 loss: 0.4028109312057495\n",
      "epoch: 39 loss: 0.2807022035121918\n",
      "epoch: 39 loss: 0.3019678592681885\n",
      "epoch: 39 loss: 0.3622100353240967\n",
      "epoch: 39 loss: 0.34031203389167786\n",
      "epoch: 39 loss: 0.3954806625843048\n",
      "epoch: 39 loss: 0.3261176645755768\n",
      "epoch: 39 loss: 0.23040102422237396\n",
      "epoch: 39 loss: 0.45111024379730225\n",
      "epoch: 39 loss: 0.33000680804252625\n",
      "epoch: 39 loss: 0.21762125194072723\n",
      "epoch: 39 loss: 0.325474351644516\n",
      "epoch: 39 loss: 0.3058937191963196\n",
      "epoch: 39 acc: 0.5416666666666666\n",
      "epoch: 40 loss: 0.3778943717479706\n",
      "epoch: 40 loss: 0.2812192142009735\n",
      "epoch: 40 loss: 0.2933814525604248\n",
      "epoch: 40 loss: 0.3692919611930847\n",
      "epoch: 40 loss: 0.3352121412754059\n",
      "epoch: 40 loss: 0.38847750425338745\n",
      "epoch: 40 loss: 0.3190253973007202\n",
      "epoch: 40 loss: 0.2289489507675171\n",
      "epoch: 40 loss: 0.45611658692359924\n",
      "epoch: 40 loss: 0.33165913820266724\n",
      "epoch: 40 loss: 0.2034677267074585\n",
      "epoch: 40 loss: 0.3103257119655609\n",
      "epoch: 40 loss: 0.30847352743148804\n",
      "epoch: 40 acc: 0.5520833333333334\n",
      "epoch: 41 loss: 0.3946917653083801\n",
      "epoch: 41 loss: 0.2803824543952942\n",
      "epoch: 41 loss: 0.2943941354751587\n",
      "epoch: 41 loss: 0.3526904881000519\n",
      "epoch: 41 loss: 0.32898882031440735\n",
      "epoch: 41 loss: 0.37864241003990173\n",
      "epoch: 41 loss: 0.31073197722435\n",
      "epoch: 41 loss: 0.2299564629793167\n",
      "epoch: 41 loss: 0.45259106159210205\n",
      "epoch: 41 loss: 0.32835012674331665\n",
      "epoch: 41 loss: 0.21394257247447968\n",
      "epoch: 41 loss: 0.3123842179775238\n",
      "epoch: 41 loss: 0.30089446902275085\n",
      "epoch: 41 acc: 0.5572916666666666\n",
      "epoch: 42 loss: 0.3775416314601898\n",
      "epoch: 42 loss: 0.27344003319740295\n",
      "epoch: 42 loss: 0.2891969084739685\n",
      "epoch: 42 loss: 0.3589811325073242\n",
      "epoch: 42 loss: 0.33625009655952454\n",
      "epoch: 42 loss: 0.37135323882102966\n",
      "epoch: 42 loss: 0.30282536149024963\n",
      "epoch: 42 loss: 0.22354446351528168\n",
      "epoch: 42 loss: 0.45321905612945557\n",
      "epoch: 42 loss: 0.3315204381942749\n",
      "epoch: 42 loss: 0.2091575264930725\n",
      "epoch: 42 loss: 0.31462931632995605\n",
      "epoch: 42 loss: 0.3033757209777832\n",
      "epoch: 42 acc: 0.5416666666666666\n",
      "epoch: 43 loss: 0.3756706118583679\n",
      "epoch: 43 loss: 0.28144460916519165\n",
      "epoch: 43 loss: 0.2923740744590759\n",
      "epoch: 43 loss: 0.3543660342693329\n",
      "epoch: 43 loss: 0.33395448327064514\n",
      "epoch: 43 loss: 0.3726597726345062\n",
      "epoch: 43 loss: 0.31517013907432556\n",
      "epoch: 43 loss: 0.22037824988365173\n",
      "epoch: 43 loss: 0.4543326497077942\n",
      "epoch: 43 loss: 0.33439967036247253\n",
      "epoch: 43 loss: 0.2114957720041275\n",
      "epoch: 43 loss: 0.313329815864563\n",
      "epoch: 43 loss: 0.3097602128982544\n",
      "epoch: 43 acc: 0.5520833333333334\n",
      "epoch: 44 loss: 0.36706191301345825\n",
      "epoch: 44 loss: 0.2731485962867737\n",
      "epoch: 44 loss: 0.28654393553733826\n",
      "epoch: 44 loss: 0.3681246042251587\n",
      "epoch: 44 loss: 0.3306232690811157\n",
      "epoch: 44 loss: 0.37210792303085327\n",
      "epoch: 44 loss: 0.29917070269584656\n",
      "epoch: 44 loss: 0.22727559506893158\n",
      "epoch: 44 loss: 0.45909011363983154\n",
      "epoch: 44 loss: 0.32427528500556946\n",
      "epoch: 44 loss: 0.20856699347496033\n",
      "epoch: 44 loss: 0.30279970169067383\n",
      "epoch: 44 loss: 0.2916836738586426\n",
      "epoch: 44 acc: 0.5625\n",
      "epoch: 45 loss: 0.37248992919921875\n",
      "epoch: 45 loss: 0.2814520299434662\n",
      "epoch: 45 loss: 0.29007384181022644\n",
      "epoch: 45 loss: 0.3600523769855499\n",
      "epoch: 45 loss: 0.3322306275367737\n",
      "epoch: 45 loss: 0.38196879625320435\n",
      "epoch: 45 loss: 0.30790767073631287\n",
      "epoch: 45 loss: 0.21807517111301422\n",
      "epoch: 45 loss: 0.45375439524650574\n",
      "epoch: 45 loss: 0.337112694978714\n",
      "epoch: 45 loss: 0.2121793031692505\n",
      "epoch: 45 loss: 0.31306618452072144\n",
      "epoch: 45 loss: 0.30682939291000366\n",
      "epoch: 45 acc: 0.5364583333333334\n",
      "epoch: 46 loss: 0.3693114221096039\n",
      "epoch: 46 loss: 0.28172367811203003\n",
      "epoch: 46 loss: 0.2900314927101135\n",
      "epoch: 46 loss: 0.3469727635383606\n",
      "epoch: 46 loss: 0.32553455233573914\n",
      "epoch: 46 loss: 0.36935603618621826\n",
      "epoch: 46 loss: 0.3146408200263977\n",
      "epoch: 46 loss: 0.22287923097610474\n",
      "epoch: 46 loss: 0.45472848415374756\n",
      "epoch: 46 loss: 0.3347781300544739\n",
      "epoch: 46 loss: 0.20872266590595245\n",
      "epoch: 46 loss: 0.3021620213985443\n",
      "epoch: 46 loss: 0.3043905198574066\n",
      "epoch: 46 acc: 0.5572916666666666\n",
      "epoch: 47 loss: 0.36122357845306396\n",
      "epoch: 47 loss: 0.2796408236026764\n",
      "epoch: 47 loss: 0.2887469232082367\n",
      "epoch: 47 loss: 0.35582858324050903\n",
      "epoch: 47 loss: 0.3359815180301666\n",
      "epoch: 47 loss: 0.38951659202575684\n",
      "epoch: 47 loss: 0.29523321986198425\n",
      "epoch: 47 loss: 0.222147136926651\n",
      "epoch: 47 loss: 0.45976579189300537\n",
      "epoch: 47 loss: 0.32085222005844116\n",
      "epoch: 47 loss: 0.21674153208732605\n",
      "epoch: 47 loss: 0.30285078287124634\n",
      "epoch: 47 loss: 0.2952693700790405\n",
      "epoch: 47 acc: 0.546875\n",
      "epoch: 48 loss: 0.36219799518585205\n",
      "epoch: 48 loss: 0.2696779668331146\n",
      "epoch: 48 loss: 0.27768445014953613\n",
      "epoch: 48 loss: 0.368209570646286\n",
      "epoch: 48 loss: 0.3319551646709442\n",
      "epoch: 48 loss: 0.37168997526168823\n",
      "epoch: 48 loss: 0.29712507128715515\n",
      "epoch: 48 loss: 0.21989226341247559\n",
      "epoch: 48 loss: 0.45692577958106995\n",
      "epoch: 48 loss: 0.3343409597873688\n",
      "epoch: 48 loss: 0.21205240488052368\n",
      "epoch: 48 loss: 0.304953396320343\n",
      "epoch: 48 loss: 0.29732316732406616\n",
      "epoch: 48 acc: 0.546875\n",
      "epoch: 49 loss: 0.358879029750824\n",
      "epoch: 49 loss: 0.28605449199676514\n",
      "epoch: 49 loss: 0.28995805978775024\n",
      "epoch: 49 loss: 0.3475438356399536\n",
      "epoch: 49 loss: 0.3266178369522095\n",
      "epoch: 49 loss: 0.3634099066257477\n",
      "epoch: 49 loss: 0.3057057559490204\n",
      "epoch: 49 loss: 0.22017532587051392\n",
      "epoch: 49 loss: 0.44963330030441284\n",
      "epoch: 49 loss: 0.33834096789360046\n",
      "epoch: 49 loss: 0.20526190102100372\n",
      "epoch: 49 loss: 0.3022068440914154\n",
      "epoch: 49 loss: 0.30537423491477966\n",
      "epoch: 49 acc: 0.5416666666666666\n",
      "epoch: 50 loss: 0.3551495671272278\n",
      "epoch: 50 loss: 0.270910382270813\n",
      "epoch: 50 loss: 0.2806067168712616\n",
      "epoch: 50 loss: 0.34523439407348633\n",
      "epoch: 50 loss: 0.3279832601547241\n",
      "epoch: 50 loss: 0.36697226762771606\n",
      "epoch: 50 loss: 0.29454052448272705\n",
      "epoch: 50 loss: 0.21980136632919312\n",
      "epoch: 50 loss: 0.4601905345916748\n",
      "epoch: 50 loss: 0.3357703387737274\n",
      "epoch: 50 loss: 0.21718434989452362\n",
      "epoch: 50 loss: 0.30971360206604004\n",
      "epoch: 50 loss: 0.29784172773361206\n",
      "epoch: 50 acc: 0.5625\n",
      "epoch: 51 loss: 0.33936113119125366\n",
      "epoch: 51 loss: 0.28517767786979675\n",
      "epoch: 51 loss: 0.2814599871635437\n",
      "epoch: 51 loss: 0.35259491205215454\n",
      "epoch: 51 loss: 0.31444209814071655\n",
      "epoch: 51 loss: 0.3561363220214844\n",
      "epoch: 51 loss: 0.3104831874370575\n",
      "epoch: 51 loss: 0.224142923951149\n",
      "epoch: 51 loss: 0.4529459476470947\n",
      "epoch: 51 loss: 0.34207066893577576\n",
      "epoch: 51 loss: 0.2020825743675232\n",
      "epoch: 51 loss: 0.29449206590652466\n",
      "epoch: 51 loss: 0.30389919877052307\n",
      "epoch: 51 acc: 0.5416666666666666\n",
      "epoch: 52 loss: 0.3544744849205017\n",
      "epoch: 52 loss: 0.27534565329551697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 52 loss: 0.2842666506767273\n",
      "epoch: 52 loss: 0.3404858112335205\n",
      "epoch: 52 loss: 0.3261762261390686\n",
      "epoch: 52 loss: 0.36585715413093567\n",
      "epoch: 52 loss: 0.29812178015708923\n",
      "epoch: 52 loss: 0.21981163322925568\n",
      "epoch: 52 loss: 0.46460163593292236\n",
      "epoch: 52 loss: 0.3308047950267792\n",
      "epoch: 52 loss: 0.2161634862422943\n",
      "epoch: 52 loss: 0.3041692078113556\n",
      "epoch: 52 loss: 0.2954905927181244\n",
      "epoch: 52 acc: 0.546875\n",
      "epoch: 53 loss: 0.33713972568511963\n",
      "epoch: 53 loss: 0.28063932061195374\n",
      "epoch: 53 loss: 0.2838468551635742\n",
      "epoch: 53 loss: 0.34798476099967957\n",
      "epoch: 53 loss: 0.3276677429676056\n",
      "epoch: 53 loss: 0.3691447377204895\n",
      "epoch: 53 loss: 0.30532845854759216\n",
      "epoch: 53 loss: 0.22020266950130463\n",
      "epoch: 53 loss: 0.45500612258911133\n",
      "epoch: 53 loss: 0.34198829531669617\n",
      "epoch: 53 loss: 0.20782962441444397\n",
      "epoch: 53 loss: 0.3027105927467346\n",
      "epoch: 53 loss: 0.30488717555999756\n",
      "epoch: 53 acc: 0.5572916666666666\n",
      "epoch: 54 loss: 0.34933555126190186\n",
      "epoch: 54 loss: 0.280878484249115\n",
      "epoch: 54 loss: 0.28081846237182617\n",
      "epoch: 54 loss: 0.34292158484458923\n",
      "epoch: 54 loss: 0.3192194402217865\n",
      "epoch: 54 loss: 0.36343303322792053\n",
      "epoch: 54 loss: 0.3007046580314636\n",
      "epoch: 54 loss: 0.22296953201293945\n",
      "epoch: 54 loss: 0.45504841208457947\n",
      "epoch: 54 loss: 0.33832114934921265\n",
      "epoch: 54 loss: 0.2098870575428009\n",
      "epoch: 54 loss: 0.29519617557525635\n",
      "epoch: 54 loss: 0.29961511492729187\n",
      "epoch: 54 acc: 0.53125\n",
      "epoch: 55 loss: 0.34024778008461\n",
      "epoch: 55 loss: 0.27303290367126465\n",
      "epoch: 55 loss: 0.28417882323265076\n",
      "epoch: 55 loss: 0.3447878062725067\n",
      "epoch: 55 loss: 0.33212384581565857\n",
      "epoch: 55 loss: 0.3728247880935669\n",
      "epoch: 55 loss: 0.29109621047973633\n",
      "epoch: 55 loss: 0.2196262925863266\n",
      "epoch: 55 loss: 0.4635993242263794\n",
      "epoch: 55 loss: 0.33259737491607666\n",
      "epoch: 55 loss: 0.2224947214126587\n",
      "epoch: 55 loss: 0.3108610510826111\n",
      "epoch: 55 loss: 0.2995550036430359\n",
      "epoch: 55 acc: 0.5572916666666666\n",
      "epoch: 56 loss: 0.3306875228881836\n",
      "epoch: 56 loss: 0.27983516454696655\n",
      "epoch: 56 loss: 0.28000208735466003\n",
      "epoch: 56 loss: 0.3473052382469177\n",
      "epoch: 56 loss: 0.31189996004104614\n",
      "epoch: 56 loss: 0.3402916491031647\n",
      "epoch: 56 loss: 0.31780341267585754\n",
      "epoch: 56 loss: 0.22388353943824768\n",
      "epoch: 56 loss: 0.4570188522338867\n",
      "epoch: 56 loss: 0.3480066955089569\n",
      "epoch: 56 loss: 0.20653045177459717\n",
      "epoch: 56 loss: 0.2988089919090271\n",
      "epoch: 56 loss: 0.30287545919418335\n",
      "epoch: 56 acc: 0.546875\n",
      "epoch: 57 loss: 0.3308907151222229\n",
      "epoch: 57 loss: 0.2812701165676117\n",
      "epoch: 57 loss: 0.28433072566986084\n",
      "epoch: 57 loss: 0.34622102975845337\n",
      "epoch: 57 loss: 0.31731554865837097\n",
      "epoch: 57 loss: 0.3639189302921295\n",
      "epoch: 57 loss: 0.29002243280410767\n",
      "epoch: 57 loss: 0.23106099665164948\n",
      "epoch: 57 loss: 0.4575713276863098\n",
      "epoch: 57 loss: 0.330325722694397\n",
      "epoch: 57 loss: 0.21521607041358948\n",
      "epoch: 57 loss: 0.29224148392677307\n",
      "epoch: 57 loss: 0.2905355989933014\n",
      "epoch: 57 acc: 0.546875\n",
      "epoch: 58 loss: 0.326290488243103\n",
      "epoch: 58 loss: 0.27163589000701904\n",
      "epoch: 58 loss: 0.2742294371128082\n",
      "epoch: 58 loss: 0.34224632382392883\n",
      "epoch: 58 loss: 0.322441965341568\n",
      "epoch: 58 loss: 0.3653011620044708\n",
      "epoch: 58 loss: 0.29887253046035767\n",
      "epoch: 58 loss: 0.22998110949993134\n",
      "epoch: 58 loss: 0.46599578857421875\n",
      "epoch: 58 loss: 0.35120558738708496\n",
      "epoch: 58 loss: 0.2190593183040619\n",
      "epoch: 58 loss: 0.31500253081321716\n",
      "epoch: 58 loss: 0.3018946051597595\n",
      "epoch: 58 acc: 0.5729166666666666\n",
      "epoch: 59 loss: 0.31910768151283264\n",
      "epoch: 59 loss: 0.28635528683662415\n",
      "epoch: 59 loss: 0.28637436032295227\n",
      "epoch: 59 loss: 0.35543420910835266\n",
      "epoch: 59 loss: 0.3309691846370697\n",
      "epoch: 59 loss: 0.3435976803302765\n",
      "epoch: 59 loss: 0.3274703919887543\n",
      "epoch: 59 loss: 0.22026701271533966\n",
      "epoch: 59 loss: 0.4637928307056427\n",
      "epoch: 59 loss: 0.34640759229660034\n",
      "epoch: 59 loss: 0.19864189624786377\n",
      "epoch: 59 loss: 0.3108607530593872\n",
      "epoch: 59 loss: 0.31073930859565735\n",
      "epoch: 59 acc: 0.5416666666666666\n",
      "epoch: 60 loss: 0.33720794320106506\n",
      "epoch: 60 loss: 0.28341853618621826\n",
      "epoch: 60 loss: 0.2904224395751953\n",
      "epoch: 60 loss: 0.3489026129245758\n",
      "epoch: 60 loss: 0.3275207579135895\n",
      "epoch: 60 loss: 0.374746173620224\n",
      "epoch: 60 loss: 0.2808612585067749\n",
      "epoch: 60 loss: 0.22054438292980194\n",
      "epoch: 60 loss: 0.4588029980659485\n",
      "epoch: 60 loss: 0.33158695697784424\n",
      "epoch: 60 loss: 0.22335466742515564\n",
      "epoch: 60 loss: 0.2836003303527832\n",
      "epoch: 60 loss: 0.29430878162384033\n",
      "epoch: 60 acc: 0.546875\n",
      "epoch: 61 loss: 0.33669179677963257\n",
      "epoch: 61 loss: 0.25814521312713623\n",
      "epoch: 61 loss: 0.27099359035491943\n",
      "epoch: 61 loss: 0.3605780601501465\n",
      "epoch: 61 loss: 0.3123970925807953\n",
      "epoch: 61 loss: 0.34858274459838867\n",
      "epoch: 61 loss: 0.28975963592529297\n",
      "epoch: 61 loss: 0.22633817791938782\n",
      "epoch: 61 loss: 0.46914365887641907\n",
      "epoch: 61 loss: 0.33735954761505127\n",
      "epoch: 61 loss: 0.22677814960479736\n",
      "epoch: 61 loss: 0.301072895526886\n",
      "epoch: 61 loss: 0.289931058883667\n",
      "epoch: 61 acc: 0.5677083333333334\n",
      "epoch: 62 loss: 0.31016188859939575\n",
      "epoch: 62 loss: 0.285767525434494\n",
      "epoch: 62 loss: 0.2834627032279968\n",
      "epoch: 62 loss: 0.34771451354026794\n",
      "epoch: 62 loss: 0.31665775179862976\n",
      "epoch: 62 loss: 0.3361269533634186\n",
      "epoch: 62 loss: 0.3152949810028076\n",
      "epoch: 62 loss: 0.22866898775100708\n",
      "epoch: 62 loss: 0.4643198549747467\n",
      "epoch: 62 loss: 0.35138580203056335\n",
      "epoch: 62 loss: 0.20058462023735046\n",
      "epoch: 62 loss: 0.3080221712589264\n",
      "epoch: 62 loss: 0.30651116371154785\n",
      "epoch: 62 acc: 0.5364583333333334\n",
      "epoch: 63 loss: 0.3259309232234955\n",
      "epoch: 63 loss: 0.28697097301483154\n",
      "epoch: 63 loss: 0.28834205865859985\n",
      "epoch: 63 loss: 0.3346604108810425\n",
      "epoch: 63 loss: 0.3303994834423065\n",
      "epoch: 63 loss: 0.3562382161617279\n",
      "epoch: 63 loss: 0.2859545350074768\n",
      "epoch: 63 loss: 0.2187240570783615\n",
      "epoch: 63 loss: 0.45699888467788696\n",
      "epoch: 63 loss: 0.3369338810443878\n",
      "epoch: 63 loss: 0.2148200273513794\n",
      "epoch: 63 loss: 0.28220149874687195\n",
      "epoch: 63 loss: 0.29108986258506775\n",
      "epoch: 63 acc: 0.5416666666666666\n",
      "epoch: 64 loss: 0.32743024826049805\n",
      "epoch: 64 loss: 0.2690805196762085\n",
      "epoch: 64 loss: 0.2783704996109009\n",
      "epoch: 64 loss: 0.35099077224731445\n",
      "epoch: 64 loss: 0.3103106617927551\n",
      "epoch: 64 loss: 0.36068984866142273\n",
      "epoch: 64 loss: 0.2870936989784241\n",
      "epoch: 64 loss: 0.2247348576784134\n",
      "epoch: 64 loss: 0.4668408930301666\n",
      "epoch: 64 loss: 0.34221380949020386\n",
      "epoch: 64 loss: 0.2273528277873993\n",
      "epoch: 64 loss: 0.29955172538757324\n",
      "epoch: 64 loss: 0.29321712255477905\n",
      "epoch: 64 acc: 0.5572916666666666\n",
      "epoch: 65 loss: 0.31175047159194946\n",
      "epoch: 65 loss: 0.2877958118915558\n",
      "epoch: 65 loss: 0.2826507091522217\n",
      "epoch: 65 loss: 0.33588287234306335\n",
      "epoch: 65 loss: 0.31265226006507874\n",
      "epoch: 65 loss: 0.33260664343833923\n",
      "epoch: 65 loss: 0.3064371347427368\n",
      "epoch: 65 loss: 0.22317343950271606\n",
      "epoch: 65 loss: 0.4626752436161041\n",
      "epoch: 65 loss: 0.356173574924469\n",
      "epoch: 65 loss: 0.20324286818504333\n",
      "epoch: 65 loss: 0.29283779859542847\n",
      "epoch: 65 loss: 0.2977760136127472\n",
      "epoch: 65 acc: 0.546875\n",
      "epoch: 66 loss: 0.31492891907691956\n",
      "epoch: 66 loss: 0.28610455989837646\n",
      "epoch: 66 loss: 0.2878209054470062\n",
      "epoch: 66 loss: 0.3331555128097534\n",
      "epoch: 66 loss: 0.32833078503608704\n",
      "epoch: 66 loss: 0.37150031328201294\n",
      "epoch: 66 loss: 0.28777703642845154\n",
      "epoch: 66 loss: 0.21501168608665466\n",
      "epoch: 66 loss: 0.4607381224632263\n",
      "epoch: 66 loss: 0.3407976031303406\n",
      "epoch: 66 loss: 0.21509048342704773\n",
      "epoch: 66 loss: 0.2952430546283722\n",
      "epoch: 66 loss: 0.29810500144958496\n",
      "epoch: 66 acc: 0.5416666666666666\n",
      "epoch: 67 loss: 0.3211327791213989\n",
      "epoch: 67 loss: 0.27616795897483826\n",
      "epoch: 67 loss: 0.27597638964653015\n",
      "epoch: 67 loss: 0.3418218791484833\n",
      "epoch: 67 loss: 0.3070424199104309\n",
      "epoch: 67 loss: 0.3340734839439392\n",
      "epoch: 67 loss: 0.2966534197330475\n",
      "epoch: 67 loss: 0.222615048289299\n",
      "epoch: 67 loss: 0.4658553898334503\n",
      "epoch: 67 loss: 0.3468003571033478\n",
      "epoch: 67 loss: 0.21984846889972687\n",
      "epoch: 67 loss: 0.28479108214378357\n",
      "epoch: 67 loss: 0.28298041224479675\n",
      "epoch: 67 acc: 0.5833333333333334\n",
      "epoch: 68 loss: 0.30312618613243103\n",
      "epoch: 68 loss: 0.28865763545036316\n",
      "epoch: 68 loss: 0.2836625874042511\n",
      "epoch: 68 loss: 0.35844656825065613\n",
      "epoch: 68 loss: 0.31408822536468506\n",
      "epoch: 68 loss: 0.35984188318252563\n",
      "epoch: 68 loss: 0.2909029722213745\n",
      "epoch: 68 loss: 0.2241121530532837\n",
      "epoch: 68 loss: 0.4657272696495056\n",
      "epoch: 68 loss: 0.34624049067497253\n",
      "epoch: 68 loss: 0.2052403837442398\n",
      "epoch: 68 loss: 0.2991422116756439\n",
      "epoch: 68 loss: 0.2917633056640625\n",
      "epoch: 68 acc: 0.5416666666666666\n",
      "epoch: 69 loss: 0.3152763247489929\n",
      "epoch: 69 loss: 0.2836417555809021\n",
      "epoch: 69 loss: 0.285616397857666\n",
      "epoch: 69 loss: 0.3328474164009094\n",
      "epoch: 69 loss: 0.32454830408096313\n",
      "epoch: 69 loss: 0.34859493374824524\n",
      "epoch: 69 loss: 0.2909027636051178\n",
      "epoch: 69 loss: 0.2195223867893219\n",
      "epoch: 69 loss: 0.4590790867805481\n",
      "epoch: 69 loss: 0.35651567578315735\n",
      "epoch: 69 loss: 0.20934587717056274\n",
      "epoch: 69 loss: 0.28925684094429016\n",
      "epoch: 69 loss: 0.29689478874206543\n",
      "epoch: 69 acc: 0.546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 70 loss: 0.31276506185531616\n",
      "epoch: 70 loss: 0.28905051946640015\n",
      "epoch: 70 loss: 0.284274697303772\n",
      "epoch: 70 loss: 0.3273395299911499\n",
      "epoch: 70 loss: 0.32261723279953003\n",
      "epoch: 70 loss: 0.35834577679634094\n",
      "epoch: 70 loss: 0.2924129068851471\n",
      "epoch: 70 loss: 0.22260917723178864\n",
      "epoch: 70 loss: 0.4609816074371338\n",
      "epoch: 70 loss: 0.34583449363708496\n",
      "epoch: 70 loss: 0.2110205739736557\n",
      "epoch: 70 loss: 0.2859140932559967\n",
      "epoch: 70 loss: 0.2954082489013672\n",
      "epoch: 70 acc: 0.5416666666666666\n",
      "epoch: 71 loss: 0.320983350276947\n",
      "epoch: 71 loss: 0.2792871594429016\n",
      "epoch: 71 loss: 0.28169694542884827\n",
      "epoch: 71 loss: 0.3424092233181\n",
      "epoch: 71 loss: 0.3147197365760803\n",
      "epoch: 71 loss: 0.3414901793003082\n",
      "epoch: 71 loss: 0.2862316370010376\n",
      "epoch: 71 loss: 0.21666216850280762\n",
      "epoch: 71 loss: 0.4655066132545471\n",
      "epoch: 71 loss: 0.3466825783252716\n",
      "epoch: 71 loss: 0.2142067402601242\n",
      "epoch: 71 loss: 0.28912246227264404\n",
      "epoch: 71 loss: 0.2896598279476166\n",
      "epoch: 71 acc: 0.5625\n",
      "epoch: 72 loss: 0.3116806745529175\n",
      "epoch: 72 loss: 0.2873449921607971\n",
      "epoch: 72 loss: 0.28132081031799316\n",
      "epoch: 72 loss: 0.33745500445365906\n",
      "epoch: 72 loss: 0.307587206363678\n",
      "epoch: 72 loss: 0.341788649559021\n",
      "epoch: 72 loss: 0.28984004259109497\n",
      "epoch: 72 loss: 0.21982967853546143\n",
      "epoch: 72 loss: 0.46223047375679016\n",
      "epoch: 72 loss: 0.3626226484775543\n",
      "epoch: 72 loss: 0.2032555788755417\n",
      "epoch: 72 loss: 0.2888786494731903\n",
      "epoch: 72 loss: 0.2931100130081177\n",
      "epoch: 72 acc: 0.546875\n",
      "epoch: 73 loss: 0.3091915547847748\n",
      "epoch: 73 loss: 0.2933937907218933\n",
      "epoch: 73 loss: 0.2905649244785309\n",
      "epoch: 73 loss: 0.32162773609161377\n",
      "epoch: 73 loss: 0.3148750364780426\n",
      "epoch: 73 loss: 0.3456119894981384\n",
      "epoch: 73 loss: 0.28527289628982544\n",
      "epoch: 73 loss: 0.22022214531898499\n",
      "epoch: 73 loss: 0.45885440707206726\n",
      "epoch: 73 loss: 0.3584187626838684\n",
      "epoch: 73 loss: 0.2055239975452423\n",
      "epoch: 73 loss: 0.29179930686950684\n",
      "epoch: 73 loss: 0.29824215173721313\n",
      "epoch: 73 acc: 0.5364583333333334\n",
      "epoch: 74 loss: 0.31078481674194336\n",
      "epoch: 74 loss: 0.27661558985710144\n",
      "epoch: 74 loss: 0.27542972564697266\n",
      "epoch: 74 loss: 0.33014973998069763\n",
      "epoch: 74 loss: 0.31747961044311523\n",
      "epoch: 74 loss: 0.3366062045097351\n",
      "epoch: 74 loss: 0.2927502691745758\n",
      "epoch: 74 loss: 0.22065769135951996\n",
      "epoch: 74 loss: 0.46563905477523804\n",
      "epoch: 74 loss: 0.35378554463386536\n",
      "epoch: 74 loss: 0.2082822471857071\n",
      "epoch: 74 loss: 0.28946453332901\n",
      "epoch: 74 loss: 0.29117947816848755\n",
      "epoch: 74 acc: 0.5572916666666666\n",
      "epoch: 75 loss: 0.3153035640716553\n",
      "epoch: 75 loss: 0.29827943444252014\n",
      "epoch: 75 loss: 0.2902449369430542\n",
      "epoch: 75 loss: 0.3328136205673218\n",
      "epoch: 75 loss: 0.3074488937854767\n",
      "epoch: 75 loss: 0.34464430809020996\n",
      "epoch: 75 loss: 0.30132153630256653\n",
      "epoch: 75 loss: 0.22044935822486877\n",
      "epoch: 75 loss: 0.4653168320655823\n",
      "epoch: 75 loss: 0.36177167296409607\n",
      "epoch: 75 loss: 0.20871493220329285\n",
      "epoch: 75 loss: 0.28688523173332214\n",
      "epoch: 75 loss: 0.29519400000572205\n",
      "epoch: 75 acc: 0.5260416666666666\n",
      "epoch: 76 loss: 0.31256091594696045\n",
      "epoch: 76 loss: 0.28560757637023926\n",
      "epoch: 76 loss: 0.286862313747406\n",
      "epoch: 76 loss: 0.32818111777305603\n",
      "epoch: 76 loss: 0.3167574107646942\n",
      "epoch: 76 loss: 0.350650429725647\n",
      "epoch: 76 loss: 0.2798963785171509\n",
      "epoch: 76 loss: 0.22527672350406647\n",
      "epoch: 76 loss: 0.46133214235305786\n",
      "epoch: 76 loss: 0.345915824174881\n",
      "epoch: 76 loss: 0.21583706140518188\n",
      "epoch: 76 loss: 0.29100048542022705\n",
      "epoch: 76 loss: 0.29162323474884033\n",
      "epoch: 76 acc: 0.546875\n",
      "epoch: 77 loss: 0.3054046332836151\n",
      "epoch: 77 loss: 0.28050893545150757\n",
      "epoch: 77 loss: 0.27659809589385986\n",
      "epoch: 77 loss: 0.346285343170166\n",
      "epoch: 77 loss: 0.3100990355014801\n",
      "epoch: 77 loss: 0.32732224464416504\n",
      "epoch: 77 loss: 0.29202184081077576\n",
      "epoch: 77 loss: 0.2215351164340973\n",
      "epoch: 77 loss: 0.47010934352874756\n",
      "epoch: 77 loss: 0.351256787776947\n",
      "epoch: 77 loss: 0.2118152230978012\n",
      "epoch: 77 loss: 0.27538150548934937\n",
      "epoch: 77 loss: 0.2806321382522583\n",
      "epoch: 77 acc: 0.5625\n",
      "epoch: 78 loss: 0.30169424414634705\n",
      "epoch: 78 loss: 0.2946454882621765\n",
      "epoch: 78 loss: 0.2902168333530426\n",
      "epoch: 78 loss: 0.3375908434391022\n",
      "epoch: 78 loss: 0.31094542145729065\n",
      "epoch: 78 loss: 0.3536073565483093\n",
      "epoch: 78 loss: 0.2907106876373291\n",
      "epoch: 78 loss: 0.22317638993263245\n",
      "epoch: 78 loss: 0.4634188115596771\n",
      "epoch: 78 loss: 0.3578069806098938\n",
      "epoch: 78 loss: 0.20771637558937073\n",
      "epoch: 78 loss: 0.29469457268714905\n",
      "epoch: 78 loss: 0.2946624457836151\n",
      "epoch: 78 acc: 0.546875\n",
      "epoch: 79 loss: 0.3071056604385376\n",
      "epoch: 79 loss: 0.2801245450973511\n",
      "epoch: 79 loss: 0.28220176696777344\n",
      "epoch: 79 loss: 0.3317878246307373\n",
      "epoch: 79 loss: 0.3123946487903595\n",
      "epoch: 79 loss: 0.32614219188690186\n",
      "epoch: 79 loss: 0.28621912002563477\n",
      "epoch: 79 loss: 0.2221175730228424\n",
      "epoch: 79 loss: 0.46073150634765625\n",
      "epoch: 79 loss: 0.3610215485095978\n",
      "epoch: 79 loss: 0.20919673144817352\n",
      "epoch: 79 loss: 0.2857277989387512\n",
      "epoch: 79 loss: 0.2876257002353668\n",
      "epoch: 79 acc: 0.5677083333333334\n",
      "epoch: 80 loss: 0.296492338180542\n",
      "epoch: 80 loss: 0.29412832856178284\n",
      "epoch: 80 loss: 0.2836742103099823\n",
      "epoch: 80 loss: 0.34288010001182556\n",
      "epoch: 80 loss: 0.3160552978515625\n",
      "epoch: 80 loss: 0.3517054319381714\n",
      "epoch: 80 loss: 0.2936917543411255\n",
      "epoch: 80 loss: 0.21727682650089264\n",
      "epoch: 80 loss: 0.4615757167339325\n",
      "epoch: 80 loss: 0.36244404315948486\n",
      "epoch: 80 loss: 0.19343045353889465\n",
      "epoch: 80 loss: 0.2903132736682892\n",
      "epoch: 80 loss: 0.29918038845062256\n",
      "epoch: 80 acc: 0.5520833333333334\n",
      "epoch: 81 loss: 0.3211321234703064\n",
      "epoch: 81 loss: 0.2887731194496155\n",
      "epoch: 81 loss: 0.2893812954425812\n",
      "epoch: 81 loss: 0.32593902945518494\n",
      "epoch: 81 loss: 0.316708505153656\n",
      "epoch: 81 loss: 0.3431555926799774\n",
      "epoch: 81 loss: 0.28511184453964233\n",
      "epoch: 81 loss: 0.21626593172550201\n",
      "epoch: 81 loss: 0.46174079179763794\n",
      "epoch: 81 loss: 0.35459640622138977\n",
      "epoch: 81 loss: 0.2178596705198288\n",
      "epoch: 81 loss: 0.2805226743221283\n",
      "epoch: 81 loss: 0.28510308265686035\n",
      "epoch: 81 acc: 0.5677083333333334\n",
      "epoch: 82 loss: 0.2999555468559265\n",
      "epoch: 82 loss: 0.29138410091400146\n",
      "epoch: 82 loss: 0.28462788462638855\n",
      "epoch: 82 loss: 0.3355051577091217\n",
      "epoch: 82 loss: 0.3062793016433716\n",
      "epoch: 82 loss: 0.34405651688575745\n",
      "epoch: 82 loss: 0.2834247052669525\n",
      "epoch: 82 loss: 0.21674089133739471\n",
      "epoch: 82 loss: 0.46769246459007263\n",
      "epoch: 82 loss: 0.35911649465560913\n",
      "epoch: 82 loss: 0.20744240283966064\n",
      "epoch: 82 loss: 0.2836148142814636\n",
      "epoch: 82 loss: 0.2891819477081299\n",
      "epoch: 82 acc: 0.546875\n",
      "epoch: 83 loss: 0.3016256093978882\n",
      "epoch: 83 loss: 0.2851324677467346\n",
      "epoch: 83 loss: 0.28154119849205017\n",
      "epoch: 83 loss: 0.33726146817207336\n",
      "epoch: 83 loss: 0.3088126480579376\n",
      "epoch: 83 loss: 0.320081502199173\n",
      "epoch: 83 loss: 0.28628697991371155\n",
      "epoch: 83 loss: 0.2154780626296997\n",
      "epoch: 83 loss: 0.4592945873737335\n",
      "epoch: 83 loss: 0.35460183024406433\n",
      "epoch: 83 loss: 0.20176054537296295\n",
      "epoch: 83 loss: 0.28105980157852173\n",
      "epoch: 83 loss: 0.28340184688568115\n",
      "epoch: 83 acc: 0.5572916666666666\n",
      "epoch: 84 loss: 0.3051456809043884\n",
      "epoch: 84 loss: 0.28953972458839417\n",
      "epoch: 84 loss: 0.2909086346626282\n",
      "epoch: 84 loss: 0.332444965839386\n",
      "epoch: 84 loss: 0.3086000680923462\n",
      "epoch: 84 loss: 0.34873831272125244\n",
      "epoch: 84 loss: 0.28976982831954956\n",
      "epoch: 84 loss: 0.2157374918460846\n",
      "epoch: 84 loss: 0.4675808548927307\n",
      "epoch: 84 loss: 0.36955276131629944\n",
      "epoch: 84 loss: 0.2087855041027069\n",
      "epoch: 84 loss: 0.29427576065063477\n",
      "epoch: 84 loss: 0.2947874069213867\n",
      "epoch: 84 acc: 0.5364583333333334\n",
      "epoch: 85 loss: 0.3028763234615326\n",
      "epoch: 85 loss: 0.29981499910354614\n",
      "epoch: 85 loss: 0.2891913056373596\n",
      "epoch: 85 loss: 0.3294033408164978\n",
      "epoch: 85 loss: 0.3060542345046997\n",
      "epoch: 85 loss: 0.3209722936153412\n",
      "epoch: 85 loss: 0.28308215737342834\n",
      "epoch: 85 loss: 0.21361251175403595\n",
      "epoch: 85 loss: 0.46157222986221313\n",
      "epoch: 85 loss: 0.3608412444591522\n",
      "epoch: 85 loss: 0.20654667913913727\n",
      "epoch: 85 loss: 0.2691493332386017\n",
      "epoch: 85 loss: 0.2766660153865814\n",
      "epoch: 85 acc: 0.546875\n",
      "epoch: 86 loss: 0.3013512194156647\n",
      "epoch: 86 loss: 0.28252577781677246\n",
      "epoch: 86 loss: 0.28623613715171814\n",
      "epoch: 86 loss: 0.33576709032058716\n",
      "epoch: 86 loss: 0.3094267249107361\n",
      "epoch: 86 loss: 0.34935712814331055\n",
      "epoch: 86 loss: 0.2775140404701233\n",
      "epoch: 86 loss: 0.22435157001018524\n",
      "epoch: 86 loss: 0.4556141495704651\n",
      "epoch: 86 loss: 0.34943342208862305\n",
      "epoch: 86 loss: 0.20319747924804688\n",
      "epoch: 86 loss: 0.28947991132736206\n",
      "epoch: 86 loss: 0.29580479860305786\n",
      "epoch: 86 acc: 0.5520833333333334\n",
      "epoch: 87 loss: 0.31278306245803833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 87 loss: 0.27540576457977295\n",
      "epoch: 87 loss: 0.27867990732192993\n",
      "epoch: 87 loss: 0.3293036222457886\n",
      "epoch: 87 loss: 0.31175240874290466\n",
      "epoch: 87 loss: 0.31395795941352844\n",
      "epoch: 87 loss: 0.3050829768180847\n",
      "epoch: 87 loss: 0.21745391190052032\n",
      "epoch: 87 loss: 0.4672733545303345\n",
      "epoch: 87 loss: 0.3641594648361206\n",
      "epoch: 87 loss: 0.2147473394870758\n",
      "epoch: 87 loss: 0.2936844229698181\n",
      "epoch: 87 loss: 0.2906985580921173\n",
      "epoch: 87 acc: 0.5729166666666666\n",
      "epoch: 88 loss: 0.2952703535556793\n",
      "epoch: 88 loss: 0.31008484959602356\n",
      "epoch: 88 loss: 0.2919905185699463\n",
      "epoch: 88 loss: 0.3437548875808716\n",
      "epoch: 88 loss: 0.3061550259590149\n",
      "epoch: 88 loss: 0.34417852759361267\n",
      "epoch: 88 loss: 0.293719619512558\n",
      "epoch: 88 loss: 0.2151535302400589\n",
      "epoch: 88 loss: 0.46384197473526\n",
      "epoch: 88 loss: 0.37002986669540405\n",
      "epoch: 88 loss: 0.19773487746715546\n",
      "epoch: 88 loss: 0.2806489169597626\n",
      "epoch: 88 loss: 0.2962556779384613\n",
      "epoch: 88 acc: 0.5364583333333334\n",
      "epoch: 89 loss: 0.30980202555656433\n",
      "epoch: 89 loss: 0.28601962327957153\n",
      "epoch: 89 loss: 0.28476715087890625\n",
      "epoch: 89 loss: 0.3217390179634094\n",
      "epoch: 89 loss: 0.31077855825424194\n",
      "epoch: 89 loss: 0.3286237418651581\n",
      "epoch: 89 loss: 0.2764846682548523\n",
      "epoch: 89 loss: 0.22219829261302948\n",
      "epoch: 89 loss: 0.4512479603290558\n",
      "epoch: 89 loss: 0.35472729802131653\n",
      "epoch: 89 loss: 0.2036883533000946\n",
      "epoch: 89 loss: 0.27955231070518494\n",
      "epoch: 89 loss: 0.2883564531803131\n",
      "epoch: 89 acc: 0.5416666666666666\n",
      "epoch: 90 loss: 0.3022162914276123\n",
      "epoch: 90 loss: 0.2745015621185303\n",
      "epoch: 90 loss: 0.2754327356815338\n",
      "epoch: 90 loss: 0.3318415880203247\n",
      "epoch: 90 loss: 0.30655723810195923\n",
      "epoch: 90 loss: 0.33015498518943787\n",
      "epoch: 90 loss: 0.29189515113830566\n",
      "epoch: 90 loss: 0.22064562141895294\n",
      "epoch: 90 loss: 0.4640897810459137\n",
      "epoch: 90 loss: 0.35831841826438904\n",
      "epoch: 90 loss: 0.20272089540958405\n",
      "epoch: 90 loss: 0.29053089022636414\n",
      "epoch: 90 loss: 0.29687461256980896\n",
      "epoch: 90 acc: 0.546875\n",
      "epoch: 91 loss: 0.3117843270301819\n",
      "epoch: 91 loss: 0.2984444499015808\n",
      "epoch: 91 loss: 0.28795188665390015\n",
      "epoch: 91 loss: 0.3296767473220825\n",
      "epoch: 91 loss: 0.3065440058708191\n",
      "epoch: 91 loss: 0.3153325021266937\n",
      "epoch: 91 loss: 0.30023789405822754\n",
      "epoch: 91 loss: 0.21600909531116486\n",
      "epoch: 91 loss: 0.46679410338401794\n",
      "epoch: 91 loss: 0.36209478974342346\n",
      "epoch: 91 loss: 0.2042750120162964\n",
      "epoch: 91 loss: 0.27540868520736694\n",
      "epoch: 91 loss: 0.28492701053619385\n",
      "epoch: 91 acc: 0.5416666666666666\n",
      "epoch: 92 loss: 0.29482245445251465\n",
      "epoch: 92 loss: 0.29508715867996216\n",
      "epoch: 92 loss: 0.29030540585517883\n",
      "epoch: 92 loss: 0.32618656754493713\n",
      "epoch: 92 loss: 0.29928073287010193\n",
      "epoch: 92 loss: 0.33382418751716614\n",
      "epoch: 92 loss: 0.2759034037590027\n",
      "epoch: 92 loss: 0.22193825244903564\n",
      "epoch: 92 loss: 0.45615431666374207\n",
      "epoch: 92 loss: 0.3523447513580322\n",
      "epoch: 92 loss: 0.20671266317367554\n",
      "epoch: 92 loss: 0.28070932626724243\n",
      "epoch: 92 loss: 0.2882257401943207\n",
      "epoch: 92 acc: 0.5416666666666666\n",
      "epoch: 93 loss: 0.3013591766357422\n",
      "epoch: 93 loss: 0.27071571350097656\n",
      "epoch: 93 loss: 0.27450913190841675\n",
      "epoch: 93 loss: 0.3306715786457062\n",
      "epoch: 93 loss: 0.3027040660381317\n",
      "epoch: 93 loss: 0.31073325872421265\n",
      "epoch: 93 loss: 0.2853912115097046\n",
      "epoch: 93 loss: 0.22332927584648132\n",
      "epoch: 93 loss: 0.4602537751197815\n",
      "epoch: 93 loss: 0.3543199300765991\n",
      "epoch: 93 loss: 0.20319348573684692\n",
      "epoch: 93 loss: 0.2779654264450073\n",
      "epoch: 93 loss: 0.2822510004043579\n",
      "epoch: 93 acc: 0.5625\n",
      "epoch: 94 loss: 0.2962161600589752\n",
      "epoch: 94 loss: 0.29816097021102905\n",
      "epoch: 94 loss: 0.28927353024482727\n",
      "epoch: 94 loss: 0.3292049169540405\n",
      "epoch: 94 loss: 0.3001202940940857\n",
      "epoch: 94 loss: 0.33543726801872253\n",
      "epoch: 94 loss: 0.29321232438087463\n",
      "epoch: 94 loss: 0.2136029601097107\n",
      "epoch: 94 loss: 0.4707605540752411\n",
      "epoch: 94 loss: 0.37212762236595154\n",
      "epoch: 94 loss: 0.20085734128952026\n",
      "epoch: 94 loss: 0.288818895816803\n",
      "epoch: 94 loss: 0.29604578018188477\n",
      "epoch: 94 acc: 0.546875\n",
      "epoch: 95 loss: 0.2981864809989929\n",
      "epoch: 95 loss: 0.29852455854415894\n",
      "epoch: 95 loss: 0.288608193397522\n",
      "epoch: 95 loss: 0.31701886653900146\n",
      "epoch: 95 loss: 0.30277854204177856\n",
      "epoch: 95 loss: 0.30839765071868896\n",
      "epoch: 95 loss: 0.2806202471256256\n",
      "epoch: 95 loss: 0.2233477681875229\n",
      "epoch: 95 loss: 0.44951772689819336\n",
      "epoch: 95 loss: 0.35465630888938904\n",
      "epoch: 95 loss: 0.19974124431610107\n",
      "epoch: 95 loss: 0.26717501878738403\n",
      "epoch: 95 loss: 0.27935346961021423\n",
      "epoch: 95 acc: 0.546875\n",
      "epoch: 96 loss: 0.29952913522720337\n",
      "epoch: 96 loss: 0.27674025297164917\n",
      "epoch: 96 loss: 0.27939465641975403\n",
      "epoch: 96 loss: 0.3305525779724121\n",
      "epoch: 96 loss: 0.3036400377750397\n",
      "epoch: 96 loss: 0.3350057899951935\n",
      "epoch: 96 loss: 0.28170037269592285\n",
      "epoch: 96 loss: 0.2237464040517807\n",
      "epoch: 96 loss: 0.45416057109832764\n",
      "epoch: 96 loss: 0.34944674372673035\n",
      "epoch: 96 loss: 0.20141059160232544\n",
      "epoch: 96 loss: 0.28345346450805664\n",
      "epoch: 96 loss: 0.2935955226421356\n",
      "epoch: 96 acc: 0.5364583333333334\n",
      "epoch: 97 loss: 0.30645066499710083\n",
      "epoch: 97 loss: 0.28690460324287415\n",
      "epoch: 97 loss: 0.28420692682266235\n",
      "epoch: 97 loss: 0.32321786880493164\n",
      "epoch: 97 loss: 0.29920580983161926\n",
      "epoch: 97 loss: 0.30464375019073486\n",
      "epoch: 97 loss: 0.30038559436798096\n",
      "epoch: 97 loss: 0.22252148389816284\n",
      "epoch: 97 loss: 0.4629509449005127\n",
      "epoch: 97 loss: 0.3597794473171234\n",
      "epoch: 97 loss: 0.20626474916934967\n",
      "epoch: 97 loss: 0.2776362895965576\n",
      "epoch: 97 loss: 0.2829864025115967\n",
      "epoch: 97 acc: 0.5520833333333334\n",
      "epoch: 98 loss: 0.2869451940059662\n",
      "epoch: 98 loss: 0.30435267090797424\n",
      "epoch: 98 loss: 0.28730690479278564\n",
      "epoch: 98 loss: 0.3286478519439697\n",
      "epoch: 98 loss: 0.29992979764938354\n",
      "epoch: 98 loss: 0.336973637342453\n",
      "epoch: 98 loss: 0.27650874853134155\n",
      "epoch: 98 loss: 0.21264055371284485\n",
      "epoch: 98 loss: 0.46049001812934875\n",
      "epoch: 98 loss: 0.36132609844207764\n",
      "epoch: 98 loss: 0.19702130556106567\n",
      "epoch: 98 loss: 0.2777544856071472\n",
      "epoch: 98 loss: 0.2902093827724457\n",
      "epoch: 98 acc: 0.5260416666666666\n",
      "epoch: 99 loss: 0.3024020195007324\n",
      "epoch: 99 loss: 0.2796388268470764\n",
      "epoch: 99 loss: 0.2805916666984558\n",
      "epoch: 99 loss: 0.3215818703174591\n",
      "epoch: 99 loss: 0.30443263053894043\n",
      "epoch: 99 loss: 0.31673553586006165\n",
      "epoch: 99 loss: 0.26992926001548767\n",
      "epoch: 99 loss: 0.22707617282867432\n",
      "epoch: 99 loss: 0.4506739377975464\n",
      "epoch: 99 loss: 0.3509548604488373\n",
      "epoch: 99 loss: 0.20474250614643097\n",
      "epoch: 99 loss: 0.26734721660614014\n",
      "epoch: 99 loss: 0.2768038511276245\n",
      "epoch: 99 acc: 0.546875\n",
      "epoch: 100 loss: 0.29149383306503296\n",
      "epoch: 100 loss: 0.2926509976387024\n",
      "epoch: 100 loss: 0.2842693328857422\n",
      "epoch: 100 loss: 0.3278005123138428\n",
      "epoch: 100 loss: 0.30141860246658325\n",
      "epoch: 100 loss: 0.3231621980667114\n",
      "epoch: 100 loss: 0.28883254528045654\n",
      "epoch: 100 loss: 0.21832872927188873\n",
      "epoch: 100 loss: 0.4673628509044647\n",
      "epoch: 100 loss: 0.36484232544898987\n",
      "epoch: 100 loss: 0.19382841885089874\n",
      "epoch: 100 loss: 0.2870267927646637\n",
      "epoch: 100 loss: 0.2936995029449463\n",
      "epoch: 100 acc: 0.546875\n",
      "epoch: 101 loss: 0.3043568432331085\n",
      "epoch: 101 loss: 0.2984673082828522\n",
      "epoch: 101 loss: 0.2927013039588928\n",
      "epoch: 101 loss: 0.32024139165878296\n",
      "epoch: 101 loss: 0.30746421217918396\n",
      "epoch: 101 loss: 0.32235491275787354\n",
      "epoch: 101 loss: 0.2842322587966919\n",
      "epoch: 101 loss: 0.2163885235786438\n",
      "epoch: 101 loss: 0.45631158351898193\n",
      "epoch: 101 loss: 0.36195996403694153\n",
      "epoch: 101 loss: 0.2058660238981247\n",
      "epoch: 101 loss: 0.2707601487636566\n",
      "epoch: 101 loss: 0.2823747992515564\n",
      "epoch: 101 acc: 0.53125\n",
      "epoch: 102 loss: 0.2904449701309204\n",
      "epoch: 102 loss: 0.29481202363967896\n",
      "epoch: 102 loss: 0.28686052560806274\n",
      "epoch: 102 loss: 0.32291916012763977\n",
      "epoch: 102 loss: 0.30223169922828674\n",
      "epoch: 102 loss: 0.3337878882884979\n",
      "epoch: 102 loss: 0.27139562368392944\n",
      "epoch: 102 loss: 0.21535083651542664\n",
      "epoch: 102 loss: 0.45708167552948\n",
      "epoch: 102 loss: 0.35791757702827454\n",
      "epoch: 102 loss: 0.1951620727777481\n",
      "epoch: 102 loss: 0.27409666776657104\n",
      "epoch: 102 loss: 0.28791263699531555\n",
      "epoch: 102 acc: 0.5208333333333334\n",
      "epoch: 103 loss: 0.3015780746936798\n",
      "epoch: 103 loss: 0.278779000043869\n",
      "epoch: 103 loss: 0.278003066778183\n",
      "epoch: 103 loss: 0.3264158368110657\n",
      "epoch: 103 loss: 0.306409627199173\n",
      "epoch: 103 loss: 0.3117038607597351\n",
      "epoch: 103 loss: 0.2753479480743408\n",
      "epoch: 103 loss: 0.22218388319015503\n",
      "epoch: 103 loss: 0.45337021350860596\n",
      "epoch: 103 loss: 0.35328933596611023\n",
      "epoch: 103 loss: 0.2034432590007782\n",
      "epoch: 103 loss: 0.2738896906375885\n",
      "epoch: 103 loss: 0.28087058663368225\n",
      "epoch: 103 acc: 0.5572916666666666\n",
      "epoch: 104 loss: 0.29188042879104614\n",
      "epoch: 104 loss: 0.29999303817749023\n",
      "epoch: 104 loss: 0.29109591245651245\n",
      "epoch: 104 loss: 0.32430335879325867\n",
      "epoch: 104 loss: 0.2980845272541046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 104 loss: 0.3286285996437073\n",
      "epoch: 104 loss: 0.27944719791412354\n",
      "epoch: 104 loss: 0.21430134773254395\n",
      "epoch: 104 loss: 0.4673571288585663\n",
      "epoch: 104 loss: 0.374843567609787\n",
      "epoch: 104 loss: 0.1958484947681427\n",
      "epoch: 104 loss: 0.27636635303497314\n",
      "epoch: 104 loss: 0.2878018319606781\n",
      "epoch: 104 acc: 0.5260416666666666\n",
      "epoch: 105 loss: 0.2927849292755127\n",
      "epoch: 105 loss: 0.2935432195663452\n",
      "epoch: 105 loss: 0.285393625497818\n",
      "epoch: 105 loss: 0.3167695105075836\n",
      "epoch: 105 loss: 0.30038514733314514\n",
      "epoch: 105 loss: 0.31354600191116333\n",
      "epoch: 105 loss: 0.26919910311698914\n",
      "epoch: 105 loss: 0.21744737029075623\n",
      "epoch: 105 loss: 0.4532620310783386\n",
      "epoch: 105 loss: 0.36428770422935486\n",
      "epoch: 105 loss: 0.19620048999786377\n",
      "epoch: 105 loss: 0.27129510045051575\n",
      "epoch: 105 loss: 0.280180960893631\n",
      "epoch: 105 acc: 0.5416666666666666\n",
      "epoch: 106 loss: 0.29119405150413513\n",
      "epoch: 106 loss: 0.2848767936229706\n",
      "epoch: 106 loss: 0.2837020456790924\n",
      "epoch: 106 loss: 0.32264915108680725\n",
      "epoch: 106 loss: 0.2985548973083496\n",
      "epoch: 106 loss: 0.3237746059894562\n",
      "epoch: 106 loss: 0.2756059169769287\n",
      "epoch: 106 loss: 0.21241408586502075\n",
      "epoch: 106 loss: 0.4564833343029022\n",
      "epoch: 106 loss: 0.3669118583202362\n",
      "epoch: 106 loss: 0.19295457005500793\n",
      "epoch: 106 loss: 0.2814994156360626\n",
      "epoch: 106 loss: 0.2919459044933319\n",
      "epoch: 106 acc: 0.5416666666666666\n",
      "epoch: 107 loss: 0.3002993166446686\n",
      "epoch: 107 loss: 0.29752039909362793\n",
      "epoch: 107 loss: 0.289396733045578\n",
      "epoch: 107 loss: 0.31796836853027344\n",
      "epoch: 107 loss: 0.3035143315792084\n",
      "epoch: 107 loss: 0.31496816873550415\n",
      "epoch: 107 loss: 0.2762492001056671\n",
      "epoch: 107 loss: 0.20538660883903503\n",
      "epoch: 107 loss: 0.46326810121536255\n",
      "epoch: 107 loss: 0.3722718358039856\n",
      "epoch: 107 loss: 0.2000739872455597\n",
      "epoch: 107 loss: 0.2728229761123657\n",
      "epoch: 107 loss: 0.2809531092643738\n",
      "epoch: 107 acc: 0.5416666666666666\n",
      "epoch: 108 loss: 0.28663477301597595\n",
      "epoch: 108 loss: 0.30061566829681396\n",
      "epoch: 108 loss: 0.29099538922309875\n",
      "epoch: 108 loss: 0.320305198431015\n",
      "epoch: 108 loss: 0.29793882369995117\n",
      "epoch: 108 loss: 0.33387887477874756\n",
      "epoch: 108 loss: 0.26619696617126465\n",
      "epoch: 108 loss: 0.20551754534244537\n",
      "epoch: 108 loss: 0.45629408955574036\n",
      "epoch: 108 loss: 0.37689194083213806\n",
      "epoch: 108 loss: 0.1879311501979828\n",
      "epoch: 108 loss: 0.2779458463191986\n",
      "epoch: 108 loss: 0.28988713026046753\n",
      "epoch: 108 acc: 0.5260416666666666\n",
      "epoch: 109 loss: 0.29728296399116516\n",
      "epoch: 109 loss: 0.28906404972076416\n",
      "epoch: 109 loss: 0.28290218114852905\n",
      "epoch: 109 loss: 0.3092784881591797\n",
      "epoch: 109 loss: 0.30056852102279663\n",
      "epoch: 109 loss: 0.31295064091682434\n",
      "epoch: 109 loss: 0.2687402367591858\n",
      "epoch: 109 loss: 0.21370750665664673\n",
      "epoch: 109 loss: 0.4542614817619324\n",
      "epoch: 109 loss: 0.37126660346984863\n",
      "epoch: 109 loss: 0.1912461221218109\n",
      "epoch: 109 loss: 0.26922982931137085\n",
      "epoch: 109 loss: 0.2801330089569092\n",
      "epoch: 109 acc: 0.5520833333333334\n",
      "epoch: 110 loss: 0.2902468740940094\n",
      "epoch: 110 loss: 0.29815471172332764\n",
      "epoch: 110 loss: 0.2920217216014862\n",
      "epoch: 110 loss: 0.31584563851356506\n",
      "epoch: 110 loss: 0.30089130997657776\n",
      "epoch: 110 loss: 0.3280612826347351\n",
      "epoch: 110 loss: 0.2732611894607544\n",
      "epoch: 110 loss: 0.2024991512298584\n",
      "epoch: 110 loss: 0.4609835743904114\n",
      "epoch: 110 loss: 0.37970325350761414\n",
      "epoch: 110 loss: 0.18431873619556427\n",
      "epoch: 110 loss: 0.2816106677055359\n",
      "epoch: 110 loss: 0.29202914237976074\n",
      "epoch: 110 acc: 0.5416666666666666\n",
      "epoch: 111 loss: 0.29848164319992065\n",
      "epoch: 111 loss: 0.29786136746406555\n",
      "epoch: 111 loss: 0.2889809012413025\n",
      "epoch: 111 loss: 0.31048819422721863\n",
      "epoch: 111 loss: 0.3005099296569824\n",
      "epoch: 111 loss: 0.32563865184783936\n",
      "epoch: 111 loss: 0.2735353708267212\n",
      "epoch: 111 loss: 0.20612424612045288\n",
      "epoch: 111 loss: 0.4575287401676178\n",
      "epoch: 111 loss: 0.375741183757782\n",
      "epoch: 111 loss: 0.19014950096607208\n",
      "epoch: 111 loss: 0.270457923412323\n",
      "epoch: 111 loss: 0.28525397181510925\n",
      "epoch: 111 acc: 0.5364583333333334\n",
      "epoch: 112 loss: 0.29410821199417114\n",
      "epoch: 112 loss: 0.2983327805995941\n",
      "epoch: 112 loss: 0.290168434381485\n",
      "epoch: 112 loss: 0.3066938817501068\n",
      "epoch: 112 loss: 0.30207663774490356\n",
      "epoch: 112 loss: 0.3229014277458191\n",
      "epoch: 112 loss: 0.26975879073143005\n",
      "epoch: 112 loss: 0.20498961210250854\n",
      "epoch: 112 loss: 0.45314499735832214\n",
      "epoch: 112 loss: 0.3684219419956207\n",
      "epoch: 112 loss: 0.19056352972984314\n",
      "epoch: 112 loss: 0.268174946308136\n",
      "epoch: 112 loss: 0.28189000487327576\n",
      "epoch: 112 acc: 0.5416666666666666\n",
      "epoch: 113 loss: 0.29633545875549316\n",
      "epoch: 113 loss: 0.2888430058956146\n",
      "epoch: 113 loss: 0.28574666380882263\n",
      "epoch: 113 loss: 0.3179831802845001\n",
      "epoch: 113 loss: 0.2994796931743622\n",
      "epoch: 113 loss: 0.33024266362190247\n",
      "epoch: 113 loss: 0.2722419202327728\n",
      "epoch: 113 loss: 0.20907756686210632\n",
      "epoch: 113 loss: 0.4538392722606659\n",
      "epoch: 113 loss: 0.3666376769542694\n",
      "epoch: 113 loss: 0.19169479608535767\n",
      "epoch: 113 loss: 0.2738886773586273\n",
      "epoch: 113 loss: 0.28780490159988403\n",
      "epoch: 113 acc: 0.5416666666666666\n",
      "epoch: 114 loss: 0.2976643443107605\n",
      "epoch: 114 loss: 0.2958829998970032\n",
      "epoch: 114 loss: 0.28871282935142517\n",
      "epoch: 114 loss: 0.31075936555862427\n",
      "epoch: 114 loss: 0.30209606885910034\n",
      "epoch: 114 loss: 0.307669073343277\n",
      "epoch: 114 loss: 0.27915582060813904\n",
      "epoch: 114 loss: 0.2077876627445221\n",
      "epoch: 114 loss: 0.4564921259880066\n",
      "epoch: 114 loss: 0.3709615468978882\n",
      "epoch: 114 loss: 0.19397854804992676\n",
      "epoch: 114 loss: 0.27487778663635254\n",
      "epoch: 114 loss: 0.2834579348564148\n",
      "epoch: 114 acc: 0.5416666666666666\n",
      "epoch: 115 loss: 0.2853293716907501\n",
      "epoch: 115 loss: 0.3015918731689453\n",
      "epoch: 115 loss: 0.28797265887260437\n",
      "epoch: 115 loss: 0.3170520067214966\n",
      "epoch: 115 loss: 0.30184340476989746\n",
      "epoch: 115 loss: 0.32586726546287537\n",
      "epoch: 115 loss: 0.27020463347435\n",
      "epoch: 115 loss: 0.20482167601585388\n",
      "epoch: 115 loss: 0.4522791802883148\n",
      "epoch: 115 loss: 0.37072518467903137\n",
      "epoch: 115 loss: 0.18669626116752625\n",
      "epoch: 115 loss: 0.2715891897678375\n",
      "epoch: 115 loss: 0.28703415393829346\n",
      "epoch: 115 acc: 0.53125\n",
      "epoch: 116 loss: 0.2944542169570923\n",
      "epoch: 116 loss: 0.2874563932418823\n",
      "epoch: 116 loss: 0.28134360909461975\n",
      "epoch: 116 loss: 0.31563785672187805\n",
      "epoch: 116 loss: 0.2926511764526367\n",
      "epoch: 116 loss: 0.3090301752090454\n",
      "epoch: 116 loss: 0.2729886770248413\n",
      "epoch: 116 loss: 0.21959932148456573\n",
      "epoch: 116 loss: 0.4478808641433716\n",
      "epoch: 116 loss: 0.3650112748146057\n",
      "epoch: 116 loss: 0.18660178780555725\n",
      "epoch: 116 loss: 0.2661910653114319\n",
      "epoch: 116 loss: 0.2823328375816345\n",
      "epoch: 116 acc: 0.5260416666666666\n",
      "epoch: 117 loss: 0.29019996523857117\n",
      "epoch: 117 loss: 0.29455533623695374\n",
      "epoch: 117 loss: 0.28577497601509094\n",
      "epoch: 117 loss: 0.31020358204841614\n",
      "epoch: 117 loss: 0.2998989224433899\n",
      "epoch: 117 loss: 0.3080188035964966\n",
      "epoch: 117 loss: 0.27314212918281555\n",
      "epoch: 117 loss: 0.20721682906150818\n",
      "epoch: 117 loss: 0.4510233402252197\n",
      "epoch: 117 loss: 0.3651810884475708\n",
      "epoch: 117 loss: 0.18978703022003174\n",
      "epoch: 117 loss: 0.2721623480319977\n",
      "epoch: 117 loss: 0.28439244627952576\n",
      "epoch: 117 acc: 0.546875\n",
      "epoch: 118 loss: 0.29393985867500305\n",
      "epoch: 118 loss: 0.2917579412460327\n",
      "epoch: 118 loss: 0.2869935631752014\n",
      "epoch: 118 loss: 0.3192993998527527\n",
      "epoch: 118 loss: 0.2944917678833008\n",
      "epoch: 118 loss: 0.32157087326049805\n",
      "epoch: 118 loss: 0.2747619152069092\n",
      "epoch: 118 loss: 0.20911642909049988\n",
      "epoch: 118 loss: 0.45577356219291687\n",
      "epoch: 118 loss: 0.372131884098053\n",
      "epoch: 118 loss: 0.19267405569553375\n",
      "epoch: 118 loss: 0.27331992983818054\n",
      "epoch: 118 loss: 0.28441911935806274\n",
      "epoch: 118 acc: 0.5416666666666666\n",
      "epoch: 119 loss: 0.2893233895301819\n",
      "epoch: 119 loss: 0.3041973114013672\n",
      "epoch: 119 loss: 0.29249000549316406\n",
      "epoch: 119 loss: 0.3110215365886688\n",
      "epoch: 119 loss: 0.2970176339149475\n",
      "epoch: 119 loss: 0.31155991554260254\n",
      "epoch: 119 loss: 0.2637023329734802\n",
      "epoch: 119 loss: 0.2039799690246582\n",
      "epoch: 119 loss: 0.44920843839645386\n",
      "epoch: 119 loss: 0.37152227759361267\n",
      "epoch: 119 loss: 0.1882043182849884\n",
      "epoch: 119 loss: 0.26816326379776\n",
      "epoch: 119 loss: 0.27915599942207336\n",
      "epoch: 119 acc: 0.5260416666666666\n",
      "epoch: 120 loss: 0.2918423116207123\n",
      "epoch: 120 loss: 0.2844216823577881\n",
      "epoch: 120 loss: 0.2836231589317322\n",
      "epoch: 120 loss: 0.3143780827522278\n",
      "epoch: 120 loss: 0.29343554377555847\n",
      "epoch: 120 loss: 0.3255365490913391\n",
      "epoch: 120 loss: 0.2612152397632599\n",
      "epoch: 120 loss: 0.21140576899051666\n",
      "epoch: 120 loss: 0.4474300146102905\n",
      "epoch: 120 loss: 0.3656558692455292\n",
      "epoch: 120 loss: 0.18635214865207672\n",
      "epoch: 120 loss: 0.2684403359889984\n",
      "epoch: 120 loss: 0.28667548298835754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 120 acc: 0.53125\n",
      "epoch: 121 loss: 0.29732707142829895\n",
      "epoch: 121 loss: 0.28835225105285645\n",
      "epoch: 121 loss: 0.2841212749481201\n",
      "epoch: 121 loss: 0.3027336597442627\n",
      "epoch: 121 loss: 0.312640517950058\n",
      "epoch: 121 loss: 0.3055502772331238\n",
      "epoch: 121 loss: 0.283718079328537\n",
      "epoch: 121 loss: 0.20909562706947327\n",
      "epoch: 121 loss: 0.4539532959461212\n",
      "epoch: 121 loss: 0.3693595230579376\n",
      "epoch: 121 loss: 0.1954742670059204\n",
      "epoch: 121 loss: 0.2773561179637909\n",
      "epoch: 121 loss: 0.28534433245658875\n",
      "epoch: 121 acc: 0.5520833333333334\n",
      "epoch: 122 loss: 0.2914878726005554\n",
      "epoch: 122 loss: 0.3099711239337921\n",
      "epoch: 122 loss: 0.2940388023853302\n",
      "epoch: 122 loss: 0.318199098110199\n",
      "epoch: 122 loss: 0.2993839681148529\n",
      "epoch: 122 loss: 0.31457701325416565\n",
      "epoch: 122 loss: 0.2785241901874542\n",
      "epoch: 122 loss: 0.2044382095336914\n",
      "epoch: 122 loss: 0.454499214887619\n",
      "epoch: 122 loss: 0.3735322058200836\n",
      "epoch: 122 loss: 0.18667834997177124\n",
      "epoch: 122 loss: 0.2674484848976135\n",
      "epoch: 122 loss: 0.28351297974586487\n",
      "epoch: 122 acc: 0.53125\n",
      "epoch: 123 loss: 0.2868924140930176\n",
      "epoch: 123 loss: 0.29112282395362854\n",
      "epoch: 123 loss: 0.2803824245929718\n",
      "epoch: 123 loss: 0.31684860587120056\n",
      "epoch: 123 loss: 0.28887811303138733\n",
      "epoch: 123 loss: 0.3194923996925354\n",
      "epoch: 123 loss: 0.26283398270606995\n",
      "epoch: 123 loss: 0.2202104777097702\n",
      "epoch: 123 loss: 0.4397103786468506\n",
      "epoch: 123 loss: 0.3565295934677124\n",
      "epoch: 123 loss: 0.18848860263824463\n",
      "epoch: 123 loss: 0.25970858335494995\n",
      "epoch: 123 loss: 0.2776990532875061\n",
      "epoch: 123 acc: 0.5208333333333334\n",
      "epoch: 124 loss: 0.2959561347961426\n",
      "epoch: 124 loss: 0.28384438157081604\n",
      "epoch: 124 loss: 0.28664377331733704\n",
      "epoch: 124 loss: 0.30932724475860596\n",
      "epoch: 124 loss: 0.30067166686058044\n",
      "epoch: 124 loss: 0.30294668674468994\n",
      "epoch: 124 loss: 0.2664329707622528\n",
      "epoch: 124 loss: 0.21818692982196808\n",
      "epoch: 124 loss: 0.4506266117095947\n",
      "epoch: 124 loss: 0.35942649841308594\n",
      "epoch: 124 loss: 0.19160431623458862\n",
      "epoch: 124 loss: 0.2681349515914917\n",
      "epoch: 124 loss: 0.28011420369148254\n",
      "epoch: 124 acc: 0.53125\n",
      "epoch: 125 loss: 0.28237801790237427\n",
      "epoch: 125 loss: 0.29463058710098267\n",
      "epoch: 125 loss: 0.2836971580982208\n",
      "epoch: 125 loss: 0.3172019124031067\n",
      "epoch: 125 loss: 0.29808205366134644\n",
      "epoch: 125 loss: 0.31395360827445984\n",
      "epoch: 125 loss: 0.2807592749595642\n",
      "epoch: 125 loss: 0.20820999145507812\n",
      "epoch: 125 loss: 0.45874035358428955\n",
      "epoch: 125 loss: 0.3759300112724304\n",
      "epoch: 125 loss: 0.1867065131664276\n",
      "epoch: 125 loss: 0.28148791193962097\n",
      "epoch: 125 loss: 0.28897830843925476\n",
      "epoch: 125 acc: 0.546875\n",
      "epoch: 126 loss: 0.2879340648651123\n",
      "epoch: 126 loss: 0.30814939737319946\n",
      "epoch: 126 loss: 0.2926540970802307\n",
      "epoch: 126 loss: 0.30911344289779663\n",
      "epoch: 126 loss: 0.29214727878570557\n",
      "epoch: 126 loss: 0.30627772212028503\n",
      "epoch: 126 loss: 0.2720065712928772\n",
      "epoch: 126 loss: 0.20749536156654358\n",
      "epoch: 126 loss: 0.4535156786441803\n",
      "epoch: 126 loss: 0.3750602602958679\n",
      "epoch: 126 loss: 0.1941652148962021\n",
      "epoch: 126 loss: 0.2577379643917084\n",
      "epoch: 126 loss: 0.274311900138855\n",
      "epoch: 126 acc: 0.53125\n",
      "epoch: 127 loss: 0.2833368480205536\n",
      "epoch: 127 loss: 0.29772934317588806\n",
      "epoch: 127 loss: 0.2908838391304016\n",
      "epoch: 127 loss: 0.3133907914161682\n",
      "epoch: 127 loss: 0.29336637258529663\n",
      "epoch: 127 loss: 0.31656357645988464\n",
      "epoch: 127 loss: 0.25362125039100647\n",
      "epoch: 127 loss: 0.20907162129878998\n",
      "epoch: 127 loss: 0.44340670108795166\n",
      "epoch: 127 loss: 0.3633711636066437\n",
      "epoch: 127 loss: 0.1771482676267624\n",
      "epoch: 127 loss: 0.26828327775001526\n",
      "epoch: 127 loss: 0.2793837785720825\n",
      "epoch: 127 acc: 0.515625\n",
      "epoch: 128 loss: 0.29706668853759766\n",
      "epoch: 128 loss: 0.2752014994621277\n",
      "epoch: 128 loss: 0.2819986045360565\n",
      "epoch: 128 loss: 0.3037240505218506\n",
      "epoch: 128 loss: 0.2965405285358429\n",
      "epoch: 128 loss: 0.31961682438850403\n",
      "epoch: 128 loss: 0.267579585313797\n",
      "epoch: 128 loss: 0.2163981795310974\n",
      "epoch: 128 loss: 0.44765496253967285\n",
      "epoch: 128 loss: 0.3660116493701935\n",
      "epoch: 128 loss: 0.1939530074596405\n",
      "epoch: 128 loss: 0.26765692234039307\n",
      "epoch: 128 loss: 0.2824331223964691\n",
      "epoch: 128 acc: 0.53125\n",
      "epoch: 129 loss: 0.2876513600349426\n",
      "epoch: 129 loss: 0.2976379096508026\n",
      "epoch: 129 loss: 0.2871930003166199\n",
      "epoch: 129 loss: 0.31030845642089844\n",
      "epoch: 129 loss: 0.30188217759132385\n",
      "epoch: 129 loss: 0.2954825758934021\n",
      "epoch: 129 loss: 0.2824976444244385\n",
      "epoch: 129 loss: 0.20870628952980042\n",
      "epoch: 129 loss: 0.4510726034641266\n",
      "epoch: 129 loss: 0.36816370487213135\n",
      "epoch: 129 loss: 0.18441438674926758\n",
      "epoch: 129 loss: 0.26691120862960815\n",
      "epoch: 129 loss: 0.27960509061813354\n",
      "epoch: 129 acc: 0.5364583333333334\n",
      "epoch: 130 loss: 0.2824409008026123\n",
      "epoch: 130 loss: 0.30709588527679443\n",
      "epoch: 130 loss: 0.2929480969905853\n",
      "epoch: 130 loss: 0.30991077423095703\n",
      "epoch: 130 loss: 0.288765013217926\n",
      "epoch: 130 loss: 0.3148135542869568\n",
      "epoch: 130 loss: 0.26576218008995056\n",
      "epoch: 130 loss: 0.20442689955234528\n",
      "epoch: 130 loss: 0.4517478048801422\n",
      "epoch: 130 loss: 0.37326714396476746\n",
      "epoch: 130 loss: 0.18472826480865479\n",
      "epoch: 130 loss: 0.26581650972366333\n",
      "epoch: 130 loss: 0.281817227602005\n",
      "epoch: 130 acc: 0.5208333333333334\n",
      "epoch: 131 loss: 0.2847207188606262\n",
      "epoch: 131 loss: 0.2904607057571411\n",
      "epoch: 131 loss: 0.28158846497535706\n",
      "epoch: 131 loss: 0.3071984052658081\n",
      "epoch: 131 loss: 0.291285902261734\n",
      "epoch: 131 loss: 0.3115505874156952\n",
      "epoch: 131 loss: 0.26276203989982605\n",
      "epoch: 131 loss: 0.21428696811199188\n",
      "epoch: 131 loss: 0.4398653507232666\n",
      "epoch: 131 loss: 0.3660722076892853\n",
      "epoch: 131 loss: 0.1800483763217926\n",
      "epoch: 131 loss: 0.2578286826610565\n",
      "epoch: 131 loss: 0.276842325925827\n",
      "epoch: 131 acc: 0.515625\n",
      "epoch: 132 loss: 0.2883245646953583\n",
      "epoch: 132 loss: 0.29195648431777954\n",
      "epoch: 132 loss: 0.2851475477218628\n",
      "epoch: 132 loss: 0.3068040609359741\n",
      "epoch: 132 loss: 0.29580122232437134\n",
      "epoch: 132 loss: 0.3141286373138428\n",
      "epoch: 132 loss: 0.26825037598609924\n",
      "epoch: 132 loss: 0.21181149780750275\n",
      "epoch: 132 loss: 0.4443088173866272\n",
      "epoch: 132 loss: 0.359596312046051\n",
      "epoch: 132 loss: 0.18544933199882507\n",
      "epoch: 132 loss: 0.2622290849685669\n",
      "epoch: 132 loss: 0.2790851891040802\n",
      "epoch: 132 acc: 0.5208333333333334\n",
      "epoch: 133 loss: 0.28691670298576355\n",
      "epoch: 133 loss: 0.2902095317840576\n",
      "epoch: 133 loss: 0.28625577688217163\n",
      "epoch: 133 loss: 0.31381043791770935\n",
      "epoch: 133 loss: 0.29653048515319824\n",
      "epoch: 133 loss: 0.314382940530777\n",
      "epoch: 133 loss: 0.2785753011703491\n",
      "epoch: 133 loss: 0.2140892893075943\n",
      "epoch: 133 loss: 0.4528440833091736\n",
      "epoch: 133 loss: 0.3662220239639282\n",
      "epoch: 133 loss: 0.19007623195648193\n",
      "epoch: 133 loss: 0.2692948281764984\n",
      "epoch: 133 loss: 0.28168201446533203\n",
      "epoch: 133 acc: 0.5416666666666666\n",
      "epoch: 134 loss: 0.2836530804634094\n",
      "epoch: 134 loss: 0.31067976355552673\n",
      "epoch: 134 loss: 0.29313719272613525\n",
      "epoch: 134 loss: 0.30821648240089417\n",
      "epoch: 134 loss: 0.29304081201553345\n",
      "epoch: 134 loss: 0.2943045198917389\n",
      "epoch: 134 loss: 0.27462127804756165\n",
      "epoch: 134 loss: 0.20988231897354126\n",
      "epoch: 134 loss: 0.4452778697013855\n",
      "epoch: 134 loss: 0.36494138836860657\n",
      "epoch: 134 loss: 0.1880575716495514\n",
      "epoch: 134 loss: 0.25891244411468506\n",
      "epoch: 134 loss: 0.2752992808818817\n",
      "epoch: 134 acc: 0.5104166666666666\n",
      "epoch: 135 loss: 0.28103744983673096\n",
      "epoch: 135 loss: 0.2896747291088104\n",
      "epoch: 135 loss: 0.2855812907218933\n",
      "epoch: 135 loss: 0.3089241683483124\n",
      "epoch: 135 loss: 0.2948558032512665\n",
      "epoch: 135 loss: 0.31491535902023315\n",
      "epoch: 135 loss: 0.25546735525131226\n",
      "epoch: 135 loss: 0.21753492951393127\n",
      "epoch: 135 loss: 0.4387705326080322\n",
      "epoch: 135 loss: 0.35952913761138916\n",
      "epoch: 135 loss: 0.1813010722398758\n",
      "epoch: 135 loss: 0.2539752721786499\n",
      "epoch: 135 loss: 0.27625587582588196\n",
      "epoch: 135 acc: 0.5260416666666666\n",
      "epoch: 136 loss: 0.28986114263534546\n",
      "epoch: 136 loss: 0.28919702768325806\n",
      "epoch: 136 loss: 0.2851332724094391\n",
      "epoch: 136 loss: 0.31258201599121094\n",
      "epoch: 136 loss: 0.2984313666820526\n",
      "epoch: 136 loss: 0.3109857141971588\n",
      "epoch: 136 loss: 0.27076104283332825\n",
      "epoch: 136 loss: 0.21612808108329773\n",
      "epoch: 136 loss: 0.4465899169445038\n",
      "epoch: 136 loss: 0.35958433151245117\n",
      "epoch: 136 loss: 0.18975675106048584\n",
      "epoch: 136 loss: 0.2710985243320465\n",
      "epoch: 136 loss: 0.2833522856235504\n",
      "epoch: 136 acc: 0.5104166666666666\n",
      "epoch: 137 loss: 0.279457688331604\n",
      "epoch: 137 loss: 0.2907758951187134\n",
      "epoch: 137 loss: 0.27923405170440674\n",
      "epoch: 137 loss: 0.31134334206581116\n",
      "epoch: 137 loss: 0.2926555275917053\n",
      "epoch: 137 loss: 0.29240432381629944\n",
      "epoch: 137 loss: 0.2716590464115143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 137 loss: 0.21632355451583862\n",
      "epoch: 137 loss: 0.45033344626426697\n",
      "epoch: 137 loss: 0.3787553310394287\n",
      "epoch: 137 loss: 0.1843523383140564\n",
      "epoch: 137 loss: 0.25810515880584717\n",
      "epoch: 137 loss: 0.2767687141895294\n",
      "epoch: 137 acc: 0.5416666666666666\n",
      "epoch: 138 loss: 0.2770662307739258\n",
      "epoch: 138 loss: 0.3252318799495697\n",
      "epoch: 138 loss: 0.3089018166065216\n",
      "epoch: 138 loss: 0.31123778223991394\n",
      "epoch: 138 loss: 0.28003743290901184\n",
      "epoch: 138 loss: 0.2997485101222992\n",
      "epoch: 138 loss: 0.2614370286464691\n",
      "epoch: 138 loss: 0.19879460334777832\n",
      "epoch: 138 loss: 0.44927555322647095\n",
      "epoch: 138 loss: 0.38276034593582153\n",
      "epoch: 138 loss: 0.17987555265426636\n",
      "epoch: 138 loss: 0.2828817069530487\n",
      "epoch: 138 loss: 0.2807132601737976\n",
      "epoch: 138 acc: 0.515625\n",
      "epoch: 139 loss: 0.28844910860061646\n",
      "epoch: 139 loss: 0.27634549140930176\n",
      "epoch: 139 loss: 0.278911828994751\n",
      "epoch: 139 loss: 0.3001590371131897\n",
      "epoch: 139 loss: 0.28190404176712036\n",
      "epoch: 139 loss: 0.3281398117542267\n",
      "epoch: 139 loss: 0.25219297409057617\n",
      "epoch: 139 loss: 0.22079676389694214\n",
      "epoch: 139 loss: 0.4432162940502167\n",
      "epoch: 139 loss: 0.379324346780777\n",
      "epoch: 139 loss: 0.18229931592941284\n",
      "epoch: 139 loss: 0.25245401263237\n",
      "epoch: 139 loss: 0.27690374851226807\n",
      "epoch: 139 acc: 0.515625\n",
      "epoch: 140 loss: 0.28785839676856995\n",
      "epoch: 140 loss: 0.3090701699256897\n",
      "epoch: 140 loss: 0.28917574882507324\n",
      "epoch: 140 loss: 0.3173925578594208\n",
      "epoch: 140 loss: 0.2839210033416748\n",
      "epoch: 140 loss: 0.30140364170074463\n",
      "epoch: 140 loss: 0.26439857482910156\n",
      "epoch: 140 loss: 0.22052693367004395\n",
      "epoch: 140 loss: 0.4532640874385834\n",
      "epoch: 140 loss: 0.3614380657672882\n",
      "epoch: 140 loss: 0.18853849172592163\n",
      "epoch: 140 loss: 0.2649126648902893\n",
      "epoch: 140 loss: 0.2750895321369171\n",
      "epoch: 140 acc: 0.515625\n",
      "epoch: 141 loss: 0.29461124539375305\n",
      "epoch: 141 loss: 0.27662819623947144\n",
      "epoch: 141 loss: 0.2856234312057495\n",
      "epoch: 141 loss: 0.29638591408729553\n",
      "epoch: 141 loss: 0.2941126525402069\n",
      "epoch: 141 loss: 0.47662654519081116\n",
      "epoch: 141 loss: 0.27537375688552856\n",
      "epoch: 141 loss: 0.3082149624824524\n",
      "epoch: 141 loss: 0.4672677516937256\n",
      "epoch: 141 loss: 0.42625758051872253\n",
      "epoch: 141 loss: 0.3380378782749176\n",
      "epoch: 141 loss: 0.3276585042476654\n",
      "epoch: 141 loss: 0.3216836452484131\n",
      "epoch: 141 acc: 0.5520833333333334\n",
      "epoch: 142 loss: 0.31801047921180725\n",
      "epoch: 142 loss: 0.4496958553791046\n",
      "epoch: 142 loss: 0.4402071237564087\n",
      "epoch: 142 loss: 0.4647490084171295\n",
      "epoch: 142 loss: 0.41865813732147217\n",
      "epoch: 142 loss: 0.3356250822544098\n",
      "epoch: 142 loss: 0.8043730854988098\n",
      "epoch: 142 loss: 0.3372948169708252\n",
      "epoch: 142 loss: 0.570029079914093\n",
      "epoch: 142 loss: 0.5058771967887878\n",
      "epoch: 142 loss: 0.3757457733154297\n",
      "epoch: 142 loss: 0.3805844783782959\n",
      "epoch: 142 loss: 0.41594991087913513\n",
      "epoch: 142 acc: 0.5572916666666666\n",
      "epoch: 143 loss: 0.4803791642189026\n",
      "epoch: 143 loss: 0.4268389046192169\n",
      "epoch: 143 loss: 0.6389406323432922\n",
      "epoch: 143 loss: 0.6440832614898682\n",
      "epoch: 143 loss: 0.6152746081352234\n",
      "epoch: 143 loss: 0.6771846413612366\n",
      "epoch: 143 loss: 0.44420698285102844\n",
      "epoch: 143 loss: 0.4045841097831726\n",
      "epoch: 143 loss: 0.4556920528411865\n",
      "epoch: 143 loss: 0.37378770112991333\n",
      "epoch: 143 loss: 0.26996248960494995\n",
      "epoch: 143 loss: 0.34398743510246277\n",
      "epoch: 143 loss: 0.3618325889110565\n",
      "epoch: 143 acc: 0.53125\n",
      "epoch: 144 loss: 0.32442185282707214\n",
      "epoch: 144 loss: 0.3246096968650818\n",
      "epoch: 144 loss: 0.2890802323818207\n",
      "epoch: 144 loss: 1.050642728805542\n",
      "epoch: 144 loss: 1.0705595016479492\n",
      "epoch: 144 loss: 0.33214521408081055\n",
      "epoch: 144 loss: 0.4722907841205597\n",
      "epoch: 144 loss: 0.4392652213573456\n",
      "epoch: 144 loss: 0.4191987216472626\n",
      "epoch: 144 loss: 0.5974906086921692\n",
      "epoch: 144 loss: 0.22140944004058838\n",
      "epoch: 144 loss: 0.3477441370487213\n",
      "epoch: 144 loss: 0.4244972765445709\n",
      "epoch: 144 acc: 0.515625\n",
      "epoch: 145 loss: 0.469635933637619\n",
      "epoch: 145 loss: 0.9737366437911987\n",
      "epoch: 145 loss: 0.4887920022010803\n",
      "epoch: 145 loss: 0.4788719117641449\n",
      "epoch: 145 loss: 3.59692645072937\n",
      "epoch: 145 loss: 0.3864422142505646\n",
      "epoch: 145 loss: 0.402031272649765\n",
      "epoch: 145 loss: 0.519347608089447\n",
      "epoch: 145 loss: 0.45236605405807495\n",
      "epoch: 145 loss: 0.7381728291511536\n",
      "epoch: 145 loss: 0.9906228184700012\n",
      "epoch: 145 loss: 0.6142500042915344\n",
      "epoch: 145 loss: 0.3642853796482086\n",
      "epoch: 145 acc: 0.546875\n",
      "epoch: 146 loss: 0.5814371705055237\n",
      "epoch: 146 loss: 0.58460533618927\n",
      "epoch: 146 loss: 0.8955091834068298\n",
      "epoch: 146 loss: 0.8793083429336548\n",
      "epoch: 146 loss: 0.4505697786808014\n",
      "epoch: 146 loss: 0.8831886649131775\n",
      "epoch: 146 loss: 0.48356038331985474\n",
      "epoch: 146 loss: 0.3385222256183624\n",
      "epoch: 146 loss: 0.8079497814178467\n",
      "epoch: 146 loss: 0.43127480149269104\n",
      "epoch: 146 loss: 0.3046228289604187\n",
      "epoch: 146 loss: 0.9795644879341125\n",
      "epoch: 146 loss: 0.41978561878204346\n",
      "epoch: 146 acc: 0.546875\n",
      "epoch: 147 loss: 0.4213140606880188\n",
      "epoch: 147 loss: 0.5693520903587341\n",
      "epoch: 147 loss: 0.38971588015556335\n",
      "epoch: 147 loss: 0.8976323008537292\n",
      "epoch: 147 loss: 0.7376809120178223\n",
      "epoch: 147 loss: 0.2793208062648773\n",
      "epoch: 147 loss: 0.5219648480415344\n",
      "epoch: 147 loss: 0.3580887019634247\n",
      "epoch: 147 loss: 0.5977282524108887\n",
      "epoch: 147 loss: 0.45125603675842285\n",
      "epoch: 147 loss: 0.3513723313808441\n",
      "epoch: 147 loss: 0.5421067476272583\n",
      "epoch: 147 loss: 0.3894362449645996\n",
      "epoch: 147 acc: 0.5260416666666666\n",
      "epoch: 148 loss: 0.4285050630569458\n",
      "epoch: 148 loss: 0.3771874010562897\n",
      "epoch: 148 loss: 0.3898624777793884\n",
      "epoch: 148 loss: 0.5708627700805664\n",
      "epoch: 148 loss: 0.5647574663162231\n",
      "epoch: 148 loss: 0.3913055956363678\n",
      "epoch: 148 loss: 0.5772527456283569\n",
      "epoch: 148 loss: 1.290641188621521\n",
      "epoch: 148 loss: 0.684367299079895\n",
      "epoch: 148 loss: 0.5589541792869568\n",
      "epoch: 148 loss: 0.7763985991477966\n",
      "epoch: 148 loss: 0.5309276580810547\n",
      "epoch: 148 loss: 0.5427172780036926\n",
      "epoch: 148 acc: 0.5104166666666666\n",
      "epoch: 149 loss: 0.5274251699447632\n",
      "epoch: 149 loss: 0.41423556208610535\n",
      "epoch: 149 loss: 0.45341914892196655\n",
      "epoch: 149 loss: 0.45882222056388855\n",
      "epoch: 149 loss: 0.44876760244369507\n",
      "epoch: 149 loss: 0.4400887191295624\n",
      "epoch: 149 loss: 0.3424200415611267\n",
      "epoch: 149 loss: 0.605216383934021\n",
      "epoch: 149 loss: 0.6915797591209412\n",
      "epoch: 149 loss: 0.5088002681732178\n",
      "epoch: 149 loss: 0.2931106686592102\n",
      "epoch: 149 loss: 0.24659517407417297\n",
      "epoch: 149 loss: 0.5127485990524292\n",
      "epoch: 149 acc: 0.5625\n",
      "epoch: 150 loss: 0.42275556921958923\n",
      "epoch: 150 loss: 0.4151560068130493\n",
      "epoch: 150 loss: 0.9190376996994019\n",
      "epoch: 150 loss: 0.546690046787262\n",
      "epoch: 150 loss: 0.8625988960266113\n",
      "epoch: 150 loss: 0.5300008058547974\n",
      "epoch: 150 loss: 0.4208228588104248\n",
      "epoch: 150 loss: 0.35135048627853394\n",
      "epoch: 150 loss: 0.6672556400299072\n",
      "epoch: 150 loss: 0.35596200823783875\n",
      "epoch: 150 loss: 0.381096214056015\n",
      "epoch: 150 loss: 0.34529057145118713\n",
      "epoch: 150 loss: 0.35309210419654846\n",
      "epoch: 150 acc: 0.5416666666666666\n",
      "epoch: 151 loss: 0.3353807330131531\n",
      "epoch: 151 loss: 0.41819673776626587\n",
      "epoch: 151 loss: 0.4885193109512329\n",
      "epoch: 151 loss: 0.4943090081214905\n",
      "epoch: 151 loss: 0.416307270526886\n",
      "epoch: 151 loss: 0.48954275250434875\n",
      "epoch: 151 loss: 0.3568754196166992\n",
      "epoch: 151 loss: 0.5607393383979797\n",
      "epoch: 151 loss: 0.5398321151733398\n",
      "epoch: 151 loss: 0.35057759284973145\n",
      "epoch: 151 loss: 0.270551860332489\n",
      "epoch: 151 loss: 0.3850632905960083\n",
      "epoch: 151 loss: 0.3897571265697479\n",
      "epoch: 151 acc: 0.5520833333333334\n",
      "epoch: 152 loss: 0.39104917645454407\n",
      "epoch: 152 loss: 0.3860720992088318\n",
      "epoch: 152 loss: 0.31639236211776733\n",
      "epoch: 152 loss: 0.4346189498901367\n",
      "epoch: 152 loss: 0.3660790026187897\n",
      "epoch: 152 loss: 0.4046016335487366\n",
      "epoch: 152 loss: 0.34753724932670593\n",
      "epoch: 152 loss: 0.23667138814926147\n",
      "epoch: 152 loss: 0.5468775629997253\n",
      "epoch: 152 loss: 0.4088013470172882\n",
      "epoch: 152 loss: 0.39292052388191223\n",
      "epoch: 152 loss: 0.36680540442466736\n",
      "epoch: 152 loss: 0.36016857624053955\n",
      "epoch: 152 acc: 0.5364583333333334\n",
      "epoch: 153 loss: 0.3026213049888611\n",
      "epoch: 153 loss: 0.41102707386016846\n",
      "epoch: 153 loss: 0.3306376338005066\n",
      "epoch: 153 loss: 0.42886894941329956\n",
      "epoch: 153 loss: 0.5403001308441162\n",
      "epoch: 153 loss: 0.2932400703430176\n",
      "epoch: 153 loss: 0.39694744348526\n",
      "epoch: 153 loss: 0.25455403327941895\n",
      "epoch: 153 loss: 0.5669278502464294\n",
      "epoch: 153 loss: 0.4176371097564697\n",
      "epoch: 153 loss: 0.186752587556839\n",
      "epoch: 153 loss: 0.310436487197876\n",
      "epoch: 153 loss: 0.293728768825531\n",
      "epoch: 153 acc: 0.53125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 154 loss: 0.3353573679924011\n",
      "epoch: 154 loss: 0.38677722215652466\n",
      "epoch: 154 loss: 0.3033275902271271\n",
      "epoch: 154 loss: 0.4641043543815613\n",
      "epoch: 154 loss: 0.2912125587463379\n",
      "epoch: 154 loss: 0.4366849362850189\n",
      "epoch: 154 loss: 0.3338659405708313\n",
      "epoch: 154 loss: 0.21299007534980774\n",
      "epoch: 154 loss: 0.5126045346260071\n",
      "epoch: 154 loss: 0.38142386078834534\n",
      "epoch: 154 loss: 0.23518258333206177\n",
      "epoch: 154 loss: 0.2907477915287018\n",
      "epoch: 154 loss: 0.2883723974227905\n",
      "epoch: 154 acc: 0.5416666666666666\n",
      "epoch: 155 loss: 0.32837533950805664\n",
      "epoch: 155 loss: 0.34971359372138977\n",
      "epoch: 155 loss: 0.32860705256462097\n",
      "epoch: 155 loss: 0.4162665605545044\n",
      "epoch: 155 loss: 0.31588152050971985\n",
      "epoch: 155 loss: 0.47037553787231445\n",
      "epoch: 155 loss: 0.26349446177482605\n",
      "epoch: 155 loss: 0.1990281194448471\n",
      "epoch: 155 loss: 0.46855056285858154\n",
      "epoch: 155 loss: 0.43751227855682373\n",
      "epoch: 155 loss: 0.19931668043136597\n",
      "epoch: 155 loss: 0.3064453601837158\n",
      "epoch: 155 loss: 0.2765137851238251\n",
      "epoch: 155 acc: 0.5208333333333334\n",
      "epoch: 156 loss: 0.3259451687335968\n",
      "epoch: 156 loss: 0.3579532504081726\n",
      "epoch: 156 loss: 0.37852856516838074\n",
      "epoch: 156 loss: 0.42166051268577576\n",
      "epoch: 156 loss: 0.34043213725090027\n",
      "epoch: 156 loss: 0.3699401915073395\n",
      "epoch: 156 loss: 0.3065321743488312\n",
      "epoch: 156 loss: 0.18008111417293549\n",
      "epoch: 156 loss: 0.4375552237033844\n",
      "epoch: 156 loss: 0.4061872065067291\n",
      "epoch: 156 loss: 0.22045862674713135\n",
      "epoch: 156 loss: 0.3344959318637848\n",
      "epoch: 156 loss: 0.31373709440231323\n",
      "epoch: 156 acc: 0.5416666666666666\n",
      "epoch: 157 loss: 0.34215205907821655\n",
      "epoch: 157 loss: 0.35147911310195923\n",
      "epoch: 157 loss: 0.34026575088500977\n",
      "epoch: 157 loss: 0.3632875978946686\n",
      "epoch: 157 loss: 0.313739538192749\n",
      "epoch: 157 loss: 0.4279891848564148\n",
      "epoch: 157 loss: 0.2923872172832489\n",
      "epoch: 157 loss: 0.18395264446735382\n",
      "epoch: 157 loss: 0.4764712452888489\n",
      "epoch: 157 loss: 0.40807849168777466\n",
      "epoch: 157 loss: 0.19378145039081573\n",
      "epoch: 157 loss: 0.28764069080352783\n",
      "epoch: 157 loss: 0.2787061929702759\n",
      "epoch: 157 acc: 0.53125\n",
      "epoch: 158 loss: 0.3510718047618866\n",
      "epoch: 158 loss: 0.3921608030796051\n",
      "epoch: 158 loss: 0.35677456855773926\n",
      "epoch: 158 loss: 0.4383409023284912\n",
      "epoch: 158 loss: 0.31561097502708435\n",
      "epoch: 158 loss: 0.41751256585121155\n",
      "epoch: 158 loss: 0.30968961119651794\n",
      "epoch: 158 loss: 0.2120494544506073\n",
      "epoch: 158 loss: 0.48199695348739624\n",
      "epoch: 158 loss: 0.4389320909976959\n",
      "epoch: 158 loss: 0.25495943427085876\n",
      "epoch: 158 loss: 0.29924073815345764\n",
      "epoch: 158 loss: 0.2713267505168915\n",
      "epoch: 158 acc: 0.5208333333333334\n",
      "epoch: 159 loss: 0.2780659794807434\n",
      "epoch: 159 loss: 0.3491699695587158\n",
      "epoch: 159 loss: 0.3580082356929779\n",
      "epoch: 159 loss: 0.43904608488082886\n",
      "epoch: 159 loss: 0.30292120575904846\n",
      "epoch: 159 loss: 0.35385221242904663\n",
      "epoch: 159 loss: 0.30429935455322266\n",
      "epoch: 159 loss: 0.21253515779972076\n",
      "epoch: 159 loss: 0.4265456795692444\n",
      "epoch: 159 loss: 0.4070563018321991\n",
      "epoch: 159 loss: 0.20575807988643646\n",
      "epoch: 159 loss: 0.3236079514026642\n",
      "epoch: 159 loss: 0.2731108069419861\n",
      "epoch: 159 acc: 0.5052083333333334\n",
      "epoch: 160 loss: 0.29972559213638306\n",
      "epoch: 160 loss: 0.3440423905849457\n",
      "epoch: 160 loss: 0.3175831139087677\n",
      "epoch: 160 loss: 0.3810253441333771\n",
      "epoch: 160 loss: 0.27610230445861816\n",
      "epoch: 160 loss: 0.3571445345878601\n",
      "epoch: 160 loss: 0.278659850358963\n",
      "epoch: 160 loss: 0.18330009281635284\n",
      "epoch: 160 loss: 0.4532860219478607\n",
      "epoch: 160 loss: 0.41006338596343994\n",
      "epoch: 160 loss: 0.22858011722564697\n",
      "epoch: 160 loss: 0.29398587346076965\n",
      "epoch: 160 loss: 0.26667365431785583\n",
      "epoch: 160 acc: 0.5625\n",
      "epoch: 161 loss: 0.27681609988212585\n",
      "epoch: 161 loss: 0.3759543299674988\n",
      "epoch: 161 loss: 0.31860974431037903\n",
      "epoch: 161 loss: 0.40194591879844666\n",
      "epoch: 161 loss: 0.30574244260787964\n",
      "epoch: 161 loss: 0.3484838008880615\n",
      "epoch: 161 loss: 0.32384204864501953\n",
      "epoch: 161 loss: 0.212709441781044\n",
      "epoch: 161 loss: 0.44343069195747375\n",
      "epoch: 161 loss: 0.4152674973011017\n",
      "epoch: 161 loss: 0.22102297842502594\n",
      "epoch: 161 loss: 0.32232820987701416\n",
      "epoch: 161 loss: 0.289638489484787\n",
      "epoch: 161 acc: 0.515625\n",
      "epoch: 162 loss: 0.29723042249679565\n",
      "epoch: 162 loss: 0.3590029776096344\n",
      "epoch: 162 loss: 0.32501357793807983\n",
      "epoch: 162 loss: 0.41457948088645935\n",
      "epoch: 162 loss: 0.3295134902000427\n",
      "epoch: 162 loss: 0.36908721923828125\n",
      "epoch: 162 loss: 0.3068510890007019\n",
      "epoch: 162 loss: 0.25875431299209595\n",
      "epoch: 162 loss: 0.4341423511505127\n",
      "epoch: 162 loss: 0.3609314262866974\n",
      "epoch: 162 loss: 0.22830858826637268\n",
      "epoch: 162 loss: 0.29974645376205444\n",
      "epoch: 162 loss: 0.31697624921798706\n",
      "epoch: 162 acc: 0.5208333333333334\n",
      "epoch: 163 loss: 0.3057611286640167\n",
      "epoch: 163 loss: 0.35204070806503296\n",
      "epoch: 163 loss: 0.314907968044281\n",
      "epoch: 163 loss: 0.41331449151039124\n",
      "epoch: 163 loss: 0.3284361660480499\n",
      "epoch: 163 loss: 0.38763150572776794\n",
      "epoch: 163 loss: 0.2960943579673767\n",
      "epoch: 163 loss: 0.247516930103302\n",
      "epoch: 163 loss: 0.4553900957107544\n",
      "epoch: 163 loss: 0.3715982437133789\n",
      "epoch: 163 loss: 0.20652176439762115\n",
      "epoch: 163 loss: 0.29086369276046753\n",
      "epoch: 163 loss: 0.27863845229148865\n",
      "epoch: 163 acc: 0.5520833333333334\n",
      "epoch: 164 loss: 0.3030889630317688\n",
      "epoch: 164 loss: 0.3499135375022888\n",
      "epoch: 164 loss: 0.32420143485069275\n",
      "epoch: 164 loss: 0.3882959187030792\n",
      "epoch: 164 loss: 0.3321567177772522\n",
      "epoch: 164 loss: 0.4172108769416809\n",
      "epoch: 164 loss: 0.2820221185684204\n",
      "epoch: 164 loss: 0.21634012460708618\n",
      "epoch: 164 loss: 0.45592060685157776\n",
      "epoch: 164 loss: 0.36531582474708557\n",
      "epoch: 164 loss: 0.22939561307430267\n",
      "epoch: 164 loss: 0.28054413199424744\n",
      "epoch: 164 loss: 0.28971612453460693\n",
      "epoch: 164 acc: 0.5260416666666666\n",
      "epoch: 165 loss: 0.2977988123893738\n",
      "epoch: 165 loss: 0.3224664330482483\n",
      "epoch: 165 loss: 0.31352630257606506\n",
      "epoch: 165 loss: 0.4314153492450714\n",
      "epoch: 165 loss: 0.3307257294654846\n",
      "epoch: 165 loss: 0.488771915435791\n",
      "epoch: 165 loss: 0.25963783264160156\n",
      "epoch: 165 loss: 0.2073463648557663\n",
      "epoch: 165 loss: 0.4510098993778229\n",
      "epoch: 165 loss: 0.36217811703681946\n",
      "epoch: 165 loss: 0.2258192002773285\n",
      "epoch: 165 loss: 0.28592148423194885\n",
      "epoch: 165 loss: 0.31353268027305603\n",
      "epoch: 165 acc: 0.53125\n",
      "epoch: 166 loss: 0.332143098115921\n",
      "epoch: 166 loss: 0.34679535031318665\n",
      "epoch: 166 loss: 0.3193204700946808\n",
      "epoch: 166 loss: 0.4228511154651642\n",
      "epoch: 166 loss: 0.3454786241054535\n",
      "epoch: 166 loss: 0.46039631962776184\n",
      "epoch: 166 loss: 0.2483309805393219\n",
      "epoch: 166 loss: 0.20812681317329407\n",
      "epoch: 166 loss: 0.47292134165763855\n",
      "epoch: 166 loss: 0.4249376952648163\n",
      "epoch: 166 loss: 0.23681135475635529\n",
      "epoch: 166 loss: 0.29593756794929504\n",
      "epoch: 166 loss: 0.2872941493988037\n",
      "epoch: 166 acc: 0.5260416666666666\n",
      "epoch: 167 loss: 0.26943594217300415\n",
      "epoch: 167 loss: 0.35496485233306885\n",
      "epoch: 167 loss: 0.31227684020996094\n",
      "epoch: 167 loss: 0.3937389552593231\n",
      "epoch: 167 loss: 0.32967647910118103\n",
      "epoch: 167 loss: 0.3923766314983368\n",
      "epoch: 167 loss: 0.26868587732315063\n",
      "epoch: 167 loss: 0.1884014904499054\n",
      "epoch: 167 loss: 0.45128053426742554\n",
      "epoch: 167 loss: 0.4047471582889557\n",
      "epoch: 167 loss: 0.2023661732673645\n",
      "epoch: 167 loss: 0.29052749276161194\n",
      "epoch: 167 loss: 0.27447906136512756\n",
      "epoch: 167 acc: 0.5104166666666666\n",
      "epoch: 168 loss: 0.2951904833316803\n",
      "epoch: 168 loss: 0.34663620591163635\n",
      "epoch: 168 loss: 0.3199380040168762\n",
      "epoch: 168 loss: 0.3793785274028778\n",
      "epoch: 168 loss: 0.32401055097579956\n",
      "epoch: 168 loss: 0.4404931366443634\n",
      "epoch: 168 loss: 0.2711891233921051\n",
      "epoch: 168 loss: 0.18658502399921417\n",
      "epoch: 168 loss: 0.4538736343383789\n",
      "epoch: 168 loss: 0.42483073472976685\n",
      "epoch: 168 loss: 0.22237977385520935\n",
      "epoch: 168 loss: 0.2790506184101105\n",
      "epoch: 168 loss: 0.28790852427482605\n",
      "epoch: 168 acc: 0.53125\n",
      "epoch: 169 loss: 0.29052165150642395\n",
      "epoch: 169 loss: 0.34868842363357544\n",
      "epoch: 169 loss: 0.3115716278553009\n",
      "epoch: 169 loss: 0.39611631631851196\n",
      "epoch: 169 loss: 0.3383559584617615\n",
      "epoch: 169 loss: 0.46881091594696045\n",
      "epoch: 169 loss: 0.3137062191963196\n",
      "epoch: 169 loss: 0.23132744431495667\n",
      "epoch: 169 loss: 0.45730966329574585\n",
      "epoch: 169 loss: 0.4040068984031677\n",
      "epoch: 169 loss: 0.2381700575351715\n",
      "epoch: 169 loss: 0.2999519407749176\n",
      "epoch: 169 loss: 0.32580864429473877\n",
      "epoch: 169 acc: 0.53125\n",
      "epoch: 170 loss: 0.32459530234336853\n",
      "epoch: 170 loss: 0.3579254448413849\n",
      "epoch: 170 loss: 0.3544742465019226\n",
      "epoch: 170 loss: 0.5205280184745789\n",
      "epoch: 170 loss: 0.3644300401210785\n",
      "epoch: 170 loss: 0.423361212015152\n",
      "epoch: 170 loss: 0.2875653803348541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 170 loss: 0.23362389206886292\n",
      "epoch: 170 loss: 0.4702720642089844\n",
      "epoch: 170 loss: 0.3544173538684845\n",
      "epoch: 170 loss: 0.2518898844718933\n",
      "epoch: 170 loss: 0.29973074793815613\n",
      "epoch: 170 loss: 0.3348163068294525\n",
      "epoch: 170 acc: 0.5364583333333334\n",
      "epoch: 171 loss: 0.31773507595062256\n",
      "epoch: 171 loss: 0.32132112979888916\n",
      "epoch: 171 loss: 0.3234366178512573\n",
      "epoch: 171 loss: 0.4633745849132538\n",
      "epoch: 171 loss: 0.35792601108551025\n",
      "epoch: 171 loss: 0.4781886637210846\n",
      "epoch: 171 loss: 0.24897518754005432\n",
      "epoch: 171 loss: 0.21238315105438232\n",
      "epoch: 171 loss: 0.47030866146087646\n",
      "epoch: 171 loss: 0.367419958114624\n",
      "epoch: 171 loss: 0.24631398916244507\n",
      "epoch: 171 loss: 0.2910158634185791\n",
      "epoch: 171 loss: 0.35681119561195374\n",
      "epoch: 171 acc: 0.5364583333333334\n",
      "epoch: 172 loss: 0.3047420382499695\n",
      "epoch: 172 loss: 0.34231850504875183\n",
      "epoch: 172 loss: 0.3351570665836334\n",
      "epoch: 172 loss: 0.5178828239440918\n",
      "epoch: 172 loss: 0.35111507773399353\n",
      "epoch: 172 loss: 0.43967586755752563\n",
      "epoch: 172 loss: 0.2531053423881531\n",
      "epoch: 172 loss: 0.20066507160663605\n",
      "epoch: 172 loss: 0.46654126048088074\n",
      "epoch: 172 loss: 0.41924747824668884\n",
      "epoch: 172 loss: 0.2209319919347763\n",
      "epoch: 172 loss: 0.3031351566314697\n",
      "epoch: 172 loss: 0.28739792108535767\n",
      "epoch: 172 acc: 0.515625\n",
      "epoch: 173 loss: 0.29141151905059814\n",
      "epoch: 173 loss: 0.34331178665161133\n",
      "epoch: 173 loss: 0.3156570494174957\n",
      "epoch: 173 loss: 0.38691744208335876\n",
      "epoch: 173 loss: 0.353304922580719\n",
      "epoch: 173 loss: 0.4716537892818451\n",
      "epoch: 173 loss: 0.27020692825317383\n",
      "epoch: 173 loss: 0.17910920083522797\n",
      "epoch: 173 loss: 0.4511144161224365\n",
      "epoch: 173 loss: 0.4248465299606323\n",
      "epoch: 173 loss: 0.218430757522583\n",
      "epoch: 173 loss: 0.2860219180583954\n",
      "epoch: 173 loss: 0.28264153003692627\n",
      "epoch: 173 acc: 0.5260416666666666\n",
      "epoch: 174 loss: 0.30744484066963196\n",
      "epoch: 174 loss: 0.34945839643478394\n",
      "epoch: 174 loss: 0.32875028252601624\n",
      "epoch: 174 loss: 0.4042940139770508\n",
      "epoch: 174 loss: 0.350536584854126\n",
      "epoch: 174 loss: 0.49999794363975525\n",
      "epoch: 174 loss: 0.32165202498435974\n",
      "epoch: 174 loss: 0.21596801280975342\n",
      "epoch: 174 loss: 0.4516991078853607\n",
      "epoch: 174 loss: 0.3801032602787018\n",
      "epoch: 174 loss: 0.2548518776893616\n",
      "epoch: 174 loss: 0.31152090430259705\n",
      "epoch: 174 loss: 0.3997936248779297\n",
      "epoch: 174 acc: 0.53125\n",
      "epoch: 175 loss: 0.38182908296585083\n",
      "epoch: 175 loss: 0.3570476472377777\n",
      "epoch: 175 loss: 0.3327106833457947\n",
      "epoch: 175 loss: 0.5518301725387573\n",
      "epoch: 175 loss: 0.42168909311294556\n",
      "epoch: 175 loss: 0.5696543455123901\n",
      "epoch: 175 loss: 0.3247961103916168\n",
      "epoch: 175 loss: 0.2657935321331024\n",
      "epoch: 175 loss: 0.46571075916290283\n",
      "epoch: 175 loss: 0.3964051604270935\n",
      "epoch: 175 loss: 0.3029436767101288\n",
      "epoch: 175 loss: 0.36655426025390625\n",
      "epoch: 175 loss: 0.41425666213035583\n",
      "epoch: 175 acc: 0.5416666666666666\n",
      "epoch: 176 loss: 0.3707612454891205\n",
      "epoch: 176 loss: 0.3430578410625458\n",
      "epoch: 176 loss: 0.3587633967399597\n",
      "epoch: 176 loss: 0.5790430903434753\n",
      "epoch: 176 loss: 0.4320807456970215\n",
      "epoch: 176 loss: 0.569218635559082\n",
      "epoch: 176 loss: 0.2756778299808502\n",
      "epoch: 176 loss: 0.19442231953144073\n",
      "epoch: 176 loss: 0.4657319188117981\n",
      "epoch: 176 loss: 0.4290415942668915\n",
      "epoch: 176 loss: 0.2729239761829376\n",
      "epoch: 176 loss: 0.34117138385772705\n",
      "epoch: 176 loss: 0.3504626154899597\n",
      "epoch: 176 acc: 0.5260416666666666\n",
      "epoch: 177 loss: 0.3182624578475952\n",
      "epoch: 177 loss: 0.39062753319740295\n",
      "epoch: 177 loss: 0.31160619854927063\n",
      "epoch: 177 loss: 0.44349077343940735\n",
      "epoch: 177 loss: 0.34830954670906067\n",
      "epoch: 177 loss: 0.5072811841964722\n",
      "epoch: 177 loss: 0.3129246234893799\n",
      "epoch: 177 loss: 0.196449875831604\n",
      "epoch: 177 loss: 0.4803040623664856\n",
      "epoch: 177 loss: 0.42170262336730957\n",
      "epoch: 177 loss: 0.23552663624286652\n",
      "epoch: 177 loss: 0.3016473054885864\n",
      "epoch: 177 loss: 0.3676150441169739\n",
      "epoch: 177 acc: 0.5364583333333334\n",
      "epoch: 178 loss: 0.3119979798793793\n",
      "epoch: 178 loss: 0.3828482925891876\n",
      "epoch: 178 loss: 0.36031249165534973\n",
      "epoch: 178 loss: 0.452027291059494\n",
      "epoch: 178 loss: 0.39862722158432007\n",
      "epoch: 178 loss: 0.46326473355293274\n",
      "epoch: 178 loss: 0.32064884901046753\n",
      "epoch: 178 loss: 0.23347194492816925\n",
      "epoch: 178 loss: 0.46027427911758423\n",
      "epoch: 178 loss: 0.39343175292015076\n",
      "epoch: 178 loss: 0.24765807390213013\n",
      "epoch: 178 loss: 0.3848443329334259\n",
      "epoch: 178 loss: 0.3903072476387024\n",
      "epoch: 178 acc: 0.5208333333333334\n",
      "epoch: 179 loss: 0.3927426040172577\n",
      "epoch: 179 loss: 0.3592708706855774\n",
      "epoch: 179 loss: 0.3154325783252716\n",
      "epoch: 179 loss: 0.4609105885028839\n",
      "epoch: 179 loss: 0.3999192416667938\n",
      "epoch: 179 loss: 0.5351701378822327\n",
      "epoch: 179 loss: 0.41205689311027527\n",
      "epoch: 179 loss: 0.36236441135406494\n",
      "epoch: 179 loss: 0.4797002375125885\n",
      "epoch: 179 loss: 0.32939067482948303\n",
      "epoch: 179 loss: 0.2880258560180664\n",
      "epoch: 179 loss: 0.358442097902298\n",
      "epoch: 179 loss: 0.7016311883926392\n",
      "epoch: 179 acc: 0.5416666666666666\n",
      "epoch: 180 loss: 0.5548739433288574\n",
      "epoch: 180 loss: 0.42671725153923035\n",
      "epoch: 180 loss: 0.3322201371192932\n",
      "epoch: 180 loss: 0.5181280970573425\n",
      "epoch: 180 loss: 0.5048404335975647\n",
      "epoch: 180 loss: 0.857589840888977\n",
      "epoch: 180 loss: 0.4426228106021881\n",
      "epoch: 180 loss: 0.32627931237220764\n",
      "epoch: 180 loss: 0.5162053108215332\n",
      "epoch: 180 loss: 0.4481674134731293\n",
      "epoch: 180 loss: 0.48161664605140686\n",
      "epoch: 180 loss: 0.5223472714424133\n",
      "epoch: 180 loss: 0.47682350873947144\n",
      "epoch: 180 acc: 0.5572916666666666\n",
      "epoch: 181 loss: 0.4830376207828522\n",
      "epoch: 181 loss: 0.3789752125740051\n",
      "epoch: 181 loss: 0.397391140460968\n",
      "epoch: 181 loss: 0.5231855511665344\n",
      "epoch: 181 loss: 0.43470433354377747\n",
      "epoch: 181 loss: 0.6527979969978333\n",
      "epoch: 181 loss: 0.3289826810359955\n",
      "epoch: 181 loss: 0.23847979307174683\n",
      "epoch: 181 loss: 0.492530882358551\n",
      "epoch: 181 loss: 0.33079931139945984\n",
      "epoch: 181 loss: 0.24565976858139038\n",
      "epoch: 181 loss: 0.30920690298080444\n",
      "epoch: 181 loss: 0.5660234093666077\n",
      "epoch: 181 acc: 0.53125\n",
      "epoch: 182 loss: 0.5579864382743835\n",
      "epoch: 182 loss: 0.39204496145248413\n",
      "epoch: 182 loss: 0.2890552282333374\n",
      "epoch: 182 loss: 0.45749950408935547\n",
      "epoch: 182 loss: 0.4556884765625\n",
      "epoch: 182 loss: 0.6146683096885681\n",
      "epoch: 182 loss: 0.5167990922927856\n",
      "epoch: 182 loss: 0.3901713788509369\n",
      "epoch: 182 loss: 0.5576838850975037\n",
      "epoch: 182 loss: 0.36616405844688416\n",
      "epoch: 182 loss: 0.34881889820098877\n",
      "epoch: 182 loss: 0.4308883845806122\n",
      "epoch: 182 loss: 0.5444588661193848\n",
      "epoch: 182 acc: 0.5625\n",
      "epoch: 183 loss: 0.7728214263916016\n",
      "epoch: 183 loss: 0.44021427631378174\n",
      "epoch: 183 loss: 0.4646916091442108\n",
      "epoch: 183 loss: 0.4629775285720825\n",
      "epoch: 183 loss: 0.42058995366096497\n",
      "epoch: 183 loss: 0.6502551436424255\n",
      "epoch: 183 loss: 0.4310778081417084\n",
      "epoch: 183 loss: 0.44372907280921936\n",
      "epoch: 183 loss: 0.5440014600753784\n",
      "epoch: 183 loss: 0.3279877007007599\n",
      "epoch: 183 loss: 0.20900310575962067\n",
      "epoch: 183 loss: 0.3873429298400879\n",
      "epoch: 183 loss: 0.4602762758731842\n",
      "epoch: 183 acc: 0.546875\n",
      "epoch: 184 loss: 0.6465139389038086\n",
      "epoch: 184 loss: 0.4132238030433655\n",
      "epoch: 184 loss: 0.48957279324531555\n",
      "epoch: 184 loss: 0.4650077819824219\n",
      "epoch: 184 loss: 0.4578799605369568\n",
      "epoch: 184 loss: 0.6850746870040894\n",
      "epoch: 184 loss: 0.44560229778289795\n",
      "epoch: 184 loss: 0.3860156536102295\n",
      "epoch: 184 loss: 0.4742886424064636\n",
      "epoch: 184 loss: 0.3980947434902191\n",
      "epoch: 184 loss: 0.24100454151630402\n",
      "epoch: 184 loss: 0.3747073709964752\n",
      "epoch: 184 loss: 0.6011930108070374\n",
      "epoch: 184 acc: 0.5625\n",
      "epoch: 185 loss: 0.5770450234413147\n",
      "epoch: 185 loss: 0.41044437885284424\n",
      "epoch: 185 loss: 0.36267584562301636\n",
      "epoch: 185 loss: 0.4765150547027588\n",
      "epoch: 185 loss: 0.4736206829547882\n",
      "epoch: 185 loss: 0.6386508941650391\n",
      "epoch: 185 loss: 0.4148636758327484\n",
      "epoch: 185 loss: 0.3958466053009033\n",
      "epoch: 185 loss: 0.5404409170150757\n",
      "epoch: 185 loss: 0.4563329815864563\n",
      "epoch: 185 loss: 0.39189213514328003\n",
      "epoch: 185 loss: 0.4515495002269745\n",
      "epoch: 185 loss: 0.6600474119186401\n",
      "epoch: 185 acc: 0.5729166666666666\n",
      "epoch: 186 loss: 0.8881877064704895\n",
      "epoch: 186 loss: 0.5156159400939941\n",
      "epoch: 186 loss: 0.4597514569759369\n",
      "epoch: 186 loss: 0.49329519271850586\n",
      "epoch: 186 loss: 0.5892220735549927\n",
      "epoch: 186 loss: 0.5533862709999084\n",
      "epoch: 186 loss: 0.3903033435344696\n",
      "epoch: 186 loss: 0.3955778479576111\n",
      "epoch: 186 loss: 0.6350492238998413\n",
      "epoch: 186 loss: 0.34682944416999817\n",
      "epoch: 186 loss: 0.24214337766170502\n",
      "epoch: 186 loss: 0.34850502014160156\n",
      "epoch: 186 loss: 0.44084909558296204\n",
      "epoch: 186 acc: 0.5833333333333334\n",
      "epoch: 187 loss: 0.49991607666015625\n",
      "epoch: 187 loss: 0.3276916742324829\n",
      "epoch: 187 loss: 0.30758771300315857\n",
      "epoch: 187 loss: 0.5113118886947632\n",
      "epoch: 187 loss: 0.4459530711174011\n",
      "epoch: 187 loss: 0.4271715581417084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 187 loss: 0.41202086210250854\n",
      "epoch: 187 loss: 0.32374998927116394\n",
      "epoch: 187 loss: 0.573282778263092\n",
      "epoch: 187 loss: 0.40223294496536255\n",
      "epoch: 187 loss: 0.28316766023635864\n",
      "epoch: 187 loss: 0.4120195806026459\n",
      "epoch: 187 loss: 0.39284563064575195\n",
      "epoch: 187 acc: 0.5520833333333334\n",
      "epoch: 188 loss: 0.5179316401481628\n",
      "epoch: 188 loss: 0.4339301586151123\n",
      "epoch: 188 loss: 0.3813290297985077\n",
      "epoch: 188 loss: 0.41175177693367004\n",
      "epoch: 188 loss: 0.42741307616233826\n",
      "epoch: 188 loss: 0.5142290592193604\n",
      "epoch: 188 loss: 0.4281335473060608\n",
      "epoch: 188 loss: 0.3567453920841217\n",
      "epoch: 188 loss: 0.5242341160774231\n",
      "epoch: 188 loss: 0.3445911705493927\n",
      "epoch: 188 loss: 0.24136851727962494\n",
      "epoch: 188 loss: 0.36213478446006775\n",
      "epoch: 188 loss: 0.3854679763317108\n",
      "epoch: 188 acc: 0.5677083333333334\n",
      "epoch: 189 loss: 0.48446783423423767\n",
      "epoch: 189 loss: 0.3826647400856018\n",
      "epoch: 189 loss: 0.38720810413360596\n",
      "epoch: 189 loss: 0.5445411801338196\n",
      "epoch: 189 loss: 0.3297213613986969\n",
      "epoch: 189 loss: 0.4009508192539215\n",
      "epoch: 189 loss: 0.43742823600769043\n",
      "epoch: 189 loss: 0.3856642246246338\n",
      "epoch: 189 loss: 0.5323050618171692\n",
      "epoch: 189 loss: 0.35625115036964417\n",
      "epoch: 189 loss: 0.2686791718006134\n",
      "epoch: 189 loss: 0.4018681049346924\n",
      "epoch: 189 loss: 0.3170507848262787\n",
      "epoch: 189 acc: 0.5416666666666666\n",
      "epoch: 190 loss: 0.494363009929657\n",
      "epoch: 190 loss: 0.44731828570365906\n",
      "epoch: 190 loss: 0.4623083174228668\n",
      "epoch: 190 loss: 0.45410898327827454\n",
      "epoch: 190 loss: 0.3825248181819916\n",
      "epoch: 190 loss: 0.42399272322654724\n",
      "epoch: 190 loss: 0.5140950083732605\n",
      "epoch: 190 loss: 0.3861071467399597\n",
      "epoch: 190 loss: 0.5866438746452332\n",
      "epoch: 190 loss: 0.44613534212112427\n",
      "epoch: 190 loss: 0.26768308877944946\n",
      "epoch: 190 loss: 0.33529043197631836\n",
      "epoch: 190 loss: 0.4525359272956848\n",
      "epoch: 190 acc: 0.5729166666666666\n",
      "epoch: 191 loss: 0.5596739053726196\n",
      "epoch: 191 loss: 0.3859432637691498\n",
      "epoch: 191 loss: 0.6042724251747131\n",
      "epoch: 191 loss: 0.5440894961357117\n",
      "epoch: 191 loss: 0.4665237069129944\n",
      "epoch: 191 loss: 0.6420654058456421\n",
      "epoch: 191 loss: 0.48042893409729004\n",
      "epoch: 191 loss: 0.5599533915519714\n",
      "epoch: 191 loss: 0.5783004760742188\n",
      "epoch: 191 loss: 0.5533270835876465\n",
      "epoch: 191 loss: 0.3168586492538452\n",
      "epoch: 191 loss: 0.5869426131248474\n",
      "epoch: 191 loss: 0.3554615080356598\n",
      "epoch: 191 acc: 0.546875\n",
      "epoch: 192 loss: 0.4859660267829895\n",
      "epoch: 192 loss: 0.5104195475578308\n",
      "epoch: 192 loss: 0.5380098819732666\n",
      "epoch: 192 loss: 0.6492592096328735\n",
      "epoch: 192 loss: 0.5845957398414612\n",
      "epoch: 192 loss: 0.39045250415802\n",
      "epoch: 192 loss: 0.3520745038986206\n",
      "epoch: 192 loss: 0.25570225715637207\n",
      "epoch: 192 loss: 0.5462073683738708\n",
      "epoch: 192 loss: 0.4252736568450928\n",
      "epoch: 192 loss: 0.2803826630115509\n",
      "epoch: 192 loss: 0.3504171371459961\n",
      "epoch: 192 loss: 0.34834158420562744\n",
      "epoch: 192 acc: 0.546875\n",
      "epoch: 193 loss: 0.41480737924575806\n",
      "epoch: 193 loss: 0.42515307664871216\n",
      "epoch: 193 loss: 0.33442172408103943\n",
      "epoch: 193 loss: 0.615342915058136\n",
      "epoch: 193 loss: 0.3662828505039215\n",
      "epoch: 193 loss: 0.6325981020927429\n",
      "epoch: 193 loss: 0.4970667362213135\n",
      "epoch: 193 loss: 0.36060452461242676\n",
      "epoch: 193 loss: 0.6387736797332764\n",
      "epoch: 193 loss: 0.5411438345909119\n",
      "epoch: 193 loss: 0.34968721866607666\n",
      "epoch: 193 loss: 0.4732007682323456\n",
      "epoch: 193 loss: 0.4726230502128601\n",
      "epoch: 193 acc: 0.5572916666666666\n",
      "epoch: 194 loss: 0.5796406269073486\n",
      "epoch: 194 loss: 0.4822627604007721\n",
      "epoch: 194 loss: 0.5518634915351868\n",
      "epoch: 194 loss: 0.6746602058410645\n",
      "epoch: 194 loss: 0.6521251201629639\n",
      "epoch: 194 loss: 0.5763494968414307\n",
      "epoch: 194 loss: 0.357250452041626\n",
      "epoch: 194 loss: 0.3466310203075409\n",
      "epoch: 194 loss: 0.6698516607284546\n",
      "epoch: 194 loss: 0.34636011719703674\n",
      "epoch: 194 loss: 0.2719395160675049\n",
      "epoch: 194 loss: 0.3233068585395813\n",
      "epoch: 194 loss: 0.29550856351852417\n",
      "epoch: 194 acc: 0.5677083333333334\n",
      "epoch: 195 loss: 0.42600497603416443\n",
      "epoch: 195 loss: 0.36254453659057617\n",
      "epoch: 195 loss: 0.3367256820201874\n",
      "epoch: 195 loss: 0.5390751361846924\n",
      "epoch: 195 loss: 0.363434761762619\n",
      "epoch: 195 loss: 0.42386242747306824\n",
      "epoch: 195 loss: 0.38379353284835815\n",
      "epoch: 195 loss: 0.29150888323783875\n",
      "epoch: 195 loss: 0.49292638897895813\n",
      "epoch: 195 loss: 0.31131330132484436\n",
      "epoch: 195 loss: 0.22077299654483795\n",
      "epoch: 195 loss: 0.3347523510456085\n",
      "epoch: 195 loss: 0.3407948911190033\n",
      "epoch: 195 acc: 0.5364583333333334\n",
      "epoch: 196 loss: 0.4230709671974182\n",
      "epoch: 196 loss: 0.38213157653808594\n",
      "epoch: 196 loss: 0.350253701210022\n",
      "epoch: 196 loss: 0.2960187494754791\n",
      "epoch: 196 loss: 0.35058659315109253\n",
      "epoch: 196 loss: 0.4881912171840668\n",
      "epoch: 196 loss: 0.37653860449790955\n",
      "epoch: 196 loss: 0.32254329323768616\n",
      "epoch: 196 loss: 0.451151579618454\n",
      "epoch: 196 loss: 0.40692588686943054\n",
      "epoch: 196 loss: 0.28526610136032104\n",
      "epoch: 196 loss: 0.4259205162525177\n",
      "epoch: 196 loss: 0.30934977531433105\n",
      "epoch: 196 acc: 0.546875\n",
      "epoch: 197 loss: 0.3745342493057251\n",
      "epoch: 197 loss: 0.3571682274341583\n",
      "epoch: 197 loss: 0.42442435026168823\n",
      "epoch: 197 loss: 0.435761034488678\n",
      "epoch: 197 loss: 0.3241839110851288\n",
      "epoch: 197 loss: 0.35789021849632263\n",
      "epoch: 197 loss: 0.4046243727207184\n",
      "epoch: 197 loss: 0.24712397158145905\n",
      "epoch: 197 loss: 0.4503673017024994\n",
      "epoch: 197 loss: 0.38728073239326477\n",
      "epoch: 197 loss: 0.23918645083904266\n",
      "epoch: 197 loss: 0.32586461305618286\n",
      "epoch: 197 loss: 0.34145650267601013\n",
      "epoch: 197 acc: 0.5364583333333334\n",
      "epoch: 198 loss: 0.40761798620224\n",
      "epoch: 198 loss: 0.309273898601532\n",
      "epoch: 198 loss: 0.3298715651035309\n",
      "epoch: 198 loss: 0.3524726927280426\n",
      "epoch: 198 loss: 0.32723233103752136\n",
      "epoch: 198 loss: 0.40893006324768066\n",
      "epoch: 198 loss: 0.39322564005851746\n",
      "epoch: 198 loss: 0.34963685274124146\n",
      "epoch: 198 loss: 0.5119848251342773\n",
      "epoch: 198 loss: 0.4299914240837097\n",
      "epoch: 198 loss: 0.2416074573993683\n",
      "epoch: 198 loss: 0.29860973358154297\n",
      "epoch: 198 loss: 0.37560489773750305\n",
      "epoch: 198 acc: 0.5572916666666666\n",
      "epoch: 199 loss: 0.5018471479415894\n",
      "epoch: 199 loss: 0.3751380443572998\n",
      "epoch: 199 loss: 0.3869650363922119\n",
      "epoch: 199 loss: 0.3856416940689087\n",
      "epoch: 199 loss: 0.3060002326965332\n",
      "epoch: 199 loss: 0.4847205579280853\n",
      "epoch: 199 loss: 0.396780401468277\n",
      "epoch: 199 loss: 0.3670646846294403\n",
      "epoch: 199 loss: 0.5418945550918579\n",
      "epoch: 199 loss: 0.34277769923210144\n",
      "epoch: 199 loss: 0.2585894763469696\n",
      "epoch: 199 loss: 0.30479902029037476\n",
      "epoch: 199 loss: 0.35831430554389954\n",
      "epoch: 199 acc: 0.5572916666666666\n"
     ]
    }
   ],
   "source": [
    "global_step = 0\n",
    "for epoch in range(200):\n",
    "    model.train()\n",
    "    for i in range(int(len(train_data) / batchsz)):\n",
    "        x = train_data[batchsz * i: batchsz * (i + 1)]\n",
    "        label = train_label[batchsz * i: batchsz * (i + 1)]\n",
    "        x, label = x.to(device), label.to(device)\n",
    "        \n",
    "        logits = model(x).squeeze(1)\n",
    "        loss = criteon(logits, label)\n",
    "        \n",
    "        # backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        global_step += 1\n",
    "        viz.line([loss.item()], [global_step], win='Training_Loss', update='append')\n",
    "\n",
    "        print('epoch:', epoch, 'loss:', loss.item())\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_correct = 0\n",
    "        total_num = 0\n",
    "        test_loss = 0\n",
    "\n",
    "        for i in range(int(len(test_data) / batchsz)):  \n",
    "            \n",
    "            # label: [100]\n",
    "            x = test_data[batchsz * i: batchsz * (i + 1)]\n",
    "            label = test_label[batchsz * i: batchsz * (i + 1)]\n",
    "            x, label = x.to(device), label.to(device)\n",
    "            \n",
    "            # logits: [100, 2]\n",
    "            logits = model(x).squeeze(1)\n",
    "            test_loss += criteon(logits, label).item()\n",
    "\n",
    "            pred = logits.argmax(dim=1)\n",
    "            total_correct += torch.eq(pred, label).float().sum().item()\n",
    "            total_num += x.size(0)\n",
    "\n",
    "        acc = total_correct / total_num\n",
    "        print('epoch:', epoch, 'acc:', acc)\n",
    "        # print('logits:', logits)\n",
    "\n",
    "        viz.line([test_loss], [global_step], win='Testing_Loss', opts=dict(title='Testing loss'), update='append')\n",
    "        viz.line([acc], [global_step], win='Accuracy', opts=dict(title='Accuracy'), update='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646951f0",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7526fd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lenet import Lenet5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "38a559a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.expand_dims(up2dn_data_fram,axis=1)\n",
    "label = up2dn_label_fram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "58e1ef74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机打乱\n",
    "np.random.seed(5)\n",
    "np.random.shuffle(data)\n",
    "np.random.shuffle(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "366786df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.from_numpy(data[int(len(data)/3):])\n",
    "train_data = train_data.type(torch.FloatTensor)\n",
    "\n",
    "test_data = torch.from_numpy(data[:int(len(data)/3)])\n",
    "test_data = test_data.type(torch.FloatTensor)\n",
    "\n",
    "train_label = torch.from_numpy(label[int(len(data)/3):])\n",
    "train_label = torch.as_tensor(train_label, dtype=torch.long)\n",
    "\n",
    "test_label = torch.from_numpy(label[:int(len(data)/3)])\n",
    "test_label = torch.as_tensor(test_label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "728f921b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Lenet5().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "83d0550f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Accuracy'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viz = Visdom()\n",
    "viz.line([0.], [0.], win='Training_Loss', opts=dict(title='Training loss'))\n",
    "viz.line([0.], [0.], win='Training_Accuracy', opts=dict(title='Training accuracy'))\n",
    "viz.line([0.], [0.], win='Testing_Loss', opts=dict(title='Testing loss'))\n",
    "viz.line([0.], [0.], win='Accuracy', opts=dict(title='Accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "015de61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: 0.6988680958747864\n",
      "epoch: 0 loss: 0.6938843131065369\n",
      "epoch: 0 loss: 0.697181761264801\n",
      "epoch: 0 loss: 0.6860491037368774\n",
      "epoch: 0 loss: 0.7120947241783142\n",
      "epoch: 0 loss: 0.7033352851867676\n",
      "epoch: 0 acc: 0.5208333333333334\n",
      "epoch: 1 loss: 0.6988680958747864\n",
      "epoch: 1 loss: 0.6938843131065369\n",
      "epoch: 1 loss: 0.697181761264801\n",
      "epoch: 1 loss: 0.6860491037368774\n",
      "epoch: 1 loss: 0.7120947241783142\n",
      "epoch: 1 loss: 0.7033352851867676\n",
      "epoch: 1 acc: 0.5208333333333334\n",
      "epoch: 2 loss: 0.6988680958747864\n",
      "epoch: 2 loss: 0.6938843131065369\n",
      "epoch: 2 loss: 0.697181761264801\n",
      "epoch: 2 loss: 0.6860491037368774\n",
      "epoch: 2 loss: 0.7120947241783142\n",
      "epoch: 2 loss: 0.7033352851867676\n",
      "epoch: 2 acc: 0.5208333333333334\n",
      "epoch: 3 loss: 0.6988680958747864\n",
      "epoch: 3 loss: 0.6938843131065369\n",
      "epoch: 3 loss: 0.697181761264801\n",
      "epoch: 3 loss: 0.6860491037368774\n",
      "epoch: 3 loss: 0.7120947241783142\n",
      "epoch: 3 loss: 0.7033352851867676\n",
      "epoch: 3 acc: 0.5208333333333334\n",
      "epoch: 4 loss: 0.6988680958747864\n",
      "epoch: 4 loss: 0.6938843131065369\n",
      "epoch: 4 loss: 0.697181761264801\n",
      "epoch: 4 loss: 0.6860491037368774\n",
      "epoch: 4 loss: 0.7120947241783142\n",
      "epoch: 4 loss: 0.7033352851867676\n",
      "epoch: 4 acc: 0.5208333333333334\n",
      "epoch: 5 loss: 0.6988680958747864\n",
      "epoch: 5 loss: 0.6938843131065369\n",
      "epoch: 5 loss: 0.697181761264801\n",
      "epoch: 5 loss: 0.6860491037368774\n",
      "epoch: 5 loss: 0.7120947241783142\n",
      "epoch: 5 loss: 0.7033352851867676\n",
      "epoch: 5 acc: 0.5208333333333334\n",
      "epoch: 6 loss: 0.6988680958747864\n",
      "epoch: 6 loss: 0.6938843131065369\n",
      "epoch: 6 loss: 0.697181761264801\n",
      "epoch: 6 loss: 0.6860491037368774\n",
      "epoch: 6 loss: 0.7120947241783142\n",
      "epoch: 6 loss: 0.7033352851867676\n",
      "epoch: 6 acc: 0.5208333333333334\n",
      "epoch: 7 loss: 0.6988680958747864\n",
      "epoch: 7 loss: 0.6938843131065369\n",
      "epoch: 7 loss: 0.697181761264801\n",
      "epoch: 7 loss: 0.6860491037368774\n",
      "epoch: 7 loss: 0.7120947241783142\n",
      "epoch: 7 loss: 0.7033352851867676\n",
      "epoch: 7 acc: 0.5208333333333334\n",
      "epoch: 8 loss: 0.6988680958747864\n",
      "epoch: 8 loss: 0.6938843131065369\n",
      "epoch: 8 loss: 0.697181761264801\n",
      "epoch: 8 loss: 0.6860491037368774\n",
      "epoch: 8 loss: 0.7120947241783142\n",
      "epoch: 8 loss: 0.7033352851867676\n",
      "epoch: 8 acc: 0.5208333333333334\n",
      "epoch: 9 loss: 0.6988680958747864\n",
      "epoch: 9 loss: 0.6938843131065369\n",
      "epoch: 9 loss: 0.697181761264801\n",
      "epoch: 9 loss: 0.6860491037368774\n",
      "epoch: 9 loss: 0.7120947241783142\n",
      "epoch: 9 loss: 0.7033352851867676\n",
      "epoch: 9 acc: 0.5208333333333334\n",
      "epoch: 10 loss: 0.6988680958747864\n",
      "epoch: 10 loss: 0.6938843131065369\n",
      "epoch: 10 loss: 0.697181761264801\n",
      "epoch: 10 loss: 0.6860491037368774\n",
      "epoch: 10 loss: 0.7120947241783142\n",
      "epoch: 10 loss: 0.7033352851867676\n",
      "epoch: 10 acc: 0.5208333333333334\n",
      "epoch: 11 loss: 0.6988680958747864\n",
      "epoch: 11 loss: 0.6938843131065369\n",
      "epoch: 11 loss: 0.697181761264801\n",
      "epoch: 11 loss: 0.6860491037368774\n",
      "epoch: 11 loss: 0.7120947241783142\n",
      "epoch: 11 loss: 0.7033352851867676\n",
      "epoch: 11 acc: 0.5208333333333334\n",
      "epoch: 12 loss: 0.6988680958747864\n",
      "epoch: 12 loss: 0.6938843131065369\n",
      "epoch: 12 loss: 0.697181761264801\n",
      "epoch: 12 loss: 0.6860491037368774\n",
      "epoch: 12 loss: 0.7120947241783142\n",
      "epoch: 12 loss: 0.7033352851867676\n",
      "epoch: 12 acc: 0.5208333333333334\n",
      "epoch: 13 loss: 0.6988680958747864\n",
      "epoch: 13 loss: 0.6938843131065369\n",
      "epoch: 13 loss: 0.697181761264801\n",
      "epoch: 13 loss: 0.6860491037368774\n",
      "epoch: 13 loss: 0.7120947241783142\n",
      "epoch: 13 loss: 0.7033352851867676\n",
      "epoch: 13 acc: 0.5208333333333334\n",
      "epoch: 14 loss: 0.6988680958747864\n",
      "epoch: 14 loss: 0.6938843131065369\n",
      "epoch: 14 loss: 0.697181761264801\n",
      "epoch: 14 loss: 0.6860491037368774\n",
      "epoch: 14 loss: 0.7120947241783142\n",
      "epoch: 14 loss: 0.7033352851867676\n",
      "epoch: 14 acc: 0.5208333333333334\n",
      "epoch: 15 loss: 0.6988680958747864\n",
      "epoch: 15 loss: 0.6938843131065369\n",
      "epoch: 15 loss: 0.697181761264801\n",
      "epoch: 15 loss: 0.6860491037368774\n",
      "epoch: 15 loss: 0.7120947241783142\n",
      "epoch: 15 loss: 0.7033352851867676\n",
      "epoch: 15 acc: 0.5208333333333334\n",
      "epoch: 16 loss: 0.6988680958747864\n",
      "epoch: 16 loss: 0.6938843131065369\n",
      "epoch: 16 loss: 0.697181761264801\n",
      "epoch: 16 loss: 0.6860491037368774\n",
      "epoch: 16 loss: 0.7120947241783142\n",
      "epoch: 16 loss: 0.7033352851867676\n",
      "epoch: 16 acc: 0.5208333333333334\n",
      "epoch: 17 loss: 0.6988680958747864\n",
      "epoch: 17 loss: 0.6938843131065369\n",
      "epoch: 17 loss: 0.697181761264801\n",
      "epoch: 17 loss: 0.6860491037368774\n",
      "epoch: 17 loss: 0.7120947241783142\n",
      "epoch: 17 loss: 0.7033352851867676\n",
      "epoch: 17 acc: 0.5208333333333334\n",
      "epoch: 18 loss: 0.6988680958747864\n",
      "epoch: 18 loss: 0.6938843131065369\n",
      "epoch: 18 loss: 0.697181761264801\n",
      "epoch: 18 loss: 0.6860491037368774\n",
      "epoch: 18 loss: 0.7120947241783142\n",
      "epoch: 18 loss: 0.7033352851867676\n",
      "epoch: 18 acc: 0.5208333333333334\n",
      "epoch: 19 loss: 0.6988680958747864\n",
      "epoch: 19 loss: 0.6938843131065369\n",
      "epoch: 19 loss: 0.697181761264801\n",
      "epoch: 19 loss: 0.6860491037368774\n",
      "epoch: 19 loss: 0.7120947241783142\n",
      "epoch: 19 loss: 0.7033352851867676\n",
      "epoch: 19 acc: 0.5208333333333334\n",
      "epoch: 20 loss: 0.6988680958747864\n",
      "epoch: 20 loss: 0.6938843131065369\n",
      "epoch: 20 loss: 0.697181761264801\n",
      "epoch: 20 loss: 0.6860491037368774\n",
      "epoch: 20 loss: 0.7120947241783142\n",
      "epoch: 20 loss: 0.7033352851867676\n",
      "epoch: 20 acc: 0.5208333333333334\n",
      "epoch: 21 loss: 0.6988680958747864\n",
      "epoch: 21 loss: 0.6938843131065369\n",
      "epoch: 21 loss: 0.697181761264801\n",
      "epoch: 21 loss: 0.6860491037368774\n",
      "epoch: 21 loss: 0.7120947241783142\n",
      "epoch: 21 loss: 0.7033352851867676\n",
      "epoch: 21 acc: 0.5208333333333334\n",
      "epoch: 22 loss: 0.6988680958747864\n",
      "epoch: 22 loss: 0.6938843131065369\n",
      "epoch: 22 loss: 0.697181761264801\n",
      "epoch: 22 loss: 0.6860491037368774\n",
      "epoch: 22 loss: 0.7120947241783142\n",
      "epoch: 22 loss: 0.7033352851867676\n",
      "epoch: 22 acc: 0.5208333333333334\n",
      "epoch: 23 loss: 0.6988680958747864\n",
      "epoch: 23 loss: 0.6938843131065369\n",
      "epoch: 23 loss: 0.697181761264801\n",
      "epoch: 23 loss: 0.6860491037368774\n",
      "epoch: 23 loss: 0.7120947241783142\n",
      "epoch: 23 loss: 0.7033352851867676\n",
      "epoch: 23 acc: 0.5208333333333334\n",
      "epoch: 24 loss: 0.6988680958747864\n",
      "epoch: 24 loss: 0.6938843131065369\n",
      "epoch: 24 loss: 0.697181761264801\n",
      "epoch: 24 loss: 0.6860491037368774\n",
      "epoch: 24 loss: 0.7120947241783142\n",
      "epoch: 24 loss: 0.7033352851867676\n",
      "epoch: 24 acc: 0.5208333333333334\n",
      "epoch: 25 loss: 0.6988680958747864\n",
      "epoch: 25 loss: 0.6938843131065369\n",
      "epoch: 25 loss: 0.697181761264801\n",
      "epoch: 25 loss: 0.6860491037368774\n",
      "epoch: 25 loss: 0.7120947241783142\n",
      "epoch: 25 loss: 0.7033352851867676\n",
      "epoch: 25 acc: 0.5208333333333334\n",
      "epoch: 26 loss: 0.6988680958747864\n",
      "epoch: 26 loss: 0.6938843131065369\n",
      "epoch: 26 loss: 0.697181761264801\n",
      "epoch: 26 loss: 0.6860491037368774\n",
      "epoch: 26 loss: 0.7120947241783142\n",
      "epoch: 26 loss: 0.7033352851867676\n",
      "epoch: 26 acc: 0.5208333333333334\n",
      "epoch: 27 loss: 0.6988680958747864\n",
      "epoch: 27 loss: 0.6938843131065369\n",
      "epoch: 27 loss: 0.697181761264801\n",
      "epoch: 27 loss: 0.6860491037368774\n",
      "epoch: 27 loss: 0.7120947241783142\n",
      "epoch: 27 loss: 0.7033352851867676\n",
      "epoch: 27 acc: 0.5208333333333334\n",
      "epoch: 28 loss: 0.6988680958747864\n",
      "epoch: 28 loss: 0.6938843131065369\n",
      "epoch: 28 loss: 0.697181761264801\n",
      "epoch: 28 loss: 0.6860491037368774\n",
      "epoch: 28 loss: 0.7120947241783142\n",
      "epoch: 28 loss: 0.7033352851867676\n",
      "epoch: 28 acc: 0.5208333333333334\n",
      "epoch: 29 loss: 0.6988680958747864\n",
      "epoch: 29 loss: 0.6938843131065369\n",
      "epoch: 29 loss: 0.697181761264801\n",
      "epoch: 29 loss: 0.6860491037368774\n",
      "epoch: 29 loss: 0.7120947241783142\n",
      "epoch: 29 loss: 0.7033352851867676\n",
      "epoch: 29 acc: 0.5208333333333334\n",
      "epoch: 30 loss: 0.6988680958747864\n",
      "epoch: 30 loss: 0.6938843131065369\n",
      "epoch: 30 loss: 0.697181761264801\n",
      "epoch: 30 loss: 0.6860491037368774\n",
      "epoch: 30 loss: 0.7120947241783142\n",
      "epoch: 30 loss: 0.7033352851867676\n",
      "epoch: 30 acc: 0.5208333333333334\n",
      "epoch: 31 loss: 0.6988680958747864\n",
      "epoch: 31 loss: 0.6938843131065369\n",
      "epoch: 31 loss: 0.697181761264801\n",
      "epoch: 31 loss: 0.6860491037368774\n",
      "epoch: 31 loss: 0.7120947241783142\n",
      "epoch: 31 loss: 0.7033352851867676\n",
      "epoch: 31 acc: 0.5208333333333334\n",
      "epoch: 32 loss: 0.6988680958747864\n",
      "epoch: 32 loss: 0.6938843131065369\n",
      "epoch: 32 loss: 0.697181761264801\n",
      "epoch: 32 loss: 0.6860491037368774\n",
      "epoch: 32 loss: 0.7120947241783142\n",
      "epoch: 32 loss: 0.7033352851867676\n",
      "epoch: 32 acc: 0.5208333333333334\n",
      "epoch: 33 loss: 0.6988680958747864\n",
      "epoch: 33 loss: 0.6938843131065369\n",
      "epoch: 33 loss: 0.697181761264801\n",
      "epoch: 33 loss: 0.6860491037368774\n",
      "epoch: 33 loss: 0.7120947241783142\n",
      "epoch: 33 loss: 0.7033352851867676\n",
      "epoch: 33 acc: 0.5208333333333334\n",
      "epoch: 34 loss: 0.6988680958747864\n",
      "epoch: 34 loss: 0.6938843131065369\n",
      "epoch: 34 loss: 0.697181761264801\n",
      "epoch: 34 loss: 0.6860491037368774\n",
      "epoch: 34 loss: 0.7120947241783142\n",
      "epoch: 34 loss: 0.7033352851867676\n",
      "epoch: 34 acc: 0.5208333333333334\n",
      "epoch: 35 loss: 0.6988680958747864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 35 loss: 0.6938843131065369\n",
      "epoch: 35 loss: 0.697181761264801\n",
      "epoch: 35 loss: 0.6860491037368774\n",
      "epoch: 35 loss: 0.7120947241783142\n",
      "epoch: 35 loss: 0.7033352851867676\n",
      "epoch: 35 acc: 0.5208333333333334\n",
      "epoch: 36 loss: 0.6988680958747864\n",
      "epoch: 36 loss: 0.6938843131065369\n",
      "epoch: 36 loss: 0.697181761264801\n",
      "epoch: 36 loss: 0.6860491037368774\n",
      "epoch: 36 loss: 0.7120947241783142\n",
      "epoch: 36 loss: 0.7033352851867676\n",
      "epoch: 36 acc: 0.5208333333333334\n",
      "epoch: 37 loss: 0.6988680958747864\n",
      "epoch: 37 loss: 0.6938843131065369\n",
      "epoch: 37 loss: 0.697181761264801\n",
      "epoch: 37 loss: 0.6860491037368774\n",
      "epoch: 37 loss: 0.7120947241783142\n",
      "epoch: 37 loss: 0.7033352851867676\n",
      "epoch: 37 acc: 0.5208333333333334\n",
      "epoch: 38 loss: 0.6988680958747864\n",
      "epoch: 38 loss: 0.6938843131065369\n",
      "epoch: 38 loss: 0.697181761264801\n",
      "epoch: 38 loss: 0.6860491037368774\n",
      "epoch: 38 loss: 0.7120947241783142\n",
      "epoch: 38 loss: 0.7033352851867676\n",
      "epoch: 38 acc: 0.5208333333333334\n",
      "epoch: 39 loss: 0.6988680958747864\n",
      "epoch: 39 loss: 0.6938843131065369\n",
      "epoch: 39 loss: 0.697181761264801\n",
      "epoch: 39 loss: 0.6860491037368774\n",
      "epoch: 39 loss: 0.7120947241783142\n",
      "epoch: 39 loss: 0.7033352851867676\n",
      "epoch: 39 acc: 0.5208333333333334\n",
      "epoch: 40 loss: 0.6988680958747864\n",
      "epoch: 40 loss: 0.6938843131065369\n",
      "epoch: 40 loss: 0.697181761264801\n",
      "epoch: 40 loss: 0.6860491037368774\n",
      "epoch: 40 loss: 0.7120947241783142\n",
      "epoch: 40 loss: 0.7033352851867676\n",
      "epoch: 40 acc: 0.5208333333333334\n",
      "epoch: 41 loss: 0.6988680958747864\n",
      "epoch: 41 loss: 0.6938843131065369\n",
      "epoch: 41 loss: 0.697181761264801\n",
      "epoch: 41 loss: 0.6860491037368774\n",
      "epoch: 41 loss: 0.7120947241783142\n",
      "epoch: 41 loss: 0.7033352851867676\n",
      "epoch: 41 acc: 0.5208333333333334\n",
      "epoch: 42 loss: 0.6988680958747864\n",
      "epoch: 42 loss: 0.6938843131065369\n",
      "epoch: 42 loss: 0.697181761264801\n",
      "epoch: 42 loss: 0.6860491037368774\n",
      "epoch: 42 loss: 0.7120947241783142\n",
      "epoch: 42 loss: 0.7033352851867676\n",
      "epoch: 42 acc: 0.5208333333333334\n",
      "epoch: 43 loss: 0.6988680958747864\n",
      "epoch: 43 loss: 0.6938843131065369\n",
      "epoch: 43 loss: 0.697181761264801\n",
      "epoch: 43 loss: 0.6860491037368774\n",
      "epoch: 43 loss: 0.7120947241783142\n",
      "epoch: 43 loss: 0.7033352851867676\n",
      "epoch: 43 acc: 0.5208333333333334\n",
      "epoch: 44 loss: 0.6988680958747864\n",
      "epoch: 44 loss: 0.6938843131065369\n",
      "epoch: 44 loss: 0.697181761264801\n",
      "epoch: 44 loss: 0.6860491037368774\n",
      "epoch: 44 loss: 0.7120947241783142\n",
      "epoch: 44 loss: 0.7033352851867676\n",
      "epoch: 44 acc: 0.5208333333333334\n",
      "epoch: 45 loss: 0.6988680958747864\n",
      "epoch: 45 loss: 0.6938843131065369\n",
      "epoch: 45 loss: 0.697181761264801\n",
      "epoch: 45 loss: 0.6860491037368774\n",
      "epoch: 45 loss: 0.7120947241783142\n",
      "epoch: 45 loss: 0.7033352851867676\n",
      "epoch: 45 acc: 0.5208333333333334\n",
      "epoch: 46 loss: 0.6988680958747864\n",
      "epoch: 46 loss: 0.6938843131065369\n",
      "epoch: 46 loss: 0.697181761264801\n",
      "epoch: 46 loss: 0.6860491037368774\n",
      "epoch: 46 loss: 0.7120947241783142\n",
      "epoch: 46 loss: 0.7033352851867676\n",
      "epoch: 46 acc: 0.5208333333333334\n",
      "epoch: 47 loss: 0.6988680958747864\n",
      "epoch: 47 loss: 0.6938843131065369\n",
      "epoch: 47 loss: 0.697181761264801\n",
      "epoch: 47 loss: 0.6860491037368774\n",
      "epoch: 47 loss: 0.7120947241783142\n",
      "epoch: 47 loss: 0.7033352851867676\n",
      "epoch: 47 acc: 0.5208333333333334\n",
      "epoch: 48 loss: 0.6988680958747864\n",
      "epoch: 48 loss: 0.6938843131065369\n",
      "epoch: 48 loss: 0.697181761264801\n",
      "epoch: 48 loss: 0.6860491037368774\n",
      "epoch: 48 loss: 0.7120947241783142\n",
      "epoch: 48 loss: 0.7033352851867676\n",
      "epoch: 48 acc: 0.5208333333333334\n",
      "epoch: 49 loss: 0.6988680958747864\n",
      "epoch: 49 loss: 0.6938843131065369\n",
      "epoch: 49 loss: 0.697181761264801\n",
      "epoch: 49 loss: 0.6860491037368774\n",
      "epoch: 49 loss: 0.7120947241783142\n",
      "epoch: 49 loss: 0.7033352851867676\n",
      "epoch: 49 acc: 0.5208333333333334\n",
      "epoch: 50 loss: 0.6988680958747864\n",
      "epoch: 50 loss: 0.6938843131065369\n",
      "epoch: 50 loss: 0.697181761264801\n",
      "epoch: 50 loss: 0.6860491037368774\n",
      "epoch: 50 loss: 0.7120947241783142\n",
      "epoch: 50 loss: 0.7033352851867676\n",
      "epoch: 50 acc: 0.5208333333333334\n",
      "epoch: 51 loss: 0.6988680958747864\n",
      "epoch: 51 loss: 0.6938843131065369\n",
      "epoch: 51 loss: 0.697181761264801\n",
      "epoch: 51 loss: 0.6860491037368774\n",
      "epoch: 51 loss: 0.7120947241783142\n",
      "epoch: 51 loss: 0.7033352851867676\n",
      "epoch: 51 acc: 0.5208333333333334\n",
      "epoch: 52 loss: 0.6988680958747864\n",
      "epoch: 52 loss: 0.6938843131065369\n",
      "epoch: 52 loss: 0.697181761264801\n",
      "epoch: 52 loss: 0.6860491037368774\n",
      "epoch: 52 loss: 0.7120947241783142\n",
      "epoch: 52 loss: 0.7033352851867676\n",
      "epoch: 52 acc: 0.5208333333333334\n",
      "epoch: 53 loss: 0.6988680958747864\n",
      "epoch: 53 loss: 0.6938843131065369\n",
      "epoch: 53 loss: 0.697181761264801\n",
      "epoch: 53 loss: 0.6860491037368774\n",
      "epoch: 53 loss: 0.7120947241783142\n",
      "epoch: 53 loss: 0.7033352851867676\n",
      "epoch: 53 acc: 0.5208333333333334\n",
      "epoch: 54 loss: 0.6988680958747864\n",
      "epoch: 54 loss: 0.6938843131065369\n",
      "epoch: 54 loss: 0.697181761264801\n",
      "epoch: 54 loss: 0.6860491037368774\n",
      "epoch: 54 loss: 0.7120947241783142\n",
      "epoch: 54 loss: 0.7033352851867676\n",
      "epoch: 54 acc: 0.5208333333333334\n",
      "epoch: 55 loss: 0.6988680958747864\n",
      "epoch: 55 loss: 0.6938843131065369\n",
      "epoch: 55 loss: 0.697181761264801\n",
      "epoch: 55 loss: 0.6860491037368774\n",
      "epoch: 55 loss: 0.7120947241783142\n",
      "epoch: 55 loss: 0.7033352851867676\n",
      "epoch: 55 acc: 0.5208333333333334\n",
      "epoch: 56 loss: 0.6988680958747864\n",
      "epoch: 56 loss: 0.6938843131065369\n",
      "epoch: 56 loss: 0.697181761264801\n",
      "epoch: 56 loss: 0.6860491037368774\n",
      "epoch: 56 loss: 0.7120947241783142\n",
      "epoch: 56 loss: 0.7033352851867676\n",
      "epoch: 56 acc: 0.5208333333333334\n",
      "epoch: 57 loss: 0.6988680958747864\n",
      "epoch: 57 loss: 0.6938843131065369\n",
      "epoch: 57 loss: 0.697181761264801\n",
      "epoch: 57 loss: 0.6860491037368774\n",
      "epoch: 57 loss: 0.7120947241783142\n",
      "epoch: 57 loss: 0.7033352851867676\n",
      "epoch: 57 acc: 0.5208333333333334\n",
      "epoch: 58 loss: 0.6988680958747864\n",
      "epoch: 58 loss: 0.6938843131065369\n",
      "epoch: 58 loss: 0.697181761264801\n",
      "epoch: 58 loss: 0.6860491037368774\n",
      "epoch: 58 loss: 0.7120947241783142\n",
      "epoch: 58 loss: 0.7033352851867676\n",
      "epoch: 58 acc: 0.5208333333333334\n",
      "epoch: 59 loss: 0.6988680958747864\n",
      "epoch: 59 loss: 0.6938843131065369\n",
      "epoch: 59 loss: 0.697181761264801\n",
      "epoch: 59 loss: 0.6860491037368774\n",
      "epoch: 59 loss: 0.7120947241783142\n",
      "epoch: 59 loss: 0.7033352851867676\n",
      "epoch: 59 acc: 0.5208333333333334\n",
      "epoch: 60 loss: 0.6988680958747864\n",
      "epoch: 60 loss: 0.6938843131065369\n",
      "epoch: 60 loss: 0.697181761264801\n",
      "epoch: 60 loss: 0.6860491037368774\n",
      "epoch: 60 loss: 0.7120947241783142\n",
      "epoch: 60 loss: 0.7033352851867676\n",
      "epoch: 60 acc: 0.5208333333333334\n",
      "epoch: 61 loss: 0.6988680958747864\n",
      "epoch: 61 loss: 0.6938843131065369\n",
      "epoch: 61 loss: 0.697181761264801\n",
      "epoch: 61 loss: 0.6860491037368774\n",
      "epoch: 61 loss: 0.7120947241783142\n",
      "epoch: 61 loss: 0.7033352851867676\n",
      "epoch: 61 acc: 0.5208333333333334\n",
      "epoch: 62 loss: 0.6988680958747864\n",
      "epoch: 62 loss: 0.6938843131065369\n",
      "epoch: 62 loss: 0.697181761264801\n",
      "epoch: 62 loss: 0.6860491037368774\n",
      "epoch: 62 loss: 0.7120947241783142\n",
      "epoch: 62 loss: 0.7033352851867676\n",
      "epoch: 62 acc: 0.5208333333333334\n",
      "epoch: 63 loss: 0.6988680958747864\n",
      "epoch: 63 loss: 0.6938843131065369\n",
      "epoch: 63 loss: 0.697181761264801\n",
      "epoch: 63 loss: 0.6860491037368774\n",
      "epoch: 63 loss: 0.7120947241783142\n",
      "epoch: 63 loss: 0.7033352851867676\n",
      "epoch: 63 acc: 0.5208333333333334\n",
      "epoch: 64 loss: 0.6988680958747864\n",
      "epoch: 64 loss: 0.6938843131065369\n",
      "epoch: 64 loss: 0.697181761264801\n",
      "epoch: 64 loss: 0.6860491037368774\n",
      "epoch: 64 loss: 0.7120947241783142\n",
      "epoch: 64 loss: 0.7033352851867676\n",
      "epoch: 64 acc: 0.5208333333333334\n",
      "epoch: 65 loss: 0.6988680958747864\n",
      "epoch: 65 loss: 0.6938843131065369\n",
      "epoch: 65 loss: 0.697181761264801\n",
      "epoch: 65 loss: 0.6860491037368774\n",
      "epoch: 65 loss: 0.7120947241783142\n",
      "epoch: 65 loss: 0.7033352851867676\n",
      "epoch: 65 acc: 0.5208333333333334\n",
      "epoch: 66 loss: 0.6988680958747864\n",
      "epoch: 66 loss: 0.6938843131065369\n",
      "epoch: 66 loss: 0.697181761264801\n",
      "epoch: 66 loss: 0.6860491037368774\n",
      "epoch: 66 loss: 0.7120947241783142\n",
      "epoch: 66 loss: 0.7033352851867676\n",
      "epoch: 66 acc: 0.5208333333333334\n",
      "epoch: 67 loss: 0.6988680958747864\n",
      "epoch: 67 loss: 0.6938843131065369\n",
      "epoch: 67 loss: 0.697181761264801\n",
      "epoch: 67 loss: 0.6860491037368774\n",
      "epoch: 67 loss: 0.7120947241783142\n",
      "epoch: 67 loss: 0.7033352851867676\n",
      "epoch: 67 acc: 0.5208333333333334\n",
      "epoch: 68 loss: 0.6988680958747864\n",
      "epoch: 68 loss: 0.6938843131065369\n",
      "epoch: 68 loss: 0.697181761264801\n",
      "epoch: 68 loss: 0.6860491037368774\n",
      "epoch: 68 loss: 0.7120947241783142\n",
      "epoch: 68 loss: 0.7033352851867676\n",
      "epoch: 68 acc: 0.5208333333333334\n",
      "epoch: 69 loss: 0.6988680958747864\n",
      "epoch: 69 loss: 0.6938843131065369\n",
      "epoch: 69 loss: 0.697181761264801\n",
      "epoch: 69 loss: 0.6860491037368774\n",
      "epoch: 69 loss: 0.7120947241783142\n",
      "epoch: 69 loss: 0.7033352851867676\n",
      "epoch: 69 acc: 0.5208333333333334\n",
      "epoch: 70 loss: 0.6988680958747864\n",
      "epoch: 70 loss: 0.6938843131065369\n",
      "epoch: 70 loss: 0.697181761264801\n",
      "epoch: 70 loss: 0.6860491037368774\n",
      "epoch: 70 loss: 0.7120947241783142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 70 loss: 0.7033352851867676\n",
      "epoch: 70 acc: 0.5208333333333334\n",
      "epoch: 71 loss: 0.6988680958747864\n",
      "epoch: 71 loss: 0.6938843131065369\n",
      "epoch: 71 loss: 0.697181761264801\n",
      "epoch: 71 loss: 0.6860491037368774\n",
      "epoch: 71 loss: 0.7120947241783142\n",
      "epoch: 71 loss: 0.7033352851867676\n",
      "epoch: 71 acc: 0.5208333333333334\n",
      "epoch: 72 loss: 0.6988680958747864\n",
      "epoch: 72 loss: 0.6938843131065369\n",
      "epoch: 72 loss: 0.697181761264801\n",
      "epoch: 72 loss: 0.6860491037368774\n",
      "epoch: 72 loss: 0.7120947241783142\n",
      "epoch: 72 loss: 0.7033352851867676\n",
      "epoch: 72 acc: 0.5208333333333334\n",
      "epoch: 73 loss: 0.6988680958747864\n",
      "epoch: 73 loss: 0.6938843131065369\n",
      "epoch: 73 loss: 0.697181761264801\n",
      "epoch: 73 loss: 0.6860491037368774\n",
      "epoch: 73 loss: 0.7120947241783142\n",
      "epoch: 73 loss: 0.7033352851867676\n",
      "epoch: 73 acc: 0.5208333333333334\n",
      "epoch: 74 loss: 0.6988680958747864\n",
      "epoch: 74 loss: 0.6938843131065369\n",
      "epoch: 74 loss: 0.697181761264801\n",
      "epoch: 74 loss: 0.6860491037368774\n",
      "epoch: 74 loss: 0.7120947241783142\n",
      "epoch: 74 loss: 0.7033352851867676\n",
      "epoch: 74 acc: 0.5208333333333334\n",
      "epoch: 75 loss: 0.6988680958747864\n",
      "epoch: 75 loss: 0.6938843131065369\n",
      "epoch: 75 loss: 0.697181761264801\n",
      "epoch: 75 loss: 0.6860491037368774\n",
      "epoch: 75 loss: 0.7120947241783142\n",
      "epoch: 75 loss: 0.7033352851867676\n",
      "epoch: 75 acc: 0.5208333333333334\n",
      "epoch: 76 loss: 0.6988680958747864\n",
      "epoch: 76 loss: 0.6938843131065369\n",
      "epoch: 76 loss: 0.697181761264801\n",
      "epoch: 76 loss: 0.6860491037368774\n",
      "epoch: 76 loss: 0.7120947241783142\n",
      "epoch: 76 loss: 0.7033352851867676\n",
      "epoch: 76 acc: 0.5208333333333334\n",
      "epoch: 77 loss: 0.6988680958747864\n",
      "epoch: 77 loss: 0.6938843131065369\n",
      "epoch: 77 loss: 0.697181761264801\n",
      "epoch: 77 loss: 0.6860491037368774\n",
      "epoch: 77 loss: 0.7120947241783142\n",
      "epoch: 77 loss: 0.7033352851867676\n",
      "epoch: 77 acc: 0.5208333333333334\n",
      "epoch: 78 loss: 0.6988680958747864\n",
      "epoch: 78 loss: 0.6938843131065369\n",
      "epoch: 78 loss: 0.697181761264801\n",
      "epoch: 78 loss: 0.6860491037368774\n",
      "epoch: 78 loss: 0.7120947241783142\n",
      "epoch: 78 loss: 0.7033352851867676\n",
      "epoch: 78 acc: 0.5208333333333334\n",
      "epoch: 79 loss: 0.6988680958747864\n",
      "epoch: 79 loss: 0.6938843131065369\n",
      "epoch: 79 loss: 0.697181761264801\n",
      "epoch: 79 loss: 0.6860491037368774\n",
      "epoch: 79 loss: 0.7120947241783142\n",
      "epoch: 79 loss: 0.7033352851867676\n",
      "epoch: 79 acc: 0.5208333333333334\n",
      "epoch: 80 loss: 0.6988680958747864\n",
      "epoch: 80 loss: 0.6938843131065369\n",
      "epoch: 80 loss: 0.697181761264801\n",
      "epoch: 80 loss: 0.6860491037368774\n",
      "epoch: 80 loss: 0.7120947241783142\n",
      "epoch: 80 loss: 0.7033352851867676\n",
      "epoch: 80 acc: 0.5208333333333334\n",
      "epoch: 81 loss: 0.6988680958747864\n",
      "epoch: 81 loss: 0.6938843131065369\n",
      "epoch: 81 loss: 0.697181761264801\n",
      "epoch: 81 loss: 0.6860491037368774\n",
      "epoch: 81 loss: 0.7120947241783142\n",
      "epoch: 81 loss: 0.7033352851867676\n",
      "epoch: 81 acc: 0.5208333333333334\n",
      "epoch: 82 loss: 0.6988680958747864\n",
      "epoch: 82 loss: 0.6938843131065369\n",
      "epoch: 82 loss: 0.697181761264801\n",
      "epoch: 82 loss: 0.6860491037368774\n",
      "epoch: 82 loss: 0.7120947241783142\n",
      "epoch: 82 loss: 0.7033352851867676\n",
      "epoch: 82 acc: 0.5208333333333334\n",
      "epoch: 83 loss: 0.6988680958747864\n",
      "epoch: 83 loss: 0.6938843131065369\n",
      "epoch: 83 loss: 0.697181761264801\n",
      "epoch: 83 loss: 0.6860491037368774\n",
      "epoch: 83 loss: 0.7120947241783142\n",
      "epoch: 83 loss: 0.7033352851867676\n",
      "epoch: 83 acc: 0.5208333333333334\n",
      "epoch: 84 loss: 0.6988680958747864\n",
      "epoch: 84 loss: 0.6938843131065369\n",
      "epoch: 84 loss: 0.697181761264801\n",
      "epoch: 84 loss: 0.6860491037368774\n",
      "epoch: 84 loss: 0.7120947241783142\n",
      "epoch: 84 loss: 0.7033352851867676\n",
      "epoch: 84 acc: 0.5208333333333334\n",
      "epoch: 85 loss: 0.6988680958747864\n",
      "epoch: 85 loss: 0.6938843131065369\n",
      "epoch: 85 loss: 0.697181761264801\n",
      "epoch: 85 loss: 0.6860491037368774\n",
      "epoch: 85 loss: 0.7120947241783142\n",
      "epoch: 85 loss: 0.7033352851867676\n",
      "epoch: 85 acc: 0.5208333333333334\n",
      "epoch: 86 loss: 0.6988680958747864\n",
      "epoch: 86 loss: 0.6938843131065369\n",
      "epoch: 86 loss: 0.697181761264801\n",
      "epoch: 86 loss: 0.6860491037368774\n",
      "epoch: 86 loss: 0.7120947241783142\n",
      "epoch: 86 loss: 0.7033352851867676\n",
      "epoch: 86 acc: 0.5208333333333334\n",
      "epoch: 87 loss: 0.6988680958747864\n",
      "epoch: 87 loss: 0.6938843131065369\n",
      "epoch: 87 loss: 0.697181761264801\n",
      "epoch: 87 loss: 0.6860491037368774\n",
      "epoch: 87 loss: 0.7120947241783142\n",
      "epoch: 87 loss: 0.7033352851867676\n",
      "epoch: 87 acc: 0.5208333333333334\n",
      "epoch: 88 loss: 0.6988680958747864\n",
      "epoch: 88 loss: 0.6938843131065369\n",
      "epoch: 88 loss: 0.697181761264801\n",
      "epoch: 88 loss: 0.6860491037368774\n",
      "epoch: 88 loss: 0.7120947241783142\n",
      "epoch: 88 loss: 0.7033352851867676\n",
      "epoch: 88 acc: 0.5208333333333334\n",
      "epoch: 89 loss: 0.6988680958747864\n",
      "epoch: 89 loss: 0.6938843131065369\n",
      "epoch: 89 loss: 0.697181761264801\n",
      "epoch: 89 loss: 0.6860491037368774\n",
      "epoch: 89 loss: 0.7120947241783142\n",
      "epoch: 89 loss: 0.7033352851867676\n",
      "epoch: 89 acc: 0.5208333333333334\n",
      "epoch: 90 loss: 0.6988680958747864\n",
      "epoch: 90 loss: 0.6938843131065369\n",
      "epoch: 90 loss: 0.697181761264801\n",
      "epoch: 90 loss: 0.6860491037368774\n",
      "epoch: 90 loss: 0.7120947241783142\n",
      "epoch: 90 loss: 0.7033352851867676\n",
      "epoch: 90 acc: 0.5208333333333334\n",
      "epoch: 91 loss: 0.6988680958747864\n",
      "epoch: 91 loss: 0.6938843131065369\n",
      "epoch: 91 loss: 0.697181761264801\n",
      "epoch: 91 loss: 0.6860491037368774\n",
      "epoch: 91 loss: 0.7120947241783142\n",
      "epoch: 91 loss: 0.7033352851867676\n",
      "epoch: 91 acc: 0.5208333333333334\n",
      "epoch: 92 loss: 0.6988680958747864\n",
      "epoch: 92 loss: 0.6938843131065369\n",
      "epoch: 92 loss: 0.697181761264801\n",
      "epoch: 92 loss: 0.6860491037368774\n",
      "epoch: 92 loss: 0.7120947241783142\n",
      "epoch: 92 loss: 0.7033352851867676\n",
      "epoch: 92 acc: 0.5208333333333334\n",
      "epoch: 93 loss: 0.6988680958747864\n",
      "epoch: 93 loss: 0.6938843131065369\n",
      "epoch: 93 loss: 0.697181761264801\n",
      "epoch: 93 loss: 0.6860491037368774\n",
      "epoch: 93 loss: 0.7120947241783142\n",
      "epoch: 93 loss: 0.7033352851867676\n",
      "epoch: 93 acc: 0.5208333333333334\n",
      "epoch: 94 loss: 0.6988680958747864\n",
      "epoch: 94 loss: 0.6938843131065369\n",
      "epoch: 94 loss: 0.697181761264801\n",
      "epoch: 94 loss: 0.6860491037368774\n",
      "epoch: 94 loss: 0.7120947241783142\n",
      "epoch: 94 loss: 0.7033352851867676\n",
      "epoch: 94 acc: 0.5208333333333334\n",
      "epoch: 95 loss: 0.6988680958747864\n",
      "epoch: 95 loss: 0.6938843131065369\n",
      "epoch: 95 loss: 0.697181761264801\n",
      "epoch: 95 loss: 0.6860491037368774\n",
      "epoch: 95 loss: 0.7120947241783142\n",
      "epoch: 95 loss: 0.7033352851867676\n",
      "epoch: 95 acc: 0.5208333333333334\n",
      "epoch: 96 loss: 0.6988680958747864\n",
      "epoch: 96 loss: 0.6938843131065369\n",
      "epoch: 96 loss: 0.697181761264801\n",
      "epoch: 96 loss: 0.6860491037368774\n",
      "epoch: 96 loss: 0.7120947241783142\n",
      "epoch: 96 loss: 0.7033352851867676\n",
      "epoch: 96 acc: 0.5208333333333334\n",
      "epoch: 97 loss: 0.6988680958747864\n",
      "epoch: 97 loss: 0.6938843131065369\n",
      "epoch: 97 loss: 0.697181761264801\n",
      "epoch: 97 loss: 0.6860491037368774\n",
      "epoch: 97 loss: 0.7120947241783142\n",
      "epoch: 97 loss: 0.7033352851867676\n",
      "epoch: 97 acc: 0.5208333333333334\n",
      "epoch: 98 loss: 0.6988680958747864\n",
      "epoch: 98 loss: 0.6938843131065369\n",
      "epoch: 98 loss: 0.697181761264801\n",
      "epoch: 98 loss: 0.6860491037368774\n",
      "epoch: 98 loss: 0.7120947241783142\n",
      "epoch: 98 loss: 0.7033352851867676\n",
      "epoch: 98 acc: 0.5208333333333334\n",
      "epoch: 99 loss: 0.6988680958747864\n",
      "epoch: 99 loss: 0.6938843131065369\n",
      "epoch: 99 loss: 0.697181761264801\n",
      "epoch: 99 loss: 0.6860491037368774\n",
      "epoch: 99 loss: 0.7120947241783142\n",
      "epoch: 99 loss: 0.7033352851867676\n",
      "epoch: 99 acc: 0.5208333333333334\n"
     ]
    }
   ],
   "source": [
    "global_step = 0\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    for i in range(int(len(train_data) / batchsz)):\n",
    "        x = train_data[batchsz * i: batchsz * (i + 1)]\n",
    "        label = train_label[batchsz * i: batchsz * (i + 1)]\n",
    "        x, label = x.to(device), label.to(device)\n",
    "        \n",
    "        logits = model(x).squeeze(1)\n",
    "        loss = criteon(logits, label)\n",
    "        \n",
    "        # backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        global_step += 1\n",
    "        viz.line([loss.item()], [global_step], win='Training_Loss', update='append')\n",
    "\n",
    "        print('epoch:', epoch, 'loss:', loss.item())\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_correct = 0\n",
    "        total_num = 0\n",
    "        test_loss = 0\n",
    "\n",
    "        for i in range(int(len(test_data) / batchsz)):  \n",
    "            \n",
    "            x = test_data[batchsz * i: batchsz * (i + 1)]\n",
    "            label = test_label[batchsz * i: batchsz * (i + 1)]\n",
    "            x, label = x.to(device), label.to(device)\n",
    "            \n",
    "            logits = model(x).squeeze(1)\n",
    "            test_loss += criteon(logits, label).item()\n",
    "\n",
    "            pred = logits.argmax(dim=1)\n",
    "            total_correct += torch.eq(pred, label).float().sum().item()\n",
    "            total_num += x.size(0)\n",
    "\n",
    "        acc = total_correct / total_num\n",
    "        print('epoch:', epoch, 'acc:', acc)\n",
    "        # print('logits:', logits)\n",
    "\n",
    "        viz.line([test_loss], [global_step], win='Testing_Loss', opts=dict(title='Testing loss'), update='append')\n",
    "        viz.line([acc], [global_step], win='Accuracy', opts=dict(title='Accuracy'), update='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a687860",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "327.688px",
    "left": "865.8px",
    "right": "20px",
    "top": "228.788px",
    "width": "627.95px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
